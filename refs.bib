@article{Acar2009,
abstract = {Two-way arrays or matrices are often not enough to represent all the information in the data and standard two-way analysis techniques commonly applied on matrices may fail to find the underlying structures in multi-modal datasets. Multiway data analysis has recently become popular as an exploratory analysis tool in discovering the structures in higher-order datasets, where data have more than two modes. We provide a review of significant contributions in the literature on multiway models, algorithms as well as their applications in diverse disciplines including chemometrics, neuroscience, social network analysis, text mining and computer vision.},
annote = {survey
Reference first seminal papers in 20s
SVD - Singular Value Descomposition},
author = {Acar, E. and Yener, B.},
doi = {10.1109/TKDE.2008.112},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Acar, Yener - 2009 - Unsupervised Multiway Data Analysis A Literature Survey.pdf:pdf},
issn = {1041-4347},
journal = {IEEE Transactions on Knowledge and Data Engineering},
keywords = {Introductory and Survey,Mining methods and algorithms,Models,Singular value decomposition,computer vision,data analysis,exploratory analysis tool,higher-order singular value decomposition,multimodal datasets,singular value decomposition,social network analysis,text mining,two-way analysis techniques,unsupervised multiway data analysis},
month = {jan},
number = {1},
pages = {6--20},
shorttitle = {Knowledge and Data Engineering, IEEE Transactions},
title = {{Unsupervised Multiway Data Analysis: A Literature Survey}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4538221},
volume = {21},
year = {2009}
}
@article{Acar2015,
abstract = {With a goal of identifying biomarkers/patterns related to certain conditions or diseases, metabolomics focuses on the detection of chemical substances in biological samples such as urine and blood using a number of analytical techniques, including nuclear magnetic resonance (NMR) spectroscopy, liquid chromatography-mass spectrometry (LC-MS), and fluorescence spectroscopy. Data sets measured using these methods provide partly complementary information, and their joint analysis has the potential to reveal underlying structures, which are, otherwise, difficult to extract. While we can collect vast amounts of data using different analytical methods, data fusion remains a challenging task, in particular, when the goal is to capture the underlying factors and use them for interpretation, e.g., for biomarker identification. Furthermore, many data fusion applications require joint analysis of heterogeneous (i.e., in the form of higher order tensors and matrices) data sets with shared/unshared factors. In order to jointly analyze such heterogeneous data sets, we formulate data fusion as a coupled matrix and tensor factorization (CMTF) problem, which has already proved useful in many data mining applications, and discuss its extension to a structure-revealing data fusion model, i.e., a data fusion model that can identify shared and unshared factors. The traditional methods commonly used for data fusion in the presence of shared/unshared factors are matrix factorization-based methods. Using both simulations and prototypical experimental coupled data sets, we assess the performance of various state-of-the-art data fusion methods and demonstrate that while matrix factorization-based approaches have limitations when used for joint analysis of heterogeneous data sets, the structure-revealing CMTF model can successfully capture the underlying factors by exploiting the low-rank structure of higher order data sets.},
author = {Acar, Evrim and Bro, Rasmus and Smilde, Age K.},
doi = {10.1109/JPROC.2015.2438719},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Acar, Bro, Smilde - 2015 - Data Fusion in Metabolomics Using Coupled Matrix and Tensor Factorizations.pdf:pdf},
issn = {0018-9219},
journal = {Proceedings of the IEEE},
keywords = {Analytical models,Brain modeling,CMTF problem,Data fusion,Data integration,Data models,LC-MS,Metabolomics,Multimodal sensors,NMR spectroscopy,Tensile stress,biochemistry,bioinformatics,biological techniques,biology computing,biomarker identification,biomedical engineering,chemical substance detection,chromatography,coupled matrix and tensor factorizations,data analysis,fluorescence spectroscopy,heterogeneous data sets,higher order matrices,higher order tensors,joint data analysis,liquid chromatography-mass spectrometry,mass spectroscopic chemical analysis,matrix decomposition,matrix factorizations,medical computing,metabolomics,nuclear magnetic resonance spectroscopy,numerical analysis,sensor fusion,spectrochemical analysis,structure revealing CMTF model,structure revealing data fusion model,tensor factorization,tensor factorizations,tensors,unshared factors},
mendeley-tags = {bioinformatics,metabolomics,tensor factorization},
month = {sep},
number = {9},
pages = {1602--1620},
shorttitle = {Proceedings of the IEEE},
title = {{Data Fusion in Metabolomics Using Coupled Matrix and Tensor Factorizations}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7202834},
volume = {103},
year = {2015}
}
@article{Acar2011,
abstract = {The problem of incomplete data – i.e., data with missing or unknown values – in multi-way arrays is ubiquitous in biomedical signal processing, network traffic analysis, bibliometrics, social network analysis, chemometrics, computer vision, communication networks, etc. We consider the problem of how to factorize data sets with missing values with the goal of capturing the underlying latent structure of the data and possibly reconstructing missing values (i.e., tensor completion). We focus on one of the most well-known tensor factorizations that captures multi-linear structure, CANDECOMP/PARAFAC (CP). In the presence of missing data, CP can be formulated as a weighted least squares problem that models only the known entries. We develop an algorithm called CP-WOPT (CP Weighted OPTimization) that uses a first-order optimization approach to solve the weighted least squares problem. Based on extensive numerical experiments, our algorithm is shown to successfully factorize tensors with noise and up to 99{\%} missing data. A unique aspect of our approach is that it scales to sparse large-scale data, e.g., 1000×1000×1000 with five million known entries (0.5{\%} dense). We further demonstrate the usefulness of CP-WOPT on two real-world applications: a novel EEG (electroencephalogram) application where missing data is frequently encountered due to disconnections of electrodes and the problem of modeling computer network traffic where data may be absent due to the expense of the data collection process.},
author = {Acar, Evrim and Dunlavy, Daniel M. and Kolda, Tamara G. and M{\o}rup, Morten},
doi = {10.1016/j.chemolab.2010.08.004},
issn = {01697439},
journal = {Chemometrics and Intelligent Laboratory Systems},
keywords = {CANDECOMP,Incomplete data,Missing data,Optimization,PARAFAC,Tensor factorization},
month = {mar},
number = {1},
pages = {41--56},
title = {{Scalable tensor factorizations for incomplete data}},
url = {http://www.sciencedirect.com/science/article/pii/S0169743910001437},
volume = {106},
year = {2011}
}
@article{Acar2014,
abstract = {BACKGROUND: Analysis of data from multiple sources has the potential to enhance knowledge discovery by capturing underlying structures, which are, otherwise, difficult to extract. Fusing data from multiple sources has already proved useful in many applications in social network analysis, signal processing and bioinformatics. However, data fusion is challenging since data from multiple sources are often (i) heterogeneous (i.e., in the form of higher-order tensors and matrices), (ii) incomplete, and (iii) have both shared and unshared components. In order to address these challenges, in this paper, we introduce a novel unsupervised data fusion model based on joint factorization of matrices and higher-order tensors.

RESULTS: While the traditional formulation of coupled matrix and tensor factorizations modeling only shared factors fails to capture the underlying structures in the presence of both shared and unshared factors, the proposed data fusion model has the potential to automatically reveal shared and unshared components through modeling constraints. Using numerical experiments, we demonstrate the effectiveness of the proposed approach in terms of identifying shared and unshared components. Furthermore, we measure a set of mixtures with known chemical composition using both LC-MS (Liquid Chromatography - Mass Spectrometry) and NMR (Nuclear Magnetic Resonance) and demonstrate that the structure-revealing data fusion model can (i) successfully capture the chemicals in the mixtures and extract the relative concentrations of the chemicals accurately, (ii) provide promising results in terms of identifying shared and unshared chemicals, and (iii) reveal the relevant patterns in LC-MS by coupling with the diffusion NMR data.

CONCLUSIONS: We have proposed a structure-revealing data fusion model that can jointly analyze heterogeneous, incomplete data sets with shared and unshared components and demonstrated its promising performance as well as potential limitations on both simulated and real data.},
author = {Acar, Evrim and Papalexakis, Evangelos E and G{\"{u}}rdeniz, G{\"{o}}zde and Rasmussen, Morten A and Lawaetz, Anders J and Nilsson, Mathias and Bro, Rasmus},
doi = {10.1186/1471-2105-15-239},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Acar et al. - 2014 - Structure-revealing data fusion.pdf:pdf},
issn = {1471-2105},
journal = {BMC bioinformatics},
keywords = {Chemistry,Chemistry: methods,Chromatography, Liquid,Magnetic Resonance Spectroscopy,Mass Spectrometry,Statistics as Topic,Statistics as Topic: methods,bioinformatics,tensor factorization},
language = {en},
mendeley-tags = {bioinformatics,tensor factorization},
month = {jan},
number = {1},
pages = {239},
pmid = {25015427},
publisher = {BioMed Central Ltd},
title = {{Structure-revealing data fusion.}},
url = {http://www.biomedcentral.com/1471-2105/15/239},
volume = {15},
year = {2014}
}
@article{An2015,
author = {An, Gaoyun and Liu, Shuai and Ruan, Qiuqi},
doi = {10.1007/s10044-015-0507-x},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/An, Liu, Ruan - 2015 - A sparse neighborhood preserving non-negative tensor factorization algorithm for facial expression recognition.pdf:pdf},
issn = {1433-7541},
journal = {Pattern Analysis and Applications},
keywords = {tensor factorization},
mendeley-tags = {tensor factorization},
month = {aug},
title = {{A sparse neighborhood preserving non-negative tensor factorization algorithm for facial expression recognition}},
url = {http://link.springer.com/10.1007/s10044-015-0507-x},
year = {2015}
}
@article{Anandkumar2012,
abstract = {This work considers a computationally and statistically efficient parameter estimation method for a wide class of latent variable models---including Gaussian mixture models, hidden Markov models, and latent Dirichlet allocation---which exploits a certain tensor structure in their low-order observable moments (typically, of second- and third-order). Specifically, parameter estimation is reduced to the problem of extracting a certain (orthogonal) decomposition of a symmetric tensor derived from the moments; this decomposition can be viewed as a natural generalization of the singular value decomposition for matrices. Although tensor decompositions are generally intractable to compute, the decomposition of these specially structured tensors can be efficiently obtained by a variety of approaches, including power iterations and maximization approaches (similar to the case of matrices). A detailed analysis of a robust tensor power method is provided, establishing an analogue of Wedin's perturbation theorem for the singular vectors of matrices. This implies a robust and computationally tractable estimation approach for several popular latent variable models.},
archivePrefix = {arXiv},
arxivId = {1210.7559},
author = {Anandkumar, Anima and Ge, Rong and Hsu, Daniel and Kakade, Sham M. and Telgarsky, Matus},
eprint = {1210.7559},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Anandkumar et al. - 2012 - Tensor decompositions for learning latent variable models.pdf:pdf},
keywords = {tutorial},
mendeley-tags = {tutorial},
month = {oct},
pages = {2773--2832},
title = {{Tensor decompositions for learning latent variable models}},
url = {http://arxiv.org/abs/1210.7559},
year = {2012}
}
@article{Anisimov2014,
abstract = {This paper describes a method for automatic detection of semantic relations between concept nodes of a networked ontological knowledge base by analyzing matrices of semantic-syntactic valences of words. These matrices are obtained by means of nonnegative factorization of tensors of syntactic compatibility of words. Such tensors are generated in the course of frequency analysis of syntactic structures of sentences taken from large text corpora of English Wikipedia and Simple English Wikipedia entries.},
author = {Anisimov, A. V. and Marchenko, O. O. and Vozniuk, T. G.},
doi = {10.1007/s10559-014-9621-9},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Anisimov, Marchenko, Vozniuk - 2014 - Determining Semantic Valences of Ontology Concepts by Means of Nonnegative Factorization of Tensor.pdf:pdf},
issn = {1060-0396},
journal = {Cybernetics and Systems Analysis},
month = {jun},
number = {3},
pages = {327--337},
title = {{Determining Semantic Valences of Ontology Concepts by Means of Nonnegative Factorization of Tensors of Large Text Corpora}},
url = {http://link.springer.com/10.1007/s10559-014-9621-9},
volume = {50},
year = {2014}
}
@article{Antolin2015,
abstract = {In this paper we discuss the use of the sum-factorization for the calculation of the integrals arising in Galerkin isogeometric analysis. While introducing very little change in an isogeometric code based on element-by-element quadrature and assembling, the sum-factorization approach, taking advantage of the tensor-product structure of splines or NURBS shape functions, significantly reduces the quadrature computational cost.},
annote = {Looks irrelevant to my review},
author = {Antolin, P. and Buffa, A. and Calabr{\`{o}}, F. and Martinelli, M. and Sangalli, G.},
doi = {10.1016/j.cma.2014.12.013},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Antolin et al. - 2015 - Efficient matrix computation for tensor-product isogeometric analysis The use of sum factorization.pdf:pdf},
issn = {00457825},
journal = {Computer Methods in Applied Mechanics and Engineering},
keywords = {Isogeometric analysis,NURBS,Numerical integration,Splines,Sum-factorization},
month = {mar},
pages = {817--828},
title = {{Efficient matrix computation for tensor-product isogeometric analysis: The use of sum factorization}},
url = {http://www.sciencedirect.com/science/article/pii/S0045782514004927},
volume = {285},
year = {2015}
}
@article{Appellof1981,
annote = {seminal paper; first application in chemometrics},
author = {Appellof, C. J. and Davidson, E. R.},
doi = {10.1021/ac00236a025},
issn = {0003-2700},
journal = {Analytical Chemistry},
keywords = {tensor},
mendeley-tags = {tensor},
month = {nov},
number = {13},
pages = {2053--2056},
publisher = {American Chemical Society},
title = {{Strategies for analyzing data from video fluorometric monitoring of liquid chromatographic effluents}},
url = {http://dx.doi.org/10.1021/ac00236a025},
volume = {53},
year = {1981}
}
@article{Arnedo2015,
abstract = {Fractional anisotropy (FA) analysis of diffusion tensor-images (DTI) has yielded inconsistent abnormalities in schizophrenia (SZ). Inconsistencies may arise from averaging heterogeneous groups of patients. Here we investigate whether SZ is a heterogeneous group of disorders distinguished by distinct patterns of FA reductions. We developed a Generalized Factorization Method (GFM) to identify biclusters (i.e., subsets of subjects associated with a subset of particular characteristics, such as low FA in specific regions). GFM appropriately assembles a collection of unsupervised techniques with Non-negative Matrix Factorization to generate biclusters, rather than averaging across all subjects and all their characteristics. DTI tract-based spatial statistics images, which output is the locally maximal FA projected onto the group white matter skeleton, were analyzed in 47 SZ and 36 healthy subjects, identifying 8 biclusters. The mean FA of the voxels of each bicluster was significantly different from those of other SZ subjects or 36 healthy controls. The eight biclusters were organized into four more general patterns of low FA in specific regions: 1) genu of corpus callosum (GCC), 2) fornix (FX)+external capsule (EC), 3) splenium of CC (SCC)+retrolenticular limb (RLIC)+posterior limb (PLIC) of the internal capsule, and 4) anterior limb of the internal capsule. These patterns were significantly associated with particular clinical features: Pattern 1 (GCC) with bizarre behavior, pattern 2 (FX+EC) with prominent delusions, and pattern 3 (SCC+RLIC+PLIC) with negative symptoms including disorganized speech. The uncovered patterns suggest that SZ is a heterogeneous group of disorders that can be distinguished by different patterns of FA reductions associated with distinct clinical features.},
author = {Arnedo, Javier and Mamah, Daniel and Baranger, David A and Harms, Michael P and Barch, Deanna M and Svrakic, Dragan M and de Erausquin, Gabriel A and Cloninger, C Robert and Zwir, Igor},
doi = {10.1016/j.neuroimage.2015.06.083},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Arnedo et al. - 2015 - Decomposition of brain diffusion imaging data uncovers latent schizophrenias with distinct patterns of white matt.pdf:pdf},
issn = {1095-9572},
journal = {NeuroImage},
keywords = {Biclusters,Conceptual clustering,Consensus clustering,Fractional anisotropy,Fuzzy clustering,Generalized factorization,Model-based clustering,Non-negative Matrix Factorization,Positive and negative symptoms,Possibilistic clustering,Relational clustering,Schizophrenias,White matter},
month = {oct},
pages = {43--54},
pmid = {26151103},
title = {{Decomposition of brain diffusion imaging data uncovers latent schizophrenias with distinct patterns of white matter anisotropy.}},
url = {http://www.sciencedirect.com/science/article/pii/S1053811915005881},
volume = {120},
year = {2015}
}
@article{Atrey2010,
annote = {Tensors are no mentioned},
author = {Atrey, Pradeep K. and Hossain, M. Anwar and {El Saddik}, Abdulmotaleb and Kankanhalli, Mohan S.},
doi = {10.1007/s00530-010-0182-0},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Atrey et al. - 2010 - Multimodal fusion for multimedia analysis a survey.pdf:pdf},
issn = {0942-4962},
journal = {Multimedia Systems},
month = {apr},
number = {6},
pages = {345--379},
title = {{Multimodal fusion for multimedia analysis: a survey}},
url = {http://link.springer.com/10.1007/s00530-010-0182-0},
volume = {16},
year = {2010}
}
@article{Azizzadenesheli2016,
abstract = {We propose a new reinforcement learning algorithm for partially observable Markov decision processes (POMDP) based on spectral decomposition methods. While spectral methods have been previously employed for consistent learning of (passive) latent variable models such as hidden Markov models, POMDPs are more challenging since the learner interacts with the environment and possibly changes the future observations in the process. We devise a learning algorithm running through episodes, in each episode we employ spectral techniques to learn the POMDP parameters from a trajectory generated by a fixed policy. At the end of the episode, an optimization oracle returns the optimal memoryless planning policy which maximizes the expected reward based on the estimated POMDP model. We prove an order-optimal regret bound w.r.t. the optimal memoryless policy and efficient scaling with respect to the dimensionality of observation and action spaces.},
archivePrefix = {arXiv},
arxivId = {1602.07764},
author = {Azizzadenesheli, Kamyar and Lazaric, Alessandro and Anandkumar, Animashree},
eprint = {1602.07764},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Azizzadenesheli, Lazaric, Anandkumar - 2016 - Reinforcement Learning of POMDP's using Spectral Methods.pdf:pdf},
keywords = {tensor},
mendeley-tags = {tensor},
month = {feb},
title = {{Reinforcement Learning of POMDP's using Spectral Methods}},
url = {http://arxiv.org/abs/1602.07764},
year = {2016}
}
@article{Barker2013,
annote = {Single source audio separation by NMF or NTF},
author = {Barker, T and Virtanen, T},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Barker, Virtanen - 2013 - Non-negative tensor factorisation of modulation spectrograms for monaural sound source separation.pdf:pdf},
journal = {INTERSPEECH},
keywords = {audio},
mendeley-tags = {audio},
title = {{Non-negative tensor factorisation of modulation spectrograms for monaural sound source separation.}},
url = {http://ee301iitk.wdfiles.com/local--files/student-project-list/TP22.PDF},
year = {2013}
}
@inproceedings{Barker2014,
author = {Barker, Tom and Virtanen, Tuomas},
booktitle = {2014 International Joint Conference on Neural Networks (IJCNN)},
doi = {10.1109/IJCNN.2014.6889522},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Barker, Virtanen - 2014 - Semi-supervised non-negative tensor factorisation of modulation spectrograms for monaural speech separation.pdf:pdf},
isbn = {978-1-4799-1484-5},
keywords = {Equations,Mathematical model,Modulation,Source separation,Spectrogram,Tensile stress,Training,Wiener filters,Wiener-filter spectral parameters,activation parameters,audio signal processing,audio source separation,blind nonnegative modulation spectrum tensor facto,feature-tensor representation factorisation,harmonically-related component,matrix decomposition,mixture signal separation,modulation spectrograms,monaural speech separation,semisupervised nonnegative matrix factorisation,semisupervised nonnegative tensor factorisation,signal reconstruction,signal separation reconstruction,single-source model,source separation,source separation performance,spectrally-based method,speech processing,tensors,two-speaker mixtures},
language = {English},
month = {jul},
pages = {3556--3561},
publisher = {IEEE},
title = {{Semi-supervised non-negative tensor factorisation of modulation spectrograms for monaural speech separation}},
url = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=6889522},
year = {2014}
}
@article{Basser2007,
abstract = {We propose a novel spectral decomposition of a 4th-order covariance tensor, $\Sigma$. Just as the variability of vector (i.e., a 1st-order tensor)-valued random variable is characterized by a covariance matrix (i.e., a 2nd-order tensor), S, the variability of a 2nd-order tensor-valued random variable, D, is characterized by a 4th-order covariance tensor, $\Sigma$. Accordingly, just as the spectral decomposition of S is a linear combination of its eigenvalues and the outer product of its corresponding (1st-order tensors) eigenvectors, the spectral decomposition of $\Sigma$ is a linear combination of its eigenvalues and the outer product of its corresponding 2nd-order eigentensors. Analogously, these eigenvalues and 2nd-order eigentensors can be used as features with which to represent and visualize variability in tensor-valued data. Here we suggest a framework to visualize the angular structure of $\Sigma$, and then use it to assess and characterize the variability of synthetic diffusion tensor magnetic resonance imaging (DTI) data. The spectral decomposition suggests a hierarchy of symmetries with which to classify the statistical anisotropy inherent in tensor data. We also present maximum likelihood estimates of the sample mean and covariance tensors associated with D, and derive formulae for the expected value of the mean and variance of the projection of D along a particular direction (i.e., the apparent diffusion coefficient or ADC). These findings would be difficult, if not impossible, to glean if we treated 2nd-order tensor random variables as vector-valued random variables, which is conventionally done in multi-variate statistical analysis.},
author = {Basser, Peter J. and Pajevic, Sinisa},
doi = {10.1016/j.sigpro.2006.02.050},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Basser, Pajevic - 2007 - Spectral decomposition of a 4th-order covariance tensor Applications to diffusion tensor MRI.pdf:pdf},
issn = {01651684},
journal = {Signal Processing},
keywords = {Anisotropy,Covariance,DT-MRI,DTI,HOS,Karhunen-Lo{\'{e}}ve,Multi-linear algebra,PCA,Tensor},
month = {feb},
number = {2},
pages = {220--236},
title = {{Spectral decomposition of a 4th-order covariance tensor: Applications to diffusion tensor MRI}},
url = {http://www.sciencedirect.com/science/article/pii/S0165168406001678},
volume = {87},
year = {2007}
}
@book{Beliczynski2007,
address = {Berlin, Heidelberg},
annote = {NTF2},
doi = {10.1007/978-3-540-71629-7},
editor = {Beliczynski, Bartlomiej and Dzielinski, Andrzej and Iwanowski, Marcin and Ribeiro, Bernardete},
isbn = {978-3-540-71590-0},
issn = {0302-9743},
keywords = {NTF},
mendeley-tags = {NTF},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Adaptive and Natural Computing Algorithms}},
url = {http://www.springerlink.com/index/10.1007/978-3-540-71629-7},
volume = {4432},
year = {2007}
}
@article{Benner2016a,
abstract = {In this paper, we study and implement the structural iterative eigensolvers for the large-scale eigenvalue problem in the Bethe-Salpeter equation (BSE) based on the reduced basis approach via low-rank factorizations in generating matrices, introduced in the previous paper. The approach reduces numerical costs down to {\$}\backslashmathcal{\{}O{\}}(N{\_}b{\^{}}2){\$} in the size of atomic orbitals basis set, {\$}N{\_}b{\$}, instead of practically intractable {\$}\backslashmathcal{\{}O{\}}(N{\_}b{\^{}}6){\$} complexity scaling for the direct diagonalization of the BSE matrix. As an alternative to rank approximation of the static screen interaction part of the BSE matrix, we propose to restrict it to a small active sub-block, with a size balancing the storage for rank-structured representations of other matrix blocks. We demonstrate that the enhanced reduced-block approximation exhibits higher precision within the controlled numerical cost, providing as well a distinct two-sided error estimate for the BSE eigenvalues. It is shown that further reduction of the asymptotic computational cost is possible due to ALS-type iteration in block tensor train (TT) format applied to the quantized-TT (QTT) tensor representation of both long eigenvectors and rank-structured matrix blocks. The QTT-rank of these entities possesses almost the same magnitude as the number of occupied orbitals in the molecular systems, {\$}N{\_}o{\$}, hence the overall asymptotic complexity for solving the BSE problem can be estimated by {\$}\backslashmathcal{\{}O{\}}(\backslashlog(N{\_}o) N{\_}o{\^{}}{\{}2{\}}){\$}. We confirm numerically a considerable decrease in computational time for the presented iterative approach applied to various compact and chain-type molecules, while supporting sufficient accuracy.},
archivePrefix = {arXiv},
arxivId = {1602.02646},
author = {Benner, Peter and Dolgov, Sergey and Khoromskaia, Venera and Khoromskij, Boris N.},
eprint = {1602.02646},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Benner et al. - 2016 - Fast iterative solution of the Bethe-Salpeter eigenvalue problem using low-rank and QTT tensor approximation.pdf:pdf},
month = {feb},
pages = {23},
title = {{Fast iterative solution of the Bethe-Salpeter eigenvalue problem using low-rank and QTT tensor approximation}},
url = {http://arxiv.org/abs/1602.02646},
year = {2016}
}
@article{Benner2016,
abstract = {ABSTRACTThe Bethe–Salpeter equation (BSE) is a reliable model for estimating the absorption spectra in molecules and solids on the basis of accurate calculation of the excited states from first principles. Direct diagonalisation of the BSE matrix is practically intractable due to O(N6) complexity scaling in the size of the atomic orbital basis set, N. In this paper, we introduce and analyse a reduced basis approach to computation of the Bethe–Salpeter excitation energies which can lead to a relaxation of the numerical costs down to O(N3). The BSE operator is specified in terms of the two-electron integrals in the Hartree–Fock molecular orbital basis and the respective energies, calculated by the tensor-based solver described in previous works. The reduced basis method includes two steps. First, the diagonal plus low-rank approximation to fully populated blocks in the BSE matrix is calculated, enabling an easier partial eigenvalue solver for a large auxiliary system relying only on matrix–vector multiplica...},
author = {Benner, Peter and Khoromskaia, Venera and Khoromskij, Boris N.},
doi = {10.1080/00268976.2016.1149241},
issn = {0026-8976},
journal = {Molecular Physics},
keywords = {65F10,65F30,65F50,65N35,Bethe–Salpeter equation,Hartree–Fock equation,low-rank tensor decompositions,model reduction,reduced basis,truncated Cholesky factorisation,two-electron integrals},
language = {en},
month = {feb},
pages = {1--14},
publisher = {Taylor {\&} Francis},
title = {{A reduced basis approach for calculation of the Bethe–Salpeter excitation energies by using low-rank tensor factorisations}},
url = {http://www.tandfonline.com/doi/abs/10.1080/00268976.2016.1149241},
year = {2016}
}
@article{Bernardi2013,
abstract = {The tensor decomposition addressed in this paper may be seen as a generalization of Singular Value Decomposition of matrices. We consider general multilinear and multihomogeneous tensors. We show how to reduce the problem to a truncated moment matrix problem and give a new criterion for flat extension of Quasi-Hankel matrices. We connect this criterion to the commutation characterization of border bases. A new algorithm is described. It applies for general multihomogeneous tensors, extending the approach on binary forms by J.J. Sylvester. An example illustrates the algebraic operations involved in this approach and how the decomposition can be recovered from eigenvector computation.},
author = {Bernardi, A. and Brachat, J. and Comon, P. and Mourrain, B.},
doi = {10.1016/j.jsc.2012.05.012},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bernardi et al. - 2013 - General tensor decomposition, moment matrices and applications.pdf:pdf},
issn = {07477171},
journal = {Journal of Symbolic Computation},
keywords = {Decomposition,Flat extension,Hankel operator,Moment matrix,Multihomogeneous polynomial,Rank,Tensor},
month = {may},
pages = {51--71},
title = {{General tensor decomposition, moment matrices and applications}},
url = {http://www.sciencedirect.com/science/article/pii/S0747717112001290},
volume = {52},
year = {2013}
}
@article{Biamonte2013,
author = {Biamonte, Jacob and Bergholm, Ville and Lanzagorta, Marco},
doi = {10.1088/1751-8113/46/47/475301},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Biamonte, Bergholm, Lanzagorta - 2013 - Tensor network methods for invariant theory.pdf:pdf},
issn = {1751-8113},
journal = {Journal of Physics A: Mathematical and Theoretical},
language = {en},
month = {nov},
number = {47},
pages = {475301},
publisher = {IOP Publishing},
title = {{Tensor network methods for invariant theory}},
url = {http://iopscience.iop.org/article/10.1088/1751-8113/46/47/475301},
volume = {46},
year = {2013}
}
@misc{Bilen2016,
abstract = {Nonnegative matrix or tensor factorization is a very popular approach for audio source separation. One important problem in nonnegative tensor factorization (NTF) in the context of user-guided audio source separation is the necessity to manually assign the NTF components to audio sources in order to be able to enforce prior information on the sources during the estimation process. In this paper, two new approaches to NTF based source separation are proposed , which do not require any manual component assignment to the sources, but estimate the underlying assignment automatically. Both algorithms use the prior information on the source samples in the estimation process along with either a limit on the minimum number of components each source uses or with a restriction that each component is used by sparse number of sources. The proposed methods are shown to outperform the classic approach with a manual distribution of the components equally among the sources.},
author = {Bilen, Cagdas and Ozerov, Alexey and P{\'{e}}rez, Patrick},
booktitle = {IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP'16)},
keywords = {Itakura-Saito divergence,generalized expectation-maximization,nonnegative matrix factorization,source separa-tion},
language = {en},
month = {mar},
title = {{Automatic Allocation of NTF Components for User-Guided Audio Source Separation}},
url = {https://hal.inria.fr/hal-01259430/},
year = {2016}
}
@misc{Bolkart2016,
abstract = {Multilinear models are widely used to represent the statistical variations of 3D human faces as they decouple shape changes due to identity and expression. Existing methods to learn a multilinear face model degrade if not every person is captured in every expression, if face scans are noisy or partially occluded, if expressions are erroneously labeled, or if the vertex correspondence is inaccurate. These limitations impose requirements on the training data that disqualify large amounts of available 3D face data from being usable to learn a multilinear model. To overcome this, we introduce the first framework to robustly learn a multilinear model from 3D face databases with missing data, corrupt data, wrong semantic correspondence , and inaccurate vertex correspondence. To achieve this robustness to erroneous training data, our framework jointly learns a multilinear model and fixes the data. We evaluate our framework on two publicly available 3D face databases, and show that our framework achieves a data completion accuracy that is comparable to state-of-the-art tensor completion methods. Our method reconstructs corrupt data more accurately than state-of-the-art methods, and improves the quality of the learned model significantly for erroneously labeled expressions.},
author = {Bolkart, Timo and Wuhrer, Stefanie},
booktitle = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bolkart, Wuhrer - 2016 - A Robust Multilinear Model Learning Framework for 3D Faces.pdf:pdf},
keywords = {3D face modeling,groupwise optimization,multilinear model,robust model learning},
language = {en},
month = {jun},
title = {{A Robust Multilinear Model Learning Framework for 3D Faces}},
url = {https://hal.inria.fr/hal-01290783/},
year = {2016}
}
@article{Caicedo2014,
abstract = {This work proposes a histology image indexing strategy based on multimodal representations obtained from the combination of visual features and associated semantic annotations. Both data modalities are complementary information sources for an image retrieval system, since visual features lack explicit semantic information and semantic terms do not usually describe the visual appearance of images. The paper proposes a novel strategy to build a fused image representation using matrix factorization algorithms and data reconstruction principles to generate a set of multimodal features. The methodology can seamlessly recover the multimodal representation of images without semantic annotations, allowing us to index new images using visual features only, and also accepting single example images as queries. Experimental evaluations on three different histology image data sets show that our strategy is a simple, yet effective approach to building multimodal representations for histology image search, and outperforms the response of the popular late fusion approach to combine information.},
author = {Caicedo, Juan C and Vanegas, Jorge A and P{\'{a}}ez, Fabian and Gonz{\'{a}}lez, Fabio A},
doi = {10.1016/j.jbi.2014.04.016},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Caicedo et al. - 2014 - Histology image search using multimodal fusion.pdf:pdf},
issn = {1532-0480},
journal = {Journal of biomedical informatics},
keywords = {Algorithms,Biopsy,Biopsy: methods,Data Mining,Data Mining: methods,Humans,Image Interpretation, Computer-Assisted,Image Interpretation, Computer-Assisted: methods,Microscopy,Microscopy: methods,Multimodal Imaging,Multimodal Imaging: methods,Natural Language Processing,Observer Variation,Pattern Recognition, Automated,Pattern Recognition, Automated: methods,Radiology Information Systems,Radiology Information Systems: organization {\&} admi,Reproducibility of Results,Semantics,Sensitivity and Specificity,Subtraction Technique},
month = {oct},
pages = {114--28},
pmid = {24820052},
title = {{Histology image search using multimodal fusion.}},
url = {http://www.sciencedirect.com/science/article/pii/S1532046414001014},
volume = {51},
year = {2014}
}
@article{Cao2015,
abstract = {The existing studies involving matrix or tensor completion problems are commonly under the nuclear norm penalization framework due to the computational efficiency of the resulting convex optimization problem. Folded-concave penalization methods have demonstrated surprising developments in sparse learning problems due to their nice practical and theoretical properties. To share the same light of folded-concave penalization methods, we propose a new tensor completion model via folded-concave penalty for estimating missing values in tensor data. Two typical folded-concave penalties, the minmax concave plus (MCP) penalty and the smoothly clipped absolute deviation (SCAD) penalty, are employed in the new model. To solve the resulting nonconvex optimization problem, we develop a local linear approximation augmented Lagrange multiplier (LLA-ALM) algorithm which combines a two-step LLA strategy to search a local optimum of the proposed model efficiently. Finally, we provide numerical experiments with phase transitions, synthetic data sets, real image and video data sets to exhibit the superiority of the proposed model over the nuclear norm penalization method in terms of the accuracy and robustness.},
author = {Cao, Wenfei and Wang, Yao and Yang, Can and Chang, Xiangyu and Han, Zhi and Xu, Zongben},
doi = {10.1016/j.neucom.2014.10.069},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cao et al. - 2015 - Folded-concave penalization approaches to tensor completion.pdf:pdf},
issn = {09252312},
journal = {Neurocomputing},
keywords = {Folded-concave penalization,Local linear approximation,Nuclear norm,Sparse learning,Tensor completion},
month = {mar},
pages = {261--273},
title = {{Folded-concave penalization approaches to tensor completion}},
url = {http://www.sciencedirect.com/science/article/pii/S0925231214014659},
volume = {152},
year = {2015}
}
@article{Carroll1970,
annote = {seminal paper},
author = {Carroll, J. Douglas and Chang, Jih-Jie},
doi = {10.1007/BF02310791},
issn = {0033-3123},
journal = {Psychometrika},
keywords = {tensor},
mendeley-tags = {tensor},
month = {sep},
number = {3},
pages = {283--319},
title = {{Analysis of individual differences in multidimensional scaling via an n-way generalization of “Eckart-Young” decomposition}},
url = {http://link.springer.com/10.1007/BF02310791},
volume = {35},
year = {1970}
}
@article{Cattell1944,
annote = {Seminal paper of tensors},
author = {Cattell, Raymond B.},
doi = {10.1007/BF02288739},
issn = {0033-3123},
journal = {Psychometrika},
month = {dec},
number = {4},
pages = {267--283},
title = {{“Parallel proportional profiles” and other principles for determining the choice of factors by rotation}},
url = {http://link.springer.com/10.1007/BF02288739},
volume = {9},
year = {1944}
}
@article{Chaudhury2014,
abstract = {Multi-dimensional population balance equations (PBEs) are commonly used to describe the dynamics of particulate processes such as granulation. Such a class of equations are numerically complex and computationally intensive to solve due to the multiple internal coordinates involved. A computationally efficient model reduction technique would overcome the computational overheads associated with the solution of multi-dimensional PBEs. Moreover, this enables the process model to be used efficiently in process control and optimization. This study is concerned with the development of a novel reduced order model for a three-dimensional population balance model (PBM) for granulation, using a tensor decomposition technique in combination with separation of variables and singular value decomposition. These techniques were used to decompose the complex aggregation and breakage integrals. The developed model is faster by two orders of magnitude, requires less memory allocation for the storage of variables and results in negligible error when compared with the full model.},
author = {Chaudhury, Anwesha and Oseledets, Ivan and Ramachandran, Rohit},
doi = {10.1016/j.compchemeng.2013.10.020},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chaudhury, Oseledets, Ramachandran - 2014 - A computationally efficient technique for the solution of multi-dimensional PBMs of granulat.pdf:pdf},
issn = {00981354},
journal = {Computers {\&} Chemical Engineering},
keywords = {Aggregation,Breakage,Granulation,Model reduction,Multi-dimensional population balance model,Tensor decomposition},
month = {feb},
pages = {234--244},
title = {{A computationally efficient technique for the solution of multi-dimensional PBMs of granulation via tensor decomposition}},
url = {http://www.sciencedirect.com/science/article/pii/S0098135413003426},
volume = {61},
year = {2014}
}
@article{Chen2014a,
abstract = {Given a set of images, finding a compact and discriminative representation is still a big challenge especially when multiple latent factors are hidden in the way of data generation. To represent multifactor images, although multilinear models are widely used to parameterize the data, most methods are based on high-order singular value decomposition (HOSVD), which preserves global statistics but interprets local variations inadequately. To this end, we propose a novel method, called multilinear graph embedding (MGE), as well as its kernelization MKGE to leverage the manifold learning techniques into multilinear models. Our method theoretically links the linear, nonlinear, and multilinear dimensionality reduction. We also show that the supervised MGE encodes informative image priors for image regularization, provided that an image is represented as a high-order tensor. From our experiments on face and gait recognition, the superior performance demonstrates that MGE better represents multifactor images than classic methods, including HOSVD and its variants. In addition, the significant improvement in image (or tensor) completion validates the potential of MGE for image regularization.},
annote = {Multilinear Graph Embedding: Representation and Regularization for Images},
author = {Chen, Yi-Lei and Hsu, Chiou-Ting},
doi = {10.1109/TIP.2013.2292303},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen, Hsu - 2014 - Multilinear Graph Embedding Representation and Regularization for Images.pdf:pdf},
issn = {1941-0042},
journal = {IEEE transactions on image processing : a publication of the IEEE Signal Processing Society},
keywords = {Data models,Equations,Face,HOSVD,Image processing,MGE,Manifolds,Mathematical model,Multi-factor data,Principal component analysis,Tensile stress,data generation,discriminative representation,face recognition,gait recognition,global statistics,graph embedding,graph theory,high-order singular value decomposition,high-order tensor,image regularization,image representation,kernelization MKGE,linear dimensionality reduction,manifold learning,manifold learning techniques,multifactor image representation,multilinear dimensionality reduction,multilinear graph embedding,multilinear models,nonlinear dimensionality reduction,singular value decomposition,statistical analysis,supervised MGE,tensors},
mendeley-tags = {Image processing},
month = {feb},
number = {2},
pages = {741--54},
pmid = {26270915},
shorttitle = {Image Processing, IEEE Transactions on},
title = {{Multilinear Graph Embedding: Representation and Regularization for Images.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/26270915},
volume = {23},
year = {2014}
}
@article{Chen2014,
abstract = {The success of research on matrix completion is evident in a variety of real-world applications. Tensor completion, which is a high-order extension of matrix completion, has also generated a great deal of research interest in recent years. Given a tensor with incomplete entries, existing methods use either factorization or completion schemes to recover the missing parts. However, as the number of missing entries increases, factorization schemes may overfit the model because of incorrectly predefined ranks, while completion schemes may fail to interpret the model factors. In this paper, we introduce a novel concept: complete the missing entries and simultaneously capture the underlying model structure. To this end, we propose a method called simultaneous tensor decomposition and completion (STDC) that combines a rank minimization technique with Tucker model decomposition. Moreover, as the model structure is implicitly included in the Tucker model, we use factor priors, which are usually known a priori in real-world tensor objects, to characterize the underlying joint-manifold drawn from the model factors. By exploiting this auxiliary information, our method leverages two classic schemes and accurately estimates the model factors and missing entries. We conducted experiments to empirically verify the convergence of our algorithm on synthetic data and evaluate its effectiveness on various kinds of real-world data. The results demonstrate the efficacy of the proposed method and its potential usage in tensor-based applications. It also outperforms state-of-the-art methods on multilinear model analysis and visual data completion tasks.},
author = {Chen, Yi-Lei and Hsu, Chiou-Ting and Liao, Hong-Yuan Mark},
doi = {10.1109/TPAMI.2013.164},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen, Hsu, Liao - 2014 - Simultaneous tensor decomposition and completion using factor priors.pdf:pdf},
issn = {1939-3539},
journal = {IEEE transactions on pattern analysis and machine intelligence},
keywords = {Approximation methods,Brain modeling,Equations,Mathematical model,Matrix decomposition,STDC,Tensile stress,Tensor completion,Tucker decomposition,Tucker model decomposition,Visualization,auxiliary information,data visualisation,factor priors,factorization scheme,joint-manifold,matrix completion,matrix decomposition,model factor,multilinear model analysis,rank minimization technique,simultaneous tensor decomposition and completion,synthetic data,tensor objects,tensors,visual data completion task},
month = {mar},
number = {3},
pages = {577--91},
pmid = {24457512},
shorttitle = {Pattern Analysis and Machine Intelligence, IEEE Tr},
title = {{Simultaneous tensor decomposition and completion using factor priors.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/24457512},
volume = {36},
year = {2014}
}
@inproceedings{Cherif2008,
abstract = {In this paper we deal with blind identification of second order Volterra-Hammerstein series based on the analysis of a third order tensor composed of the fourth order output cumulants. We demonstrate that this nonlinear identification problem can be reduced to a linear one having the form Ax + By = c. The resolution of this system can be made with many methods. In this work we have used two algorithms: the alternating least square algorithm (ALS) and the alternating QR factorization algorithm (AQR). Simulation results show a good estimation of kernels with little superiority of the AQR algorithm. This superiority is the result of the numerical stability of the algorithm.},
author = {Cherif, I. and Fnaiech, F.},
booktitle = {2008 34th Annual Conference of IEEE Industrial Electronics},
doi = {10.1109/IECON.2008.4758237},
isbn = {978-1-4244-1767-4},
issn = {1553-572X},
keywords = {Alternating least square,Biological system modeling,Blind identification,Cumulant cubic tensor,Decision feedback equalizers,Kernel,Least squares methods,Optical filters,Optical receivers,QR matrix factorization,Signal processing,Signal processing algorithms,Stability,Tensile stress,Volterra series,Volterra-Hammerstein series,alternating QR factorization algorithm,alternating least square algorithm,blind identification,cumulant cubic tensor analysis,fourth order output cumulants,kernel,least squares approximations,nonlinear filters,nonlinear identification problem,numerical stability,second order Volterra-Hammerstein series,tensor factorization,tensors,third order tensor},
mendeley-tags = {kernel,tensor factorization},
month = {nov},
pages = {1851--1856},
publisher = {IEEE},
shorttitle = {Industrial Electronics, 2008. IECON 2008. 34th Ann},
title = {{Blind identification of a second order Volterra-Hammerstein series using cumulant cubic tensor analysis}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4758237},
year = {2008}
}
@article{Cichocki2008,
abstract = {In these lecture notes, the authors have outlined several approaches to solve a NMF/NTF problem. The following main conclusions can be drawn: 1) Multiplicative algorithms are not necessary the best approaches for NMF, especially if data representations are not very redundant or sparse. 2) Much better performance can be achieved using the FP-ALS (especially for large-scale problems), IPC, and QN methods. 3) To achieve high performance it is quite important to use the multilayer structure with multistart initialization conditions. 4) To estimate physically meaningful nonnegative components it is often necessary to use some a priori knowledge and impose additional constraints or regularization terms (to control sparsity, boundness, continuity or smoothness of the estimated nonnegative components).},
annote = {Methods to solve optimization problem
Relevant author},
author = {Cichocki, A. and Zdunek, R. and Amari, S.-i.},
doi = {10.1109/MSP.2008.4408452},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cichocki, Zdunek, Amari - 2008 - Nonnegative Matrix and Tensor Factorization Lecture Notes.pdf:pdf},
issn = {1053-5888},
journal = {IEEE Signal Processing Magazine},
keywords = {Brain modeling,Clustering algorithms,Cost function,Data analysis,FP-ALS,IPC methods,Image segmentation,Matrix decomposition,NTF,Pattern recognition,QN methods,Robustness,Surges,Tensile stress,large-scale problems,matrix decomposition,multilayer structure,multistart initialization conditions,nonnegative components,nonnegative matrix factorization,nonnegative tensor factorization,signal processing,tensors},
mendeley-tags = {NTF},
number = {1},
pages = {142--145},
shorttitle = {IEEE Signal Processing Magazine},
title = {{Nonnegative Matrix and Tensor Factorization [Lecture Notes]}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4408452},
volume = {25},
year = {2008}
}
@article{Cichocki2015,
abstract = {The widespread use of multisensor technology and the emergence of big data sets have highlighted the limitations of standard flat-view matrix models and the necessity to move toward more versatile data analysis tools. We show that higher-order tensors (i.e., multiway arrays) enable such a fundamental paradigm shift toward models that are essentially polynomial, the uniqueness of which, unlike the matrix methods, is guaranteed under very mild and natural conditions. Benefiting from the power of multilinear algebra as their mathematical backbone, data analysis techniques using tensor decompositions are shown to have great flexibility in the choice of constraints which match data properties and extract more general latent components in the data than matrix-based methods.},
annote = {Survey
References to seminal papers
Methods and application with tensors, not only in signal processing.
A list of software available to deal with tensors
Refences comparing advantage of tensors (multilinear algebra) compared with matrices (linear algebra)},
author = {Cichocki, Andrzej and Mandic, Danilo and {De Lathauwer}, Lieven and Zhou, Guoxu and Zhao, Qibin and Caiafa, Cesar and PHAN, HUY ANH},
doi = {10.1109/MSP.2013.2297439},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cichocki et al. - 2015 - Tensor Decompositions for Signal Processing Applications From two-way to multiway component analysis.pdf:pdf},
issn = {1053-5888},
journal = {IEEE Signal Processing Magazine},
keywords = {Big Data,Big data,Data analysis,Data models,Matrix decomposition,Sensors,Tensile stress,big data sets,data analysis,data analysis tools,mathematical backbone,matrix algebra,multilinear algebra,multisensor technology,multiway arrays,multiway component analysis,sensor fusion,signal processing applications,standard flat-view matrix models,tensor decompositions,tensors,two-way component analysis},
month = {mar},
number = {2},
pages = {145--163},
shorttitle = {Signal Processing Magazine, IEEE},
title = {{Tensor Decompositions for Signal Processing Applications: From two-way to multiway component analysis}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7038247},
volume = {32},
year = {2015}
}
@article{Cohen2016,
abstract = {Convolutional rectifier networks, i.e. convolutional neural networks with rectified linear activation and max or average pooling, are the cornerstone of modern deep learning. However, despite their wide use and success, our theoretical understanding of the expressive properties that drive these networks is partial at best. On other hand, we have a much firmer grasp of these issues in the world of arithmetic circuits. Specifically, it is known that convolutional arithmetic circuits posses the property of "complete depth efficiency", meaning that besides a negligible set, all functions that can be implemented by a deep network of polynomial size, require exponential size in order to be implemented (or even approximated) by a shallow network. In this paper we describe a construction based on generalized tensor decompositions, that transforms convolutional arithmetic circuits into convolutional rectifier networks. We then use mathematical tools available from the world of arithmetic circuits to prove new results. First, we show that convolutional rectifier networks are universal with max pooling but not with average pooling. Second, and more importantly, we show that depth efficiency is weaker with convolutional rectifier networks than it is with convolutional arithmetic circuits. This leads us to believe that developing effective methods for training convolutional arithmetic circuits, thereby fulfilling their expressive potential, may give rise to a deep learning architecture that is provably superior to convolutional rectifier networks but has so far been overlooked by practitioners.},
archivePrefix = {arXiv},
arxivId = {1603.00162},
author = {Cohen, Nadav and Shashua, Amnon},
eprint = {1603.00162},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cohen, Shashua - 2016 - Convolutional Rectifier Networks as Generalized Tensor Decompositions.pdf:pdf},
month = {mar},
title = {{Convolutional Rectifier Networks as Generalized Tensor Decompositions}},
url = {http://arxiv.org/abs/1603.00162},
year = {2016}
}
@article{Combettes2016,
abstract = {We analyze a class of norms defined via an optimal interpolation problem involving the composition of norms and a linear operator. This framework encompasses a number of norms which have been used as regularizers in machine learning and statistics. In particular, these include the latent group lasso, the overlapping group lasso, and certain norms used for learning tensors. We establish basic properties of this class of regularizers and we provide the dual norm. We present a novel stochastic block-coordinate version of the Douglas-Rachford algorithm to solve regularization problems with these regularizers. A unique feature of the algorithm is that it yields iterates that converge to a solution in the case of non smooth losses and random block updates. Finally, we present numerical experiments on the latent group lasso.},
archivePrefix = {arXiv},
arxivId = {1603.09273},
author = {Combettes, Patrick L. and McDonald, Andrew M. and Micchelli, Charles A. and Pontil, Massimiliano},
eprint = {1603.09273},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Combettes et al. - 2016 - Learning with Optimal Interpolation Norms Properties and Algorithms.pdf:pdf},
month = {mar},
title = {{Learning with Optimal Interpolation Norms: Properties and Algorithms}},
url = {http://arxiv.org/abs/1603.09273},
year = {2016}
}
@article{Comon2014,
abstract = {Tensor decompositions are at the core of many Blind Source Separation (BSS) algorithms, either explicitly or implicitly. In particular, the Canonical Polyadic (CP) tensor decomposition plays a central role in identification of underdetermined mixtures. Despite some similarities, CP and Singular value Decomposition (SVD) are quite different. More generally, tensors and matrices enjoy different properties, as pointed out in this brief survey.},
annote = {Read to background
Survey},
author = {Comon, Pierre},
doi = {10.1109/MSP.2014.2298533},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Comon - 2014 - Tensors A brief introduction.pdf:pdf},
issn = {1053-5888},
journal = {IEEE Signal Processing Magazine},
keywords = {CP decomposition,Waring,blind source separation,polyadic,polynomial,tensor},
language = {en},
mendeley-tags = {blind source separation},
month = {may},
number = {3},
pages = {44--53},
title = {{Tensors : A brief introduction}},
url = {https://hal.archives-ouvertes.fr/hal-00923279/},
volume = {31},
year = {2014}
}
@article{Comon2016,
abstract = {In this paper, we study a polynomial decomposition model that arises in problems of system identification, signal processing and machine learning. We show that this decomposition is a special case of the X-rank decomposition --- a powerful novel concept in algebraic geometry that generalizes the tensor CP decomposition. We prove new results on generic/maximal rank and on identifiability of the polynomial decomposition model. In the paper, we try to make results and basic tools accessible for a general audience (assuming no knowledge of algebraic geometry or its prerequisites).},
archivePrefix = {arXiv},
arxivId = {1603.01566},
author = {Comon, Pierre and Qi, Yang and Usevich, Konstantin},
eprint = {1603.01566},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Comon, Qi, Usevich - 2016 - X-rank and identifiability for a polynomial decomposition model.pdf:pdf},
month = {mar},
pages = {23},
title = {{X-rank and identifiability for a polynomial decomposition model}},
url = {http://arxiv.org/abs/1603.01566},
year = {2016}
}
@article{Dahne2015,
abstract = {Multimodal data are ubiquitous in engineering, communications, robotics, computer vision, or more generally speaking in industry and the sciences. All disciplines have developed their respective sets of analytic tools to fuse the information that is available in all measured modalities. In this paper, we provide a review of classical as well as recent machine learning methods (specifically factor models) for fusing information from functional neuroimaging techniques such as: LFP, EEG, MEG, fNIRS, and fMRI. Early and late fusion scenarios are distinguished, and appropriate factor models for the respective scenarios are presented along with example applications from selected multimodal neuroimaging studies. Further emphasis is given to the interpretability of the resulting model parameters, in particular by highlighting how factor models relate to physical models needed for source localization. The methods we discuss allow for the extraction of information from neural data, which ultimately contributes to 1) better neuroscientific understanding; 2) enhance diagnostic performance; and 3) discover neural signals of interest that correlate maximally with a given cognitive paradigm. While we clearly study the multimodal functional neuroimaging challenge, the discussed machine learning techniques have a wide applicability, i.e., in general data fusion, and may thus be informative to the general interested reader.},
author = {Dahne, Sven and Biebmann, Felix and Samek, Wojciech and Haufe, Stefan and Goltz, Dominique and Gundlach, Christopher and Villringer, Arno and Fazli, Siamac and Muller, Klaus-Robert},
doi = {10.1109/JPROC.2015.2425807},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dahne et al. - 2015 - Multivariate Machine Learning Methods for Fusing Multimodal Functional Neuroimaging Data.pdf:pdf},
issn = {0018-9219},
journal = {Proceedings of the IEEE},
keywords = {Brain models,Data mining,Data models,EEG,EEG technique,Feature extraction,LFP technique,MEG,MEG technique,Machine learning,Multimodal sensors,Neuroimaging,analytic tools,bioimageinformatics,biomedical MRI,cognitive paradigm,data fusion,diagnostic performance,electroencephalography,fMRI,fMRI technique,fNIRS,fNIRS technique,factor models,feature extraction,functional near-infrared spectroscopy,image fusion,information extraction,infrared spectroscopy,learning (artificial intelligence),magnetic resonance imaging,magnetoencephalography,medical image processing,multimodal functional neuroimaging data,multimodal neuroimaging,multivariate machine learning methods,neural signals discovery,neuroscientific understanding,review},
mendeley-tags = {bioimageinformatics},
number = {9},
pages = {1--24},
shorttitle = {Proceedings of the IEEE},
title = {{Multivariate Machine Learning Methods for Fusing Multimodal Functional Neuroimaging Data}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7182735},
volume = {103},
year = {2015}
}
@article{Dartois2016,
abstract = {In this text we review a few structural properties of matrix models that should at least partly generalize to random tensor models. We review some aspects of the loop equations for matrix models and their algebraic counterpart for tensor models. Despite the generic title of this review, we, in particular, invoke the Topological Recursion. We explain its appearance in matrix models. Then we state that a family of tensor models provides a natural example which satisfies a version of the most general form of the topological recursion, named the blobbed topological recursion. We discuss the difficulties of extending the technical solutions existing for matrix models to tensor models. Some proofs are not published yet but will be given in a coming paper, the rest of the results are well known in the literature.},
archivePrefix = {arXiv},
arxivId = {1603.02167},
author = {Dartois, Stephane},
eprint = {1603.02167},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dartois - 2016 - Tensor Models extending the matrix models structures and methods.pdf:pdf},
month = {mar},
pages = {13},
title = {{Tensor Models: extending the matrix models structures and methods}},
url = {http://arxiv.org/abs/1603.02167},
year = {2016}
}
@article{Defant2012,
abstract = {Within finite dimensional Banach lattices we prove interpolation formulas for the Fremlin tensor product and spaces of regular multilinear forms and operators. We show applications to factorization of matrices with respect to the Schur product. Our results imply various abstract variants of Schurʼs classical result, and in particular we extend Pisierʼs converse for matrices in finite dimensional ℓp-spaces to the setting of complex Calder{\'{o}}n interpolation of finite dimensional Banach lattices.},
author = {Defant, Andreas and Masty{\l}o, Mieczys{\l}aw},
doi = {10.1016/j.jfa.2012.02.007},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Defant, Masty{\l}o - 2012 - Interpolation of Fremlin tensor products and Schur factorization of matrices.pdf:pdf},
issn = {00221236},
journal = {Journal of Functional Analysis},
keywords = {Banach lattice,Calder{\'{o}}n–Lozanovskii space,Complex interpolation,Fremlin tensor product,Regular operator},
month = {may},
number = {9},
pages = {3981--3999},
title = {{Interpolation of Fremlin tensor products and Schur factorization of matrices}},
url = {http://www.sciencedirect.com/science/article/pii/S0022123612000675},
volume = {262},
year = {2012}
}
@article{Desmorat2016,
abstract = {The tensorial nature of crack density of an initially isotropic 2D medium with open and closed cracks is studied by means of polar decomposition rewriting of standard micro-mechanics results. The question of both indicial and constitutive symmetries of different crack density tensors is addressed: for instance the standard fourth order crack density tensor Dc is rari-constant (totally symmetric) and the fourth order closed cracks density tensor  by which closed cracks are acting is found to have the square symmetry. The effect of cracks closure and sliding is accordingly shown to be represented by a second order tensor ($\delta$c) so that only two second order crack density tensors, do and $\delta$c, are needed for 2D medium with open and closed sliding cracks. Similarly to the open cracks case, any arbitrary closed crack system is shown to be represented by only two non orthogonal families of cracks. The question of macroscopic cracks closure conditions is finally studied. Present study leads to an approximate framework in which the only internal variable representative of physical cracks, open and closed, is second order cracks density tensor. Proposed second order tensorial framework is shown to be exact in the case of two orthogonal arrays of cracks, open and/or closed, it is approximate in the general case of many arrays of cracks, open and/or closed.},
author = {Desmorat, B. and Desmorat, R.},
doi = {10.1016/j.euromechsol.2016.02.004},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Desmorat, Desmorat - 2016 - Second order tensorial framework for 2D medium with open and closed cracks.pdf:pdf},
issn = {09977538},
journal = {European Journal of Mechanics - A/Solids},
keywords = {closure effect,crack density,micro-mechanics,polar decomposition,sliding},
month = {feb},
title = {{Second order tensorial framework for 2D medium with open and closed cracks}},
url = {http://www.sciencedirect.com/science/article/pii/S0997753816300122},
year = {2016}
}
@article{Ding2015,
author = {Ding, Weiyang and Qi, Liqun and Wei, Yimin},
doi = {10.1002/nla.1970},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ding, Qi, Wei - 2015 - Fast Hankel tensor-vector product and its application to exponential data fitting.pdf:pdf},
issn = {10705325},
journal = {Numerical Linear Algebra with Applications},
month = {oct},
number = {5},
pages = {814--832},
title = {{Fast Hankel tensor-vector product and its application to exponential data fitting}},
url = {http://doi.wiley.com/10.1002/nla.1970},
volume = {22},
year = {2015}
}
@article{Domanov2015,
abstract = {Canonical Polyadic Decomposition (CPD) of a third-order tensor is a minimal de- composition into a sum of rank-1 tensors. We find conditions for the uniqueness of individual rank-1 tensors in CPD and present an algorithm to recover them. We called the algorithm “algebraic” because it relies only on standard linear algebra: we compute Kronecker products, the null space of a matrix, and eigen/singular value decomposition. Our new conditions for uniqueness and the working assumptions for the algorithm are more relaxed than, for instance, the famous Kruskal bound. We address both the case where all tensor dimensions are strictly smaller than the rank and the case where a dimension is at least equal to the rank. In the latter case it is known that if 2 ≤ I ≤ J ≤ K, then the CPD of a generic I×J×K tensor of rank R ≤ K is unique if and only if R ≤ (I−1)(J−1). An existing algebraic algorithm (based on simultaneous diagonalization of a set of matrices) com- putes CPD under the more restrictive constraint R(R − 1) ≤ I(I − 1)J(J − 1)/2 and optimization based algorithms fail to compute the CPD in a reasonable amount of time in the low dimensional case I = 3, J = 7, K = R = 12. By comparison, in our approach it takes less than 1 sec to compute CPD of a generic 3 ×7×12 tensor of rank 12. We show for R ≤ 24 and conjecture for R {\textgreater} 25 that our algorithm can recover the rank-1 tensors in CPD up to R ≤ (I −1)(J −1).},
author = {Domanov, I and Lathauwer, L De},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Domanov, Lathauwer - 2015 - Canonical polyadic decomposition of third-order tensors relaxed uniqueness conditions and algebraic algorith.pdf:pdf},
journal = {arXiv preprint arXiv:1501.07251},
title = {{Canonical polyadic decomposition of third-order tensors: relaxed uniqueness conditions and algebraic algorithm}},
url = {http://arxiv.org/abs/1501.07251},
year = {2015}
}
@article{Domanov2014,
author = {Domanov, I and Lathauwer, LD},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Domanov, Lathauwer - 2014 - Canonical polyadic decomposition of third-order tensors reduction to generalized eigenvalue decomposition.pdf:pdf},
journal = {SIAM Journal on Matrix Analysis and Applications},
title = {{Canonical polyadic decomposition of third-order tensors: reduction to generalized eigenvalue decomposition}},
url = {http://epubs.siam.org/doi/abs/10.1137/130916084},
year = {2014}
}
@article{Domanov2013a,
abstract = {Canonical polyadic decomposition (CPD) of a higher-order tensor is decomposition into a minimal number of rank-{\$}1{\$} tensors. We give an overview of existing results concerning uniqueness. We present new, relaxed, conditions that guarantee uniqueness of one factor matrix. These conditions involve Khatri--Rao products of compound matrices. We make links with existing results involving ranks and k-ranks of factor matrices. We give a shorter proof, based on properties of second compound matrices, of existing results concerning overall CPD uniqueness in the case where one factor matrix has full column rank. We develop basic material involving {\$}m{\$}th compound matrices that will be instrumental in Part II for establishing overall CPD uniqueness in cases where none of the factor matrices has full column rank.},
annote = {comparing advantage of tensors (multilinear algebra) with matrices (linear algebra)},
author = {Domanov, Ignat and {De Lathauwer}, Lieven},
doi = {10.1137/120877234},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Domanov, De Lathauwer - 2013 - On the Uniqueness of the Canonical Polyadic Decomposition of Third-Order Tensors---Part I Basic Results a.pdf:pdf},
issn = {0895-4798},
journal = {SIAM Journal on Matrix Analysis and Applications},
keywords = {15A23,15A69,Candecomp,Khatri--Rao product,Parafac,canonical polyadic decomposition,compound matrix,multilinear algebra,tensor,three-way array},
language = {en},
month = {jul},
number = {3},
pages = {855--875},
publisher = {Society for Industrial and Applied Mathematics},
title = {{On the Uniqueness of the Canonical Polyadic Decomposition of Third-Order Tensors---Part I: Basic Results and Uniqueness of One Factor Matrix}},
url = {http://epubs.siam.org/doi/abs/10.1137/120877234},
volume = {34},
year = {2013}
}
@article{Domanov2013,
abstract = {Canonical polyadic (also known as Candecomp/Parafac) decomposition (CPD) of a higher-order tensor is decomposition into a minimal number of rank-{\$}1{\$} tensors. In Part I, we gave an overview of existing results concerning uniqueness and presented new, relaxed, conditions that guarantee uniqueness of one factor matrix. In Part II we use these results for establishing overall CPD uniqueness in cases where none of the factor matrices has full column rank. We obtain uniqueness conditions involving Khatri--Rao products of compound matrices and Kruskal-type conditions. We consider both deterministic and generic uniqueness. We also discuss uniqueness of INDSCAL and other constrained polyadic decompositions.},
author = {Domanov, Ignat and {De Lathauwer}, Lieven},
doi = {10.1137/120877258},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Domanov, De Lathauwer - 2013 - On the Uniqueness of the Canonical Polyadic Decomposition of Third-Order Tensors---Part II Uniqueness of.pdf:pdf},
issn = {0895-4798},
journal = {SIAM Journal on Matrix Analysis and Applications},
keywords = {15A23,15A69,Candecomp,Khatri--Rao product,Parafac,canonical polyadic decomposition,compound matrix,multilinear algebra,tensor,three-way array},
language = {en},
month = {jul},
number = {3},
pages = {876--903},
publisher = {Society for Industrial and Applied Mathematics},
title = {{On the Uniqueness of the Canonical Polyadic Decomposition of Third-Order Tensors---Part II: Uniqueness of the Overall Decomposition}},
url = {http://epubs.siam.org/doi/abs/10.1137/120877258},
volume = {34},
year = {2013}
}
@article{Dourbal2016,
abstract = {A method of fast linear transform algorithm synthesis for an arbitrary tensor, matrix, or vector is proposed. The method is based on factorization of a tensor and using the factors for building computational structures performing fast tensor - vector multiplication on a computer or dedicated hardware platform.},
archivePrefix = {arXiv},
arxivId = {1602.07008},
author = {Dourbal, Pavel},
eprint = {1602.07008},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dourbal - 2016 - Synthesis of fast multiplication algorithms for arbitrary tensors.pdf:pdf},
month = {feb},
pages = {79},
title = {{Synthesis of fast multiplication algorithms for arbitrary tensors}},
url = {http://arxiv.org/abs/1602.07008},
year = {2016}
}
@article{Espin-Noboa2016,
abstract = {Nowadays, human movement in urban spaces can be traced digitally in many cases. It can be observed that movement patterns are not constant, but vary across time and space. In this work,we characterize such spatio-temporal patterns with an innovative combination of two separate approaches that have been utilized for studying human mobility in the past. First, by using non-negative tensor factorization (NTF), we are able to cluster human behavior based on spatio-temporal dimensions. Second, for understanding these clusters, we propose to use HypTrails, a Bayesian approach for expressing and comparing hypotheses about human trails. To formalize hypotheses we utilize data that is publicly available on the Web, namely Foursquare data and census data provided by an open data platform. By applying this combination of approaches to taxi data in Manhattan, we can discover and explain different patterns in human mobility that cannot be identified in a collective analysis. As one example, we can find a group of taxi rides that end at locations with a high number of party venues (according to Foursquare) on weekend nights. Overall, our work demonstrates that human mobility is not one-dimensional but rather contains different facets both in time and space which we explain by utilizing online data. The findings of this paper argue for a more fine-grained analysis of human mobility in order to make more informed decisions for e.g., enhancing urban structures, tailored traffic control and location-based recommender systems.},
archivePrefix = {arXiv},
arxivId = {1601.05274},
author = {Esp{\'{i}}n-Noboa, Lisette and Lemmerich, Florian and Singer, Philipp and Strohmaier, Markus},
doi = {10.1145/2872518.2890468},
eprint = {1601.05274},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Esp{\'{i}}n-Noboa et al. - 2016 - Discovering and Characterizing Mobility Patterns in Urban Spaces A Study of Manhattan Taxi Data.pdf:pdf},
journal = {arXiv preprint},
month = {jan},
title = {{Discovering and Characterizing Mobility Patterns in Urban Spaces: A Study of Manhattan Taxi Data}},
url = {http://arxiv.org/abs/1601.05274},
year = {2016}
}
@article{Fanaee-T2016,
abstract = {Traditional spectral-based methods such as PCA are popular for anomaly detection in a variety of problems and domains. However, if data includes tensor (multiway) structure (e.g. space-time-measurements), some meaningful anomalies may remain invisible with these methods. Although tensor-based anomaly detection (TAD) has been applied within a variety of disciplines over the last twenty years, it is not yet recognized as a formal category in anomaly detection. This survey aims to highlight the potential of tensor-based techniques as a novel approach for detection and identification of abnormalities and failures. We survey the interdisciplinary works in which TAD is reported and characterize the learning the strategies, methods and applications; extract the important open issues in TAD and provide the corresponding existing solutions according to the state-of-the-art.},
author = {Fanaee-T, Hadi and Gama, Joao},
doi = {10.1016/j.knosys.2016.01.027},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fanaee-T, Gama - 2016 - Tensor-based anomaly detection An interdisciplinary survey.pdf:pdf},
issn = {09507051},
journal = {Knowledge-Based Systems},
keywords = {Anomaly detection,Multiway data,Tensor analysis,Tensor decomposition,Tensorial learning},
month = {feb},
title = {{Tensor-based anomaly detection: An interdisciplinary survey}},
url = {http://www.sciencedirect.com/science/article/pii/S0950705116000472},
year = {2016}
}
@article{Figueiredo2014,
abstract = {The performance of household electrical seasonal consumption disaggregation is explored in this paper. Firstly, given a tensor composed by the data for the several devices in the house, non-negative tensor factorization is performed in order to extract the most relevant components. Secondly, the outcome is embedded in the test step, where only the whole-home measured consumption is available. Lastly, the disaggregated data by device is obtained by factorizing the associated matrix regarding the learned model. This source separation approach thus requires prior data, needed to learn the source models. Nevertheless, the consumer behaviors vary along time particularly from season to season, and hence also the electrical consumption. Consequently, the assessment of performance at long-term and across different times of the year is essential.We evaluate the performance of load disaggregation by this supervised method along several years and across seasons. Towards this end, computational experiments were yielded using real-world data from a household electrical consumption measurements along several years. The analysis of the computational results illustrates the adequacy of the method for handling the shifts between seasons.},
author = {Figueiredo, M},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Figueiredo - 2014 - Exploring the performance of non-negative multi-way factorization for household electrical seasonal consumption disa.pdf:pdf},
journal = {Neural Networks (IJCNN) {\ldots}},
title = {{Exploring the performance of non-negative multi-way factorization for household electrical seasonal consumption disaggregation}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=6889809},
year = {2014}
}
@misc{Fitzgerald2006,
abstract = {Recently, non-negative matrix factor 2D deconvolution was developed as a means of separating harmonic instruments from single channel mixtures. This technique uses a model which is convolutive in both time and frequency, and so can capture instruments which have both time-varying spectra and time-varying fundamental frequencies simultaneously. However, in many cases two or more channels are available, in which case it would be advantageous to have a multi-channel version of the algorithm. To this end, a shifted 2D non-negative tensor factorisation algorithm is derived, which extends non-negative matrix factor 2D deconvolution to the multi-channel case. The use of this algorithm for multi-channel sound source separation of pitched instruments is demonstrated},
annote = {Single source audio separation by NMF or NTF},
author = {Fitzgerald, D. and Cranitch, M. and Coyle, E.},
booktitle = {Irish Signals and Systems Conference, 2006. IET},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fitzgerald, Cranitch, Coyle - 2006 - Shifted 2D Non-negative Tensor Factorisation.pdf:pdf},
keywords = {2D nonnegative tensor factorization,Non-negative tensor factorisation,acoustic signal processing,deconvolution,matrix algebra,matrix factor,multichannel sound source separation,musical instruments,pitched instruments,sound source separation,source separation,tensors,time-varying spectra,time-varying systems},
pages = {509--513},
shorttitle = {Irish Signals and Systems Conference, 2006. IET},
title = {{Shifted 2D Non-negative Tensor Factorisation}},
year = {2006}
}
@inproceedings{Flatz2014,
author = {Flatz, M and Vajtersic, M},
booktitle = {International Conference on High Performance Computing {\&} Simulation (HPCS), 2014},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Flatz, Vajtersic - 2014 - Parallel nonnegative tensor factorization via newton iteration on matrices.pdf:pdf},
keywords = {tensor},
mendeley-tags = {tensor},
title = {{Parallel nonnegative tensor factorization via newton iteration on matrices}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=6903803},
year = {2014}
}
@inproceedings{Flatz2014a,
author = {Flatz, Markus and Vajtersic, Marian},
booktitle = {2014 International Conference on High Performance Computing {\&} Simulation (HPCS)},
doi = {10.1109/HPCSim.2014.6903803},
isbn = {978-1-4799-5313-4},
keywords = {Algorithm design and analysis,Computers,Data analysis,Educational institutions,Jacobian matrices,Matrix decomposition,NMF,NMF algorithm,Newton iteration,Newton method,Tensile stress,matricization,matrix decomposition,nonnegative matrix factorization,parallel algorithms,parallel design,parallel nonnegative tensor factorization,second-order tensors,tensors},
language = {English},
month = {jul},
pages = {1014--1015},
publisher = {IEEE},
title = {{Parallel nonnegative tensor factorization via newton iteration on matrices}},
url = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=6903803},
year = {2014}
}
@article{Fleury2010,
abstract = {By 2050, about one third of the French population will be over 65. Our laboratory's current research focuses on the monitoring of elderly people at home, to detect a loss of autonomy as early as possible. Our aim is to quantify criteria such as the international activities of daily living (ADL) or the French Autonomie Gerontologie Groupes Iso-Ressources (AGGIR) scales, by automatically classifying the different ADL performed by the subject during the day. A Health Smart Home is used for this. Our Health Smart Home includes, in a real flat, infrared presence sensors (location), door contacts (to control the use of some facilities), temperature and hygrometry sensor in the bathroom, and microphones (sound classification and speech recognition). A wearable kinematic sensor also informs postural transitions (using pattern recognition) and walk periods (frequency analysis). This data collected from the various sensors are then used to classify each temporal frame into one of the ADL that was previously acquired (seven activities: hygiene, toilet use, eating, resting, sleeping, communication, and dressing/undressing). This is done using support vector machines. We performed a 1-h experimentation with 13 young and healthy subjects to determine the models of the different activities, and then we tested the classification algorithm (cross validation) with real data.},
author = {Fleury, Anthony and Vacher, Michel and Noury, Norbert},
doi = {10.1109/TITB.2009.2037317},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fleury, Vacher, Noury - 2010 - SVM-based multimodal classification of activities of daily living in Health Smart Homes sensors, algorith.pdf:pdf},
issn = {1558-0032},
journal = {IEEE transactions on information technology in biomedicine : a publication of the IEEE Engineering in Medicine and Biology Society},
keywords = {Activities of Daily Living,Activities of Daily Living: classification,Adult,Algorithms,Automated,Automated: methods,Bayes Theorem,Biomechanical Phenomena,Biomechanical Phenomena: physiology,Female,Humans,Male,Monitoring,Neural Networks (Computer),Pattern Recognition,Physiologic,Physiologic: instrumentation,Physiologic: methods,Reproducibility of Results},
month = {mar},
number = {2},
pages = {274--83},
pmid = {20007037},
shorttitle = {Information Technology in Biomedicine, IEEE Transa},
title = {{SVM-based multimodal classification of activities of daily living in Health Smart Homes: sensors, algorithms, and first experimental results.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20007037},
volume = {14},
year = {2010}
}
@article{Frolov2016,
abstract = {A substantial progress in development of new and efficient tensor factorization techniques has led to an extensive research of their applicability in recommender systems field. Tensor-based recommender models push the boundaries of traditional collaborative filtering techniques by taking into account a multifaceted nature of real environments, which allows to produce more accurate, situational (e.g. context-aware, criteria-driven) recommendations. Despite the promising results, tensor-based methods are poorly covered in existing recommender systems surveys. This survey aims to complement previous works and provide a comprehensive overview on the subject. To the best of our knowledge, this is the first attempt to consolidate studies from various application domains in an easily readable, digestible format, which helps to get a notion of the current state of the field. We also provide a high level discussion of the future perspectives and directions for further improvement of tensor-based recommendation systems.},
annote = {Survey of tensors methods applied to recommendation systems},
archivePrefix = {arXiv},
arxivId = {1603.06038},
author = {Frolov, Evgeny and Oseledets, Ivan},
eprint = {1603.06038},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Frolov, Oseledets - 2016 - Tensor Methods and Recommender Systems.pdf:pdf},
month = {mar},
pages = {41},
title = {{Tensor Methods and Recommender Systems}},
url = {http://arxiv.org/abs/1603.06038},
year = {2016}
}
@article{Garcia-Duran2016,
author = {Garcia-Duran, Alberto and Bordes, Antoine and Usunier, Nicolas and Grandvalet, Yves},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Garcia-Duran et al. - 2016 - Combining Two and Three-Way Embedding Models for Link Prediction in Knowledge Bases.pdf:pdf},
issn = {1076 - 9757},
journal = {Journal of Artificial Intelligence Research},
pages = {715--742},
title = {{Combining Two and Three-Way Embedding Models for Link Prediction in Knowledge Bases}},
url = {http://www.jair.org/papers/paper5013.html},
volume = {55},
year = {2016}
}
@article{Geng2011,
abstract = {Multilinear subspace analysis (MSA) is a promising methodology for pattern-recognition problems due to its ability in decomposing the data formed from the interaction of multiple factors. The MSA requires a large training set, which is well organized in a single tensor, which consists of data samples with all possible combinations of the contributory factors. However, such a "complete" training set is difficult (or impossible) to obtain in many real applications. The missing-value problem is therefore crucial to the practicality of the MSA but has been hardly investigated up to present. To solve the problem, this paper proposes an algorithm named M(2)SA, which is advantageous in real applications due to the following: 1) it inherits the ability of the MSA to decompose the interlaced semantic factors; 2) it does not depend on any assumptions on the data distribution; and 3) it can deal with a high percentage of missing values. M(2)SA is evaluated by face image modeling on two typical multifactorial applications, i.e., face recognition and facial age estimation. Experimental results show the effectiveness of M(2) SA even when the majority of the values in the training tensor are missing.},
author = {Geng, Xin and Smith-Miles, Kate and Zhou, Zhi-Hua and Wang, Liang},
doi = {10.1109/TSMCB.2010.2097588},
issn = {1941-0492},
journal = {IEEE transactions on systems, man, and cybernetics. Part B, Cybernetics : a publication of the IEEE Systems, Man, and Cybernetics Society},
keywords = {Algorithms,Artificial Intelligence,Biometry,Biometry: methods,Computer Simulation,Face,Face: anatomy {\&} histology,Humans,Image Enhancement,Image Enhancement: methods,Image Interpretation, Computer-Assisted,Image Interpretation, Computer-Assisted: methods,Models, Biological,Pattern Recognition, Automated,Pattern Recognition, Automated: methods,Reproducibility of Results,Sensitivity and Specificity},
language = {English},
month = {jun},
number = {3},
pages = {881--92},
pmid = {21193381},
publisher = {IEEE},
title = {{Face image modeling by multilinear subspace analysis with missing values.}},
url = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=5678656},
volume = {41},
year = {2011}
}
@article{Ghoshdastidar2016,
abstract = {Graph partitioning plays a central role in machine learning, and the development of graph partitioning algorithms is still an active area of research. The immense demand for such algorithms arises due to the abundance of applications that involve pairwise interactions or similarities among entities. Recent studies in computer vision and databases systems have emphasized on the necessity of considering multi-way interactions, and has led to the study of a more general problem in the form of hypergraph partitioning.   This paper focuses on the problem of partitioning uniform hypergraphs, which arises in computer vision applications such as subspace clustering, motion segmentation etc. We show that uniform hypergraph partitioning is equivalent to a tensor trace maximization problem, and hence, a tensor based method is a natural answer to this problem. We also propose a tensor spectral method that extends the widely known spectral clustering algorithm to the case of uniform hypergraphs. While the theoretical guarantees of spectral clustering have been extensively studied, very little is known about the statistical properties of tensor based methods. To this end, we prove the consistency of the proposed algorithm under a planted partition model.   The computational complexity of tensorial approaches has resulted in the use of various tensor sampling strategies. We present the first theoretical study on the effect of sampling in tensor based hypergraph partitioning. Our result justifies the empirical success of iterative sampling techniques often used in practice. We also present an iteratively sampled variant of the proposed algorithm for the purpose of subspace clustering, and demonstrate the performance of this method on a benchmark problem.},
archivePrefix = {arXiv},
arxivId = {1602.06516},
author = {Ghoshdastidar, Debarghya and Dukkipati, Ambedkar},
eprint = {1602.06516},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ghoshdastidar, Dukkipati - 2016 - Uniform Hypergraph Partitioning Provable Tensor Methods and Sampling Techniques.pdf:pdf},
month = {feb},
pages = {31},
title = {{Uniform Hypergraph Partitioning: Provable Tensor Methods and Sampling Techniques}},
url = {http://arxiv.org/abs/1602.06516},
year = {2016}
}
@article{Gomez-Chova2015,
abstract = {Earth observation through remote sensing images allows the accurate characterization and identification of materials on the surface from space and airborne platforms. Multiple and heterogeneous image sources can be available for the same geographical region: multispectral, hyperspectral, radar, multitemporal, and multiangular images can today be acquired over a given scene. These sources can be combined/fused to improve classification of the materials on the surface. Even if this type of systems is generally accurate, the field is about to face new challenges: the upcoming constellations of satellite sensors will acquire large amounts of images of different spatial, spectral, angular, and temporal resolutions. In this scenario, multimodal image fusion stands out as the appropriate framework to address these problems. In this paper, we provide a taxonomical view of the field and review the current methodologies for multimodal classification of remote sensing images. We also highlight the most recent advances, which exploit synergies with machine learning and signal processing: sparse methods, kernel-based fusion, Markov modeling, and manifold alignment. Then, we illustrate the different approaches in seven challenging remote sensing applications: 1) multiresolution fusion for multispectral image classification; 2) image downscaling as a form of multitemporal image fusion and multidimensional interpolation among sensors of different spatial, spectral, and temporal resolutions; 3) multiangular image classification; 4) multisensor image fusion exploiting physically-based feature extractions; 5) multitemporal image classification of land covers in incomplete, inconsistent, and vague image sources; 6) spatiospectral multisensor fusion of optical and radar images for change detection; and 7) cross-sensor adaptation of classifiers. The adoption of these techniques in operational settings will help to monitor our planet from space in the very near future.},
annote = {remote sensing images},
author = {Gomez-Chova, Luis and Tuia, Devis and Moser, Gabriele and Camps-Valls, Gustau},
doi = {10.1109/JPROC.2015.2449668},
issn = {0018-9219},
journal = {Proceedings of the IEEE},
keywords = {Classification,Earth observation,Image fusion,Markov modeling,Remote sensing,Satellites,Sensors,Spatial resolution,Synthetic aperture radar,airborne platforms,fusion,geophysical image processing,geophysical techniques,heterogeneous image sources,image classification,image fusion,image multimodal classification,kernel-based fusion,machine learning,manifold alignment,material characterization,material classification,material identification,multiangular,multidimensional interpolation,multimodal image analysis,multimodal image fusion,multiresolution fusion,multisource,multispectral image classification,multitemporal,multitemporal image fusion,optical images,radar images,remote sensing,remote sensing image,satellite sensors,signal processing,space platforms,sparse methods},
month = {sep},
number = {9},
pages = {1560--1584},
shorttitle = {Proceedings of the IEEE},
title = {{Multimodal Classification of Remote Sensing Images: A Review and Future Directions}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7182258},
volume = {103},
year = {2015}
}
@inproceedings{Gong2016,
author = {Gong, Changfei and Zeng, Dong and Bian, Zhaoying and Huang, Jing and Zhang, Xinyu and Zhang, Hua and Lu, Lijun and Feng, Qianjin and Liang, Zhengrong and Ma, Jianhua},
booktitle = {SPIE Medical Imaging},
doi = {10.1117/12.2217351},
editor = {Kontos, Despina and Flohr, Thomas G. and Lo, Joseph Y.},
month = {mar},
pages = {97833D},
publisher = {International Society for Optics and Photonics},
title = {{Robust dynamic myocardial perfusion CT deconvolution using adaptive-weighted tensor total variation regularization}},
url = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?articleid=2511254},
year = {2016}
}
@article{Gonzalez2011,
author = {Gonz{\'{a}}lez, FA and Caicedo, JC},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gonz{\'{a}}lez, Caicedo - 2011 - Quantum latent semantic analysis.pdf:pdf},
journal = {Advances in Information Retrieval Theory},
keywords = {quantum},
mendeley-tags = {quantum},
title = {{Quantum latent semantic analysis}},
url = {http://link.springer.com/chapter/10.1007/978-3-642-23318-0{\_}7},
year = {2011}
}
@article{Goodfellow2015,
abstract = {The ICML 2013 Workshop on Challenges in Representation Learning(1) focused on three challenges: the black box learning challenge, the facial expression recognition challenge, and the multimodal learning challenge. We describe the datasets created for these challenges and summarize the results of the competitions. We provide suggestions for organizers of future challenges and some comments on what kind of knowledge can be gained from machine learning competitions.},
annote = {ICML 2013 workshop on challenges in representaiton learning. Three challenges one of them the multimodal learning challenge.},
author = {Goodfellow, Ian J and Erhan, Dumitru and {Luc Carrier}, Pierre and Courville, Aaron and Mirza, Mehdi and Hamner, Ben and Cukierski, Will and Tang, Yichuan and Thaler, David and Lee, Dong-Hyun and Zhou, Yingbo and Ramaiah, Chetan and Feng, Fangxiang and Li, Ruifan and Wang, Xiaojie and Athanasakis, Dimitris and Shawe-Taylor, John and Milakov, Maxim and Park, John and Ionescu, Radu and Popescu, Marius and Grozea, Cristian and Bergstra, James and Xie, Jingjing and Romaszko, Lukasz and Xu, Bing and Chuang, Zhang and Bengio, Yoshua},
doi = {10.1016/j.neunet.2014.09.005},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Goodfellow et al. - 2015 - Challenges in representation learning a report on three machine learning contests.pdf:pdf},
issn = {1879-2782},
journal = {Neural networks : the official journal of the International Neural Network Society},
keywords = {Algorithms,Artificial Intelligence,Biometric Identification,Biometric Identification: methods,Humans},
month = {apr},
pages = {59--63},
pmid = {25613956},
title = {{Challenges in representation learning: a report on three machine learning contests.}},
url = {http://www.sciencedirect.com/science/article/pii/S0893608014002159},
volume = {64},
year = {2015}
}
@inproceedings{Guillaumin2010,
abstract = {In image categorization the goal is to decide if an image belongs to a certain category or not. A binary classifier can be learned from manually labeled images; while using more labeled examples improves performance, obtaining the image labels is a time consuming process. We are interested in how other sources of information can aid the learning process given a fixed amount of labeled images. In particular, we consider a scenario where keywords are associated with the training images, e.g. as found on photo sharing websites. The goal is to learn a classifier for images alone, but we will use the keywords associated with labeled and unlabeled images to improve the classifier using semi-supervised learning. We first learn a strong Multiple Kernel Learning (MKL) classifier using both the image content and keywords, and use it to score unlabeled images. We then learn classifiers on visual features only, either support vector machines (SVM) or least-squares regression (LSR), from the MKL output values on both the labeled and unlabeled images. In our experiments on 20 classes from the PASCAL VOC'07 set and 38 from the MIR Flickr set, we demonstrate the benefit of our semi-supervised approach over only using the labeled images. We also present results for a scenario where we do not use any manual labeling but directly learn classifiers from the image tags. The semi-supervised approach also improves classification accuracy in this case.},
author = {Guillaumin, Matthieu and Verbeek, Jakob and Schmid, Cordelia},
booktitle = {2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2010.5540120},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Guillaumin, Verbeek, Schmid - 2010 - Multimodal semi-supervised learning for image classification.pdf:pdf},
isbn = {978-1-4244-6984-0},
issn = {1063-6919},
keywords = {Airplanes,Airports,Clouds,Image classification,Information resources,Kernel,Labeling,Semisupervised learning,Support vector machine classification,Support vector machines,binary classifier,image categorization,image classification,image content,keywords,labeled images,learning (artificial intelligence),least-squares regression,multimodal semi-supervised learning,multiple kernel learning classifier,regression analysis,support vector machines},
month = {jun},
pages = {902--909},
publisher = {IEEE},
shorttitle = {Computer Vision and Pattern Recognition (CVPR), 20},
title = {{Multimodal semi-supervised learning for image classification}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5540120},
year = {2010}
}
@inproceedings{Haeffele2014,
author = {Haeffele, Benjamin and Young, Eric and Vidal, Rene},
booktitle = {Proceedings of the 31st International Conference on Machine Learning (ICML-14)},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Haeffele, Young, Vidal - 2014 - Structured Low-Rank Matrix Factorization Optimality, Algorithm, and Applications to Image Processing.pdf:pdf},
pages = {2007--2015},
title = {{Structured Low-Rank Matrix Factorization: Optimality, Algorithm, and Applications to Image Processing}},
url = {http://machinelearning.wustl.edu/mlpapers/papers/icml2014c2{\_}haeffele14},
year = {2014}
}
@article{Han2016,
abstract = {We propose a general technique for obtaining sparse solutions to generalized eigenvalue problems, and call it Regularized Generalized Eigen-Decomposition (RGED). For decades, Fisher׳s discriminant criterion has been applied in supervised feature extraction and discriminant analysis, and it is formulated as a generalized eigenvalue problem. Thus RGED can be applied to effectively extract sparse features and calculate sparse discriminant directions for all variants of Fisher discriminant criterion based models. Particularly, RGED can be applied to matrix-based and even tensor-based discriminant techniques, for instance, 2D-Linear Discriminant Analysis (2D-LDA). Furthermore, an iterative algorithm based on the alternating direction method of multipliers is developed. The algorithm approximately solves RGED with monotonically decreasing convergence and at an acceptable speed for results of modest accuracy. Numerical experiments based on four data sets of different types of images show that RGED has competitive classification performance with existing multidimensional and sparse techniques of discriminant analysis.},
author = {Han, Xixuan and Clemmensen, Line},
doi = {10.1016/j.patcog.2015.07.008},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Han, Clemmensen - 2016 - Regularized generalized eigen-decomposition with applications to sparse supervised feature extraction and spars.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Regularized generalized eigen-decomposition,Sparse 2D-LDA,Sparse 3D-LDA,Sparse discriminant analysis,Sparse supervised feature extraction},
month = {jan},
pages = {43--54},
title = {{Regularized generalized eigen-decomposition with applications to sparse supervised feature extraction and sparse discriminant analysis}},
url = {http://www.sciencedirect.com/science/article/pii/S003132031500268X},
volume = {49},
year = {2016}
}
@article{Hansen2015,
abstract = {Tensor factorizations with nonnegativity constraints have found application in analysing data from cyber traffic, social networks, and other areas. We consider application data best described as being generated by a Poisson process (e.g. count data), which leads to sparse tensors that can be modelled by sparse factor matrices. In this paper, we investigate efficient techniques for computing an appropriate canonical polyadic tensor factorization based on the Kullback–Leibler divergence function. We propose novel subproblem solvers within the standard alternating block variable approach. Our new methods exploit structure and reformulate the optimization problem as small independent subproblems. We employ bound-constrained Newton and quasi-Newton methods. We compare our algorithms against other codes, demonstrating superior speed for high accuracy results and the ability to quickly find sparse solutions.},
author = {Hansen, Samantha and Plantenga, Todd and Kolda, Tamara G.},
doi = {10.1080/10556788.2015.1009977},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hansen, Plantenga, Kolda - 2015 - Newton-based optimization for Kullback–Leibler nonnegative tensor factorizations.pdf:pdf},
issn = {1055-6788},
journal = {Optimization Methods and Software},
keywords = {Kullback–Leibler,multilinear algebra,nonlinear optimization,optimization,poisson,tensor factorization},
language = {en},
mendeley-tags = {optimization},
month = {apr},
number = {5},
pages = {1002--1029},
publisher = {Taylor {\&} Francis},
title = {{Newton-based optimization for Kullback–Leibler nonnegative tensor factorizations}},
url = {http://www.tandfonline.com/doi/abs/10.1080/10556788.2015.1009977},
volume = {30},
year = {2015}
}
@incollection{Hao2014,
address = {Berlin, Heidelberg},
author = {Hao, N. and Horesh, L. and Kilmer, M. E.},
booktitle = {COMPRESSED SENSING {\&} SPARSE FILTERING},
chapter = {5},
doi = {10.1007/978-3-642-38398-4},
editor = {Carmi, Avishy Y. and Mihaylova, Lyudmila and Godsill, Simon J.},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hao, Horesh, Kilmer - 2014 - Nonnegative Tensor Decomposition.pdf:pdf},
isbn = {978-3-642-38397-7},
keywords = {NTD},
mendeley-tags = {NTD},
publisher = {Springer Berlin Heidelberg},
series = {Signals and Communication Technology},
title = {{Nonnegative Tensor Decomposition}},
url = {http://link.springer.com/10.1007/978-3-642-38398-4},
year = {2014}
}
@article{Hardoon2009,
author = {Hardoon, David R. and Shawe-Taylor, John},
doi = {10.1007/s10994-009-5159-x},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hardoon, Shawe-Taylor - 2009 - Decomposing the tensor kernel support vector machine for neuroscience data with structured labels.pdf:pdf},
issn = {0885-6125},
journal = {Machine Learning},
keywords = {kernel,tensor},
mendeley-tags = {kernel,tensor},
month = {dec},
number = {1-2},
pages = {29--46},
title = {{Decomposing the tensor kernel support vector machine for neuroscience data with structured labels}},
url = {http://link.springer.com/10.1007/s10994-009-5159-x},
volume = {79},
year = {2009}
}
@article{Harshman1970,
author = {Harshman, RA},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Harshman - 1970 - Foundations of the PARAFAC procedure Models and conditions for an explanatory multi-modal factor analysis.pdf:pdf},
journal = {UCLA Working Papers in Phonetics},
title = {{Foundations of the PARAFAC procedure: Models and conditions for an" explanatory" multi-modal factor analysis}},
url = {http://www.psychology.uwo.ca/faculty/harshman/wpppfac0.pdf},
year = {1970}
}
@inproceedings{Hazan2005,
abstract = {We introduce an algorithm for a non-negative 3D tensor factorization for the purpose of establishing a local parts feature decomposition from an object class of images. In the past, such a decomposition was obtained using non-negative matrix factorization (NMF) where images were vectorized before being factored by NMF. A tensor factorization (NTF) on the other hand preserves the 2D representations of images and provides a unique factorization (unlike NMF which is not unique). The resulting "factors" from the NTF factorization are both sparse (like with NMF) but also separable allowing efficient convolution with the test image. Results show a superior decomposition to what an NMF can provide on all fronts - degree of sparsity, lack of ghost residue due to invariant parts and efficiency of coding of around an order of magnitude better. Experiments on using the local parts decomposition for face detection using SVM and Adaboost classifiers demonstrate that the recovered features are discriminatory and highly effective for classification.},
author = {Hazan, T. and Polak, S. and Shashua, A.},
booktitle = {Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1},
doi = {10.1109/ICCV.2005.228},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hazan, Polak, Shashua - 2005 - Sparse image coding using a 3D non-negative tensor factorization.pdf:pdf},
isbn = {0-7695-2334-X},
issn = {1550-5499},
keywords = {3D nonnegative tensor factorization,Adaboost classifier,Computer science,Convolution,Face detection,Face recognition,Filters,Image coding,Independent component analysis,Matrix decomposition,NPARAFAC,Principal component analysis,Tensile stress,face detection,face recognition,feature decomposition,feature extraction,image classification,image coding,image convolution,image object class,image representation,image vector,matrix decomposition,nonnegative matrix factorization,sparse image coding,sparse matrices,support vector machine,support vector machines,tensors,unique factorization},
mendeley-tags = {NPARAFAC},
pages = {50--57 Vol. 1},
publisher = {IEEE},
shorttitle = {Computer Vision, 2005. ICCV 2005. Tenth IEEE Inter},
title = {{Sparse image coding using a 3D non-negative tensor factorization}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1541238},
volume = {1},
year = {2005}
}
@article{Hitchcock1927,
annote = {Seminal paper, the first publishing about tensors},
author = {Hitchcock, Frank L.},
doi = {10.1002/sapm192761164},
issn = {00971421},
journal = {Journal of Mathematics and Physics},
month = {apr},
number = {1-4},
pages = {164--189},
title = {{The Expression of a Tensor or a Polyadic as a Sum of Products}},
url = {http://doi.wiley.com/10.1002/sapm192761164},
volume = {6},
year = {1927}
}
@article{Ho2014,
author = {Ho, JC and Ghosh, J and Sun, J},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ho, Ghosh, Sun - 2014 - Extracting Phenotypes from Patient Claim Records Using Nonnegative Tensor Factorization.pdf:pdf},
journal = {Brain Informatics and Health},
title = {{Extracting Phenotypes from Patient Claim Records Using Nonnegative Tensor Factorization}},
url = {http://link.springer.com/chapter/10.1007/978-3-319-09891-3{\_}14},
year = {2014}
}
@article{Hou2016,
abstract = {In this paper, we investigate the solution of the second-order cone tensor eigenvalue complementarity problem (SOCTEiCP), which is a general framework including matrix eigenvalue complementarity problem and the recently introduced tensor generalized eigenvalue complementarity problem as its special cases. We first show the equivalence of the SOCTEiCP to a particular variational inequality, thereby giving a positive answer that the SOCTEiCP has at least one solution under some reasonable conditions. Then, we formulate the SOCTEiCP as appropriate nonlinear programming problems, which are extremely beneficial for designing reliable solvers to find solutions of the problem under consideration. In particular, we apply the so-called scaling-and-projection method to solve the SOCTEiCP with symmetric tensors and report some preliminary numerical results to verify the reliability of the proposed algorithm.},
archivePrefix = {arXiv},
arxivId = {1603.06413},
author = {Hou, Jiaojiao and Ling, Chen and He, Hongjin},
eprint = {1603.06413},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hou, Ling, He - 2016 - A class of second-order cone eigenvalue complementarity problems for higher-order tensors.pdf:pdf},
month = {mar},
pages = {25},
title = {{A class of second-order cone eigenvalue complementarity problems for higher-order tensors}},
url = {http://arxiv.org/abs/1603.06413},
year = {2016}
}
@article{Houle2012,
author = {Houle, ME and Kashima, H and Nett, M},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Houle, Kashima, Nett - 2012 - Fast similarity computation in factorized tensors.pdf:pdf},
journal = {Similarity Search and Applications},
title = {{Fast similarity computation in factorized tensors}},
url = {http://link.springer.com/chapter/10.1007/978-3-642-32153-5{\_}16},
year = {2012}
}
@article{Hsieh2016,
author = {Hsieh, Chung-Yang and Lin, Wei-Yang},
doi = {10.1007/s11042-016-3407-1},
issn = {1380-7501},
journal = {Multimedia Tools and Applications},
month = {mar},
title = {{Video-based human action and hand gesture recognition by fusing factored matrices of dual tensors}},
url = {http://link.springer.com/10.1007/s11042-016-3407-1},
year = {2016}
}
@article{Hu2015,
abstract = {We present a scalable Bayesian model for low-rank factorization of massive tensors with binary observations. The proposed model has the following key properties: (1) in contrast to the models based on the logistic or probit likelihood, using a zero-truncated Poisson likelihood for binary data allows our model to scale up in the number of $\backslash$emph{\{}ones{\}} in the tensor, which is especially appealing for massive but sparse binary tensors; (2) side-information in form of binary pairwise relationships (e.g., an adjacency network) between objects in any tensor mode can also be leveraged, which can be especially useful in "cold-start" settings; and (3) the model admits simple Bayesian inference via batch, as well as $\backslash$emph{\{}online{\}} MCMC; the latter allows scaling up even for $\backslash$emph{\{}dense{\}} binary data (i.e., when the number of ones in the tensor/network is also massive). In addition, non-negative factor matrices in our model provide easy interpretability, and the tensor rank can be inferred from the data. We evaluate our model on several large-scale real-world binary tensors, achieving excellent computational scalability, and also demonstrate its usefulness in leveraging side-information provided in form of mode-network(s).},
archivePrefix = {arXiv},
arxivId = {1508.04210},
author = {Hu, Changwei and Rai, Piyush and Carin, Lawrence},
eprint = {1508.04210},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hu, Rai, Carin - 2015 - Zero-Truncated Poisson Tensor Factorization for Massive Binary Tensors.pdf:pdf},
keywords = {bayesian},
mendeley-tags = {bayesian},
month = {aug},
title = {{Zero-Truncated Poisson Tensor Factorization for Massive Binary Tensors}},
url = {http://arxiv.org/abs/1508.04210},
year = {2015}
}
@article{Iwasaki2016,
abstract = {In this paper, we propose nonlinear tensor analysis methods: the tensor self-organizing map (TSOM) and the tensor generative topographic mapping (TGTM). TSOM is a straightforward extension of the self-organizing map from high-dimensional data to tensorial data, and TGTM is an extension of the generative topographic map, which provides a theoretical background for TSOM using a probabilistic generative model. These methods are useful tools for analyzing and visualizing tensorial data, especially multimodal relational data. For given n-mode relational data, TSOM and TGTM can simultaneously organize a set of n-topographic maps. Furthermore, they can be used to explore the tensorial data space by interactively visualizing the relationships between modes. We present the TSOM algorithm and a theoretical description from the viewpoint of TGTM. Various TSOM variations and visualization techniques are also described, along with some applications to real relational datasets. Additionally, we attempt to build a comprehensive description of the TSOM family by adapting various data structures.},
author = {Iwasaki, Tohru and Furukawa, Tetsuo},
doi = {10.1016/j.neunet.2016.01.013},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Iwasaki, Furukawa - 2016 - Tensor SOM and tensor GTM Nonlinear tensor analysis by topographic mappings.pdf:pdf},
issn = {08936080},
journal = {Neural Networks},
keywords = {Generative topographic map,Relational data,Self-organizing map,Tensor decomposition},
month = {feb},
title = {{Tensor SOM and tensor GTM: Nonlinear tensor analysis by topographic mappings}},
url = {http://www.sciencedirect.com/science/article/pii/S0893608016000149},
year = {2016}
}
@article{Jiang2016,
abstract = {In [12], Hillar and Lim famously demonstrated that "multilinear (tensor) analogues of many efficiently computable problems in numerical linear algebra are NP-hard". Despite many recent advancements, the state-of-the-art methods for computing such `tensor analogues' still suffer severely from the curse of dimensionality. In this paper we show that the Tucker core of a tensor however, retains many properties of the original tensor, including the CP rank, the border rank, the tensor Schatten quasi norms, and the Z-eigenvalues. Since the core is typically smaller than the original tensor, this property leads to considerable computational advantages, as confirmed by our numerical experiments. In our analysis, we in fact work with a generalized Tucker-like decomposition that can accommodate any full column-rank factorization matrices.},
archivePrefix = {arXiv},
arxivId = {1601.01469},
author = {Jiang, Bo and Yang, Fan and Zhang, Shuzhong},
eprint = {1601.01469},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jiang, Yang, Zhang - 2016 - Tensor and Its Tucker Core the Invariance Relationships.pdf:pdf},
month = {jan},
title = {{Tensor and Its Tucker Core: the Invariance Relationships}},
url = {http://arxiv.org/abs/1601.01469},
year = {2016}
}
@article{Karahan2015,
abstract = {Current high-throughput data acquisition technologies probe dynamical systems with different imaging modalities, generating massive data sets at different spatial and temporal resolutions-posing challenging problems in multimodal data fusion. A case in point is the attempt to parse out the brain structures and networks that underpin human cognitive processes by analysis of different neuroimaging modalities (functional MRI, EEG, NIRS, etc.). We emphasize that the multimodal, multiscale nature of neuroimaging data is well reflected by a multiway (tensor) structure where the underlying processes can be summarized by a relatively small number of components or “atoms.” We introduce Markov-Penrose diagrams-an integration of Bayesian DAG and tensor network notation in order to analyze these models. These diagrams not only clarify matrix and tensor EEG and fMRI time/frequency analysis and inverse problems, but also help understand multimodal fusion via multiway partial least squares and coupled matrix-tensor factorization. We show here, for the first time, that Granger causal analysis of brain networks is a tensor regression problem, thus allowing the atomic decomposition of brain networks. Analysis of EEG and fMRI recordings shows the potential of the methods and suggests their use in other scientific domains.},
author = {Karahan, Esin and Rojas-Lopez, Pedro A. and Bringas-Vega, Maria L. and Valdes-Hernandez, Pedro A. and Valdes-Sosa, Pedro A.},
doi = {10.1109/JPROC.2015.2455028},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Karahan et al. - 2015 - Tensor Analysis and Fusion of Multimodal Brain Images.pdf:pdf},
issn = {0018-9219},
journal = {Proceedings of the IEEE},
keywords = {Autoregressive processes,Bayes methods,Bayesian DAG,Bayesian models,Bayesian statistics,Brain modeling,EEG/fMRI,Electroencephalography,Granger causal analysis,Granger causality,Inverse problems,Markov-Penrose diagram,Multimodal sensors,N-PLS,NIRS,PARAFAC,Probabilistic logic,Tensile stress,bioimage,biomedical MRI,brain network atomic decomposition,brain structure parsing,causality,cognition,coupled matrix-tensor factorization,dynamical system,electroencephalography,fMRI time-frequency analysis,functional MRI,high-throughput data acquisition technology,human cognitive process,image fusion,image resolution,inverse problem,inverse problems,least squares approximations,magnetic resonance imaging,matrix decomposition,matrix-tensor EEG,medical image processing,multidimensional systems,multimodal brain image fusion,multimodal data,multimodal data fusion,multimodal multiscale neuroimaging data,multiway partial least squares,multiway structure,neuroimaging modality analysis,neurophysiology,regression analysis,spatial resolution,spatiotemporal phenomena,temporal resolution,tensor analysis,tensor decomposition,tensor network,tensor network notation,tensor regression problem,tensor structure,tensors,time-frequency analysis},
mendeley-tags = {bioimage},
month = {sep},
number = {9},
pages = {1531--1559},
shorttitle = {Proceedings of the IEEE},
title = {{Tensor Analysis and Fusion of Multimodal Brain Images}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7214360},
volume = {103},
year = {2015}
}
@article{Kasai2016,
abstract = {We propose an online tensor subspace tracking algorithm based on the CP decomposition exploiting the recursive least squares (RLS), dubbed OnLine Low-rank Subspace tracking by TEnsor CP Decomposition (OLSTEC). Numerical evaluations show that the proposed OLSTEC algorithm gives faster convergence per iteration comparing with the state-of-the-art online algorithms.},
archivePrefix = {arXiv},
arxivId = {1602.07067},
author = {Kasai, Hiroyuki},
eprint = {1602.07067},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kasai - 2016 - Online Low-Rank Tensor Subspace Tracking from Incomplete Data by CP Decomposition using Recursive Least Squares.pdf:pdf},
month = {feb},
title = {{Online Low-Rank Tensor Subspace Tracking from Incomplete Data by CP Decomposition using Recursive Least Squares}},
url = {http://arxiv.org/abs/1602.07067},
year = {2016}
}
@article{Kessler2014,
abstract = {MOTIVATION: Estimating a phenotype distribution conditional on a set of discrete-valued predictors is a commonly encountered task. For example, interest may be in how the density of a quantitative trait varies with single nucleotide polymorphisms and patient characteristics. The subset of important predictors is not usually known in advance. This becomes more challenging with a high-dimensional predictor set when there is the possibility of interaction.

RESULTS: We demonstrate a novel non-parametric Bayes method based on a tensor factorization of predictor-dependent weights for Gaussian kernels. The method uses multistage predictor selection for dimension reduction, providing succinct models for the phenotype distribution. The resulting conditional density morphs flexibly with the selected predictors. In a simulation study and an application to molecular epidemiology data, we demonstrate advantages over commonly used methods.},
author = {Kessler, David C and Taylor, Jack A and Dunson, David B},
doi = {10.1093/bioinformatics/btu040},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kessler, Taylor, Dunson - 2014 - Learning phenotype densities conditional on many interacting predictors.pdf:pdf},
issn = {1367-4811},
journal = {Bioinformatics (Oxford, England)},
keywords = {Algorithms,Bayes Theorem,Humans,Phenotype,Polymorphism, Single Nucleotide,kernel,tensor factorization},
mendeley-tags = {kernel,tensor factorization},
month = {jun},
number = {11},
pages = {1562--8},
pmid = {24501099},
title = {{Learning phenotype densities conditional on many interacting predictors.}},
url = {http://bioinformatics.oxfordjournals.org/content/early/2014/02/05/bioinformatics.btu040.short},
volume = {30},
year = {2014}
}
@article{Khoromskaia2014,
author = {Khoromskaia, V},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Khoromskaia - 2014 - Black-box Hartree–Fock solver by tensor numerical methods.pdf:pdf},
journal = {Computational Methods in Applied Mathematics},
keywords = {tensor},
mendeley-tags = {tensor},
title = {{Black-box Hartree–Fock solver by tensor numerical methods}},
url = {http://www.degruyter.com/view/j/cmam.2014.14.issue-1/cmam-2013-0023/cmam-2013-0023.xml},
year = {2014}
}
@article{Khoromskaia2013,
abstract = {In this paper, the problem of efficient grid-based computation of the two-electron integrals (TEI) in a general basis is considered. We introduce the novel multiple tensor factorizations of the TEI unfolding matrix which decrease the computational demands for the evaluation of TEI in several aspects. Using the reduced higher-order SVD the redundancy-free product-basis set is constructed that diminishes dramatically the initial number {\$}O(N{\_}b{\^{}}2){\$} of three-dimensional ({\$}3{\$}D) convolutions, defined over cross products of {\$}N{\_}b{\$} basis functions, to {\$}O(N{\_}b){\$} scaling. The tensor-structured numerical integration with the {\$}3{\$}D Newton convolving kernel is performed in one-dimensional ({\$}1{\$}D) complexity, thus enabling high resolution over fine {\$}3{\$}D Cartesian grids. Furthermore, using the quantized approximation of long vectors ensures the logarithmic storage complexity in the grid size. Finally, we present and analyze two approaches to compute the Cholesky decomposition of the TEI matrix based on two types of precomput...},
author = {Khoromskaia, V. and Khoromskij, B. N. and Schneider, R.},
doi = {10.1137/120884067},
issn = {1064-8275},
journal = {SIAM Journal on Scientific Computing},
keywords = {65F10,65F30,65F50,65N35,Coloumb and exchange matrices,Hartree--Fock equation,kernel,quantized approximation of vectors,reduced higher-order SVD,tensor-structured approximation,truncated Cholesky decomposition,two-electron integrals},
language = {en},
mendeley-tags = {kernel},
month = {apr},
number = {2},
pages = {A987--A1010},
publisher = {Society for Industrial and Applied Mathematics},
title = {{Tensor-Structured Factorized Calculation of Two-Electron Integrals in a General Basis}},
url = {http://epubs.siam.org/doi/abs/10.1137/120884067},
volume = {35},
year = {2013}
}
@article{Khoromskaia2012,
author = {Khoromskaia, Venera and Khoromskij, Boris N. and Schneider, Reinhold},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Khoromskaia, Khoromskij, Schneider - 2012 - Tensor-structured factorized calculation of two-electron integrals in a general basis.pdf:pdf},
keywords = {kernel},
mendeley-tags = {kernel},
month = {may},
title = {{Tensor-structured factorized calculation of two-electron integrals in a general basis}},
url = {http://www.mis.mpg.de/publications/preprints/2012/prepr2012-29.html},
year = {2012}
}
@article{Kilmer2013,
abstract = {Recent work by Kilmer and Martin [Linear Algebra Appl., 435 (2011), pp. 641--658] and Braman [Linear Algebra Appl., 433 (2010), pp. 1241--1253] provides a setting in which the familiar tools of linear algebra can be extended to better understand third-order tensors. Continuing along this vein, this paper investigates further implications including (1) a bilinear operator on the matrices which is nearly an inner product and which leads to definitions for length of matrices, angle between two matrices, and orthogonality of matrices, and (2) the use of t-linear combinations to characterize the range and kernel of a mapping defined by a third-order tensor and the t-product and the quantification of the dimensions of those sets. These theoretical results lead to the study of orthogonal projections as well as an effective Gram--Schmidt process for producing an orthogonal basis of matrices. The theoretical framework also leads us to consider the notion of tensor polynomials and their relation to tensor eigentupl...},
annote = {It references seminal papers in linear algebra.},
author = {Kilmer, Misha E. and Braman, Karen and Hao, Ning and Hoover, Randy C.},
doi = {10.1137/110837711},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kilmer et al. - 2013 - Third-Order Tensors as Operators on Matrices A Theoretical and Computational Framework with Applications in Imagi.pdf:pdf},
issn = {0895-4798},
journal = {SIAM Journal on Matrix Analysis and Applications},
keywords = {15A69,65F30,Krylov methods,eigendecomposition,multidimensional arrays,singular value decomposition,tensor SVD,tensor decomposition},
language = {en},
month = {jan},
number = {1},
pages = {148--172},
publisher = {Society for Industrial and Applied Mathematics},
title = {{Third-Order Tensors as Operators on Matrices: A Theoretical and Computational Framework with Applications in Imaging}},
url = {http://epubs.siam.org/doi/abs/10.1137/110837711},
volume = {34},
year = {2013}
}
@inproceedings{Kim2016,
abstract = {Contextual information has been recognized as an important factor to consider in user-aware Recommendation Systems. Since contextual information can be used as a significant factor in modeling user behavior, various context-aware recommendation methods are proposed. However, the state-of-the-art context modeling methods treat contexts as other dimensions similar to the dimensions of users and items, and cannot extract the special semantic operation of contexts. On the other hand, some works on multi-domain relation prediction can be used for the context-aware recommendation, but they have problems in generating recommendation under a large amount of contextual information. In this paper, we propose the 4-way Tensor, a parallel tensor factorization algorithm, to accelerate the tensor factorization of large datasets to support efficient context-aware recommendations. The basic idea of this algorithm is to partition a tensor into partition and then exploit the inherent parallelism to perform tensor related operations in parallel.},
author = {Kim, Svetlana},
booktitle = {2016 International Conference on Big Data and Smart Computing (BigComp)},
doi = {10.1109/BIGCOMP.2016.7425796},
isbn = {978-1-4673-8796-5},
keywords = {4-way tensor,4-way tensor factorization,Collaboration,Context,Context Awareness,Context modeling,Filtering,Matrix decomposition,PARAFAC,Recommendation system,Sparse matrices,Tensile stress,Tensor Factorization,context-aware recommendations,matrix decomposition,parallel algorithms,parallel tensor factorization algorithm,recommender systems,ubiquitous computing},
month = {jan},
pages = {18--23},
publisher = {IEEE},
shorttitle = {2016 International Conference on Big Data and Smar},
title = {{Architecture of 4-way tensor factorization for context-aware recommendations}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7425796},
year = {2016}
}
@article{Kolda2009,
abstract = {This survey provides an overview of higher-order tensor decompositions, their applications, and available software. A tensor is a multidimensional or N-way array. Decompositions of higher-order tensors (i.e., N-way arrays with {\$}N \backslashgeq 3{\$}) have applications in psycho-metrics, chemometrics, signal processing, numerical linear algebra, computer vision, numerical analysis, data mining, neuroscience, graph analysis, and elsewhere. Two particular tensor decompositions can be considered to be higher-order extensions of the matrix singular value decomposition: CANDECOMP/PARAFAC (CP) decomposes a tensor as a sum of rank-one tensors, and the Tucker decomposition is a higher-order form of principal component analysis. There are many other tensor decompositions, including INDSCAL, PARAFAC2, CANDELINC, DEDICOM, and PARATUCK2 as well as nonnegative variants of all of the above. The N-way Toolbox, Tensor Toolbox, and Multilinear Engine are examples of software packages for working with tensors.},
annote = {Read to background},
author = {Kolda, Tamara G. and Bader, Brett W.},
doi = {10.1137/07070111X},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kolda, Bader - 2009 - Tensor Decompositions and Applications.pdf:pdf},
issn = {0036-1445},
journal = {SIAM Review},
keywords = {15A69,65F99,canonical decomposition (CANDECOMP),higher-order principal components analysis (Tucker,higher-order singular value decomposition (HOSVD),multilinear algebra,multiway arrays,parallel factors (PARAFAC),tensor decompositions},
language = {en},
month = {aug},
number = {3},
pages = {455--500},
publisher = {Society for Industrial and Applied Mathematics},
title = {{Tensor Decompositions and Applications}},
url = {http://epubs.siam.org/doi/abs/10.1137/07070111X},
volume = {51},
year = {2009}
}
@book{Kolda2006,
author = {Kolda, TG},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kolda - 2006 - Multilinear operators for higher-order decompositions.pdf:pdf},
keywords = {tensor},
mendeley-tags = {tensor},
title = {{Multilinear operators for higher-order decompositions}},
url = {http://www.ca.sandia.gov/{~}tgkolda/pubs/pubfiles/SAND2006-2081.pdf},
year = {2006}
}
@article{Koltchinskii2011,
author = {Koltchinskii, Vladimir and Lounici, Karim and Tsybakov, Alexandre B.},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Koltchinskii, Lounici, Tsybakov - 2011 - Nuclear-norm penalization and optimal rates for noisy low-rank matrix completion.pdf:pdf},
issn = {2168-8966},
journal = {The Annals of Statistics},
keywords = {Lasso,Matrix completion,low-rank matrix estimation,noncommutative Bernstein inequality,optimal rate of convergence,recovery of the rank,statistical learning},
language = {EN},
month = {oct},
number = {5},
pages = {2302--2329},
publisher = {Institute of Mathematical Statistics},
title = {{Nuclear-norm penalization and optimal rates for noisy low-rank matrix completion}},
url = {http://projecteuclid.org/euclid.aos/1322663459},
volume = {39},
year = {2011}
}
@article{Krishnamurthy2015,
author = {Krishnamurthy, Akshay},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Krishnamurthy - 2015 - Interactive Algorithms for Unsupervised Machine Learning.pdf:pdf},
keywords = {*LEARNING MACHINES,ALGORITHMS,APPROXIMATION(MATHEMATICS),CLUSTERING,DATA ACQUISITION,EXPERIMENTAL DATA,MATRICES(MATHEMATICS),NETWORK ARCHITECTURE,PROBABILITY,RELATIONAL DATA BASES,SAMPLING,SIMULATION,STATISTICAL ANALYSIS,STATISTICAL INFERENCE,TENSOR ANALYSIS,THESES,TOMOGRAPHY},
month = {jun},
title = {{Interactive Algorithms for Unsupervised Machine Learning}},
url = {http://oai.dtic.mil/oai/oai?verb=getRecord{\&}metadataPrefix=html{\&}identifier=ADA624286},
year = {2015}
}
@article{Kruskal1977,
abstract = {A three-way array X (or three-dimensional matrix) is an array of numbers xijk subscripted by three indices. A triad is a multiplicative array, xijk = aibjck. Analogous to the rank and the row rank of a matrix, we define rank (X) to be the minimum number of triads whose sum is X, and dim1(X) to be the dimensionality of the space of matrices generated by the 1-slabs of X. (Rank and dim1 may not be equal.) We prove several lower bounds on rank. For example, a special case of Theorem 1 is that rank(X)⩾dim1(UX) + rank(XW) − dim1(UXW), where U and W are matrices; this generalizes a matrix theorem of Frobenius. We define the triple product [A, B, C] of three matrices to be the three-way array whose (i, j, k) element is given by ⩞rairbjrckr; in other words, the triple product is the sum of triads formed from the columns of A, B, and C. We prove several sufficient conditions for the factors of a triple product to be essentially unique. For example (see Theorem 4a), suppose [A, B, C] = [Ā, B̄, C̄], and each of the matrices has R columns. Suppose every set of rank (A) columns of A are independent, and similar conditions hold for B and C. Suppose rank (A) + rank (B) + rank (C) ⩾ 2R + 2. Then there exist diagonal matrices $\Lambda$, M, N and a permutation matrix P such that Ā = AP$\Lambda$, B̄ = BPM, C̄ = CPN. Our results have applications to arithmetic complexity theory and to statistical models used in three-way multidimensional scaling.},
annote = {comparing advantage of tensors (multilinear algebra) compared with matrices (linear algebra)},
author = {Kruskal, Joseph B.},
doi = {10.1016/0024-3795(77)90069-6},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kruskal - 1977 - Three-way arrays rank and uniqueness of trilinear decompositions, with application to arithmetic complexity and statist.pdf:pdf},
issn = {00243795},
journal = {Linear Algebra and its Applications},
number = {2},
pages = {95--138},
title = {{Three-way arrays: rank and uniqueness of trilinear decompositions, with application to arithmetic complexity and statistics}},
url = {http://www.sciencedirect.com/science/article/pii/0024379577900696},
volume = {18},
year = {1977}
}
@article{Lahat2015,
abstract = {In various disciplines, information about the same phenomenon can be acquired from different types of detectors, at different conditions, in multiple experiments or subjects, among others. We use the term “modality” for each such acquisition framework. Due to the rich characteristics of natural phenomena, it is rare that a single modality provides complete knowledge of the phenomenon of interest. The increasing availability of several modalities reporting on the same system introduces new degrees of freedom, which raise questions beyond those related to exploiting each modality separately. As we argue, many of these questions, or “challenges,” are common to multiple domains. This paper deals with two key issues: “why we need data fusion” and “how we perform it.” The first issue is motivated by numerous examples in science and technology, followed by a mathematical framework that showcases some of the benefits that data fusion provides. In order to address the second issue, “diversity” is introduced as a key concept, and a number of data-driven solutions based on matrix and tensor decompositions are discussed, emphasizing how they account for diversity across the data sets. The aim of this paper is to provide the reader, regardless of his or her community of origin, with a taste of the vastness of the field, the prospects, and the opportunities that it holds.},
author = {Lahat, Dana and Adali, Tulay and Jutten, Christian},
doi = {10.1109/JPROC.2015.2460697},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lahat, Adali, Jutten - 2015 - Multimodal Data Fusion An Overview of Methods, Challenges, and Prospects.pdf:pdf},
issn = {0018-9219},
journal = {Proceedings of the IEEE},
keywords = {Blind source separation,Data integration,Electroencephalography,Laser radar,Multimodal sensors,Sensors,Synthetic aperture radar,acquisition framework,data acquisition,data diversity,data fusion,data-driven solutions,latent variables,matrix decomposition,modality term,multimodal data fusion,multimodality,multiset data analysis,overview,sensor fusion,tensor decomposition,tensor decompositions,tensors},
month = {sep},
number = {9},
pages = {1449--1477},
shorttitle = {Proceedings of the IEEE},
title = {{Multimodal Data Fusion: An Overview of Methods, Challenges, and Prospects}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7214350},
volume = {103},
year = {2015}
}
@article{Lee2007,
abstract = {In this paper we present a method for continuous EEG classification, where we employ nonnegative tensor factorization (NTF) to determine discriminative spectral features and use the Viterbi algorithm to continuously classify multiple mental tasks. This is an extension of our previous work on the use of nonnegative matrix factorization (NMF) for EEG classification. Numerical experiments with two data sets in BCI competition, confirm the useful behavior of the method for continuous EEG classification.},
author = {Lee, Hyekyoung and Kim, Yong-Deok and Cichocki, Andrzej and Choi, Seungjin},
doi = {10.1142/S0129065707001159},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lee et al. - 2007 - Nonnegative tensor factorization for continuous EEG classification.pdf:pdf},
issn = {0129-0657},
journal = {International journal of neural systems},
keywords = {Algorithms,Biometry,Biometry: methods,Brain,Brain Mapping,Brain: physiology,Computer Simulation,Electroencephalography,Electroencephalography: classification,Humans,NTF,User-Computer Interface,neuroimages},
language = {en},
mendeley-tags = {NTF,neuroimages},
month = {aug},
number = {4},
pages = {305--17},
pmid = {17696294},
publisher = {World Scientific Publishing Company},
title = {{Nonnegative tensor factorization for continuous EEG classification.}},
url = {http://www.worldscientific.com/doi/abs/10.1142/S0129065707001159},
volume = {17},
year = {2007}
}
@article{Lee2015,
abstract = {We propose new algorithms for singular value decomposition (SVD) of large-scale matrices based on a low-rank tensor approximation technique called the tensor train (TT) format. The proposed algorithms can compute a few extreme (i.e., largest or smallest) singular values and corresponding singular vectors for large-scale structured matrices given in a TT format. The computational complexity of the proposed methods scales logarithmically with the matrix size under the assumption that both the matrix and the singular vectors admit approximate low-rank TT decompositions. The proposed methods, which are called the alternating least squares SVD (ALS-SVD) and modified alternating least squares SVD (MALS-SVD), compute the left and right singular vectors approximately through block TT decompositions. A large-scale optimization problem is reduced to sequential small-scale optimization problems, and each core tensor of the block TT decompositions can be updated by applying any standard SVD method. The optimal ranks ...},
author = {Lee, Namgil and Cichocki, Andrzej},
doi = {10.1137/140983410},
issn = {0895-4798},
journal = {SIAM Journal on Matrix Analysis and Applications},
keywords = {(modified) alternating least squares ((M)ALS),15A18,65F15,65F30,curse of dimensionality,low-rank tensor approximation,matrix factorization,matrix product operator,singular value decomposition (SVD),symmetric eigenvalue decomposition (EVD),tensor network,tensor train (TT) decomposition},
language = {en},
month = {jul},
number = {3},
pages = {994--1014},
publisher = {Society for Industrial and Applied Mathematics},
title = {{Estimating a Few Extreme Singular Values and Vectors for Large-Scale Matrices in Tensor Train Format}},
url = {http://epubs.siam.org/doi/abs/10.1137/140983410},
volume = {36},
year = {2015}
}
@article{Li2016a,
abstract = {For a tensor, its minimal Ger{\v{s}}gorin tensor eigenvalue inclusion set is presented. By establishing a sufficient and necessary condition for the elements belonging to this set, we give a sequence of approximation sets and prove that the limit of this sequence is the minimal Ger{\v{s}}gorin tensor eigenvalue inclusion set for an irreducible tensor.},
author = {Li, Chaoqian and Zhang, Chengyi and Li, Yaotang},
doi = {10.1016/j.cam.2016.02.008},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li, Zhang, Li - 2016 - Minimal Ger{\v{s}}gorin tensor eigenvalue inclusion set and its approximation.pdf:pdf},
issn = {03770427},
journal = {Journal of Computational and Applied Mathematics},
keywords = {15A18,15A69,Approximation,Boundary,Minimal Ger{\v{s}}gorin tensor eigenvalue theorem,Tensor eigenvalue},
month = {feb},
title = {{Minimal Ger{\v{s}}gorin tensor eigenvalue inclusion set and its approximation}},
url = {http://www.sciencedirect.com/science/article/pii/S0377042716300553},
year = {2016}
}
@article{Li2016,
abstract = {In this study, we propose a new method for multifocus image fusion by combining with the structure tensors of mixed order differentials and the multiscale neighborhood. In this method, the structure tensor of an integral differential is utilized to detect the high frequency regions and the structure tensor of the fractional differential is used to detect the low frequency regions. To improve the performance of the fusion method, we propose a new focus measure based on the multiscale neighborhood technique to generate the initial fusion decision maps by exploiting the advantages of different scales. Next, based on the multiscale neighborhood technique, a post-processing method is used to update the initial fusion decision maps. During the fusion process, the pixels located in the focused inner regions are selected to produce the fused image. In order to avoid discontinuities in the transition zone between the focused and defocused regions, we propose a new “averaging” scheme based on the fusion decision maps at different scales. Our experimental results demonstrate that the proposed method outperformed the conventional multifocus image fusion methods in terms of both their subjective and objective quality.},
author = {Li, Huafeng and Li, Xiaosong and Yu, Zhengtao and Mao, Cunli},
doi = {10.1016/j.ins.2016.02.030},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li et al. - 2016 - Multifocus image fusion by combining with mixed-order structure tensors and multiscale neighborhood.pdf:pdf},
issn = {00200255},
journal = {Information Sciences},
keywords = {Fractional differential,Multifocus image fusion,Multiscale focus measure,Multiscale neighborhood,Structure tensor},
month = {feb},
title = {{Multifocus image fusion by combining with mixed-order structure tensors and multiscale neighborhood}},
url = {http://www.sciencedirect.com/science/article/pii/S0020025516300950},
year = {2016}
}
@article{Li2015,
abstract = {We study the symmetric outer product for tensors. Specifically, we look at decompositions of a fully (partially) symmetric tensor into a sum of rank-one fully (partially) symmetric tensors. We present an iterative technique for third-order partially symmetric tensors and fourth-order fully and partially symmetric tensors. We include several numerical examples which indicate faster convergence for the new algorithms than for the standard method of alternating least squares.},
author = {Li, Na and Navasca, Carmeliza and Glenn, Christina},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li, Navasca, Glenn - 2015 - Iterative methods for symmetric outer product tensor decomposition.pdf:pdf},
issn = {10689613},
journal = {Electronic Transactions on Numerical Analysis},
keywords = {Factorization of matrices,Multilinear algebra,Tensor products,tensor},
mendeley-tags = {tensor},
pages = {124--139},
publisher = {Kent State University},
title = {{Iterative methods for symmetric outer product tensor decomposition}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84937400505{\&}partnerID=tZOtx3y1},
volume = {44},
year = {2015}
}
@article{Li2016b,
author = {Li, Qing and Chen, Yuanzhu and Jiang, Li Ling and Li, Ping and Chen, Hsinchun},
doi = {10.1145/2838731},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li et al. - 2016 - A Tensor-Based Information Framework for Predicting the Stock Market.pdf:pdf},
issn = {10468188},
journal = {ACM Transactions on Information Systems},
keywords = {Tensor,news,predictive model,social media,stock,trading strategy},
month = {feb},
number = {2},
pages = {1--30},
publisher = {ACM},
title = {{A Tensor-Based Information Framework for Predicting the Stock Market}},
url = {http://dl.acm.org/citation.cfm?id=2891107.2838731},
volume = {34},
year = {2016}
}
@inproceedings{Li2008,
abstract = {In this paper, we propose a new approach for face shape recovery from a single image. A single near infrared (NIR) image is used as the input, and a mapping from the NIR tensor space to 3D tensor space, learned by using statistical learning, is used for the shape recovery. In the learning phase, the two tensor models are constructed for NIR and 3D images respectively, and a canonical correlation analysis (CCA) based multi-variate mapping from NIR to 3D faces is learned from a given training set of NIR-3D face pairs. In the reconstruction phase, given an NIR face image, the depth map is computed directly using the learned mapping with the help of tensor models. Experimental results are provided to evaluate the accuracy and speed of the method. The work provides a practical solution for reliable and fast shape recovery and modeling of 3D objects.},
author = {Li, Stan Z.},
booktitle = {2008 IEEE Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2008.4587341},
isbn = {978-1-4244-2242-5},
issn = {1063-6919},
keywords = {CCA mapping,Face detection,Humans,Image reconstruction,Infrared imaging,Lighting,Magnetic force microscopy,NIR face image,Shape,Surface fitting,Surface reconstruction,Tensile stress,canonical correlation analysis,face recognition,face shape recovery,image reconstruction,multivariate mapping,near infrared image,shape recovery,tensor spaces,tensors},
month = {jun},
pages = {1--7},
publisher = {IEEE},
shorttitle = {Computer Vision and Pattern Recognition, 2008. CVP},
title = {{Face shape recovery from a single image using CCA mapping between tensor spaces}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4587341},
year = {2008}
}
@article{Lian2015,
author = {Lian, W and Rai, P and Salazar, E and Carin, L},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lian et al. - 2015 - Integrating Features and Similarities Flexible Models for Heterogeneous Multiview Data.pdf:pdf},
journal = {AAAI},
title = {{Integrating Features and Similarities: Flexible Models for Heterogeneous Multiview Data.}},
url = {http://people.duke.edu/{~}pr73/recent/mlfsAAAI2015.pdf},
year = {2015}
}
@inproceedings{Liu2016a,
abstract = {Nonlinear model order reduction has always been a challenging but important task in various science and engineering fields. In this paper, a novel symmetric tensor-based order-reduction method (STORM) is presented for simulating large-scale nonlinear systems. The multidimensional data structure of symmetric tensors, as the higher order generalization of symmetric matrices, is utilized for the effective capture of high-order nonlinearities and efficient generation of compact models. Compared to the recent tensor-based nonlinear model order reduction (TNMOR) algorithm [1], STORM shows advantages in two aspects. First, STORM avoids the assumption of the existence of a low-rank tensor approximation. Second, with the use of the symmetric tensor decomposition, STORM allows significantly faster computation and less storage complexity than TNMOR. Numerical experiments demonstrate the superior computational efficiency and accuracy of STORM against existing nonlinear model order reduction methods.},
author = {Liu, Haotian and Batselier, Kim and Kwok, Yu-Kwong and Wong, Ngai},
booktitle = {2016 21st Asia and South Pacific Design Automation Conference (ASP-DAC)},
doi = {10.1109/ASPDAC.2016.7428070},
isbn = {978-1-4673-9569-4},
keywords = {Computational modeling,Integrated circuit modeling,Numerical models,Read only memory,STORM,Storms,Symmetric matrices,Tensile stress,approximation theory,large-scale nonlinear system,low-rank tensor approximation,matrix algebra,multidimensional data structure,nonlinear control systems,nonlinear model order reduction method,reduced order systems,symmetric matrices,symmetric tensor decomposition,tensors},
month = {jan},
pages = {557--562},
publisher = {IEEE},
shorttitle = {2016 21st Asia and South Pacific Design Automation},
title = {{STORM: A nonlinear model order reduction method via symmetric tensor decomposition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7428070},
year = {2016}
}
@article{Liu2013,
abstract = {In this paper, we propose an algorithm to estimate missing values in tensors of visual data. The values can be missing due to problems in the acquisition process or because the user manually identified unwanted outliers. Our algorithm works even with a small amount of samples and it can propagate structure to fill larger missing regions. Our methodology is built on recent studies about matrix completion using the matrix trace norm. The contribution of our paper is to extend the matrix case to the tensor case by proposing the first definition of the trace norm for tensors and then by building a working algorithm. First, we propose a definition for the tensor trace norm that generalizes the established definition of the matrix trace norm. Second, similarly to matrix completion, the tensor completion is formulated as a convex optimization problem. Unfortunately, the straightforward problem extension is significantly harder to solve than the matrix case because of the dependency among multiple constraints. To tackle this problem, we developed three algorithms: simple low rank tensor completion (SiLRTC), fast low rank tensor completion (FaLRTC), and high accuracy low rank tensor completion (HaLRTC). The SiLRTC algorithm is simple to implement and employs a relaxation technique to separate the dependent relationships and uses the block coordinate descent (BCD) method to achieve a globally optimal solution; the FaLRTC algorithm utilizes a smoothing scheme to transform the original nonsmooth problem into a smooth one and can be used to solve a general tensor trace norm minimization problem; the HaLRTC algorithm applies the alternating direction method of multipliers (ADMMs) to our problem. Our experiments show potential applications of our algorithms and the quantitative evaluation indicates that our methods are more accurate and robust than heuristic approaches. The efficiency comparison indicates that FaLTRC and HaLRTC are more efficient than SiLRTC and between FaLRTC an- HaLRTC the former is more efficient to obtain a low accuracy solution and the latter is preferred if a high-accuracy solution is desired.},
annote = {Tensor Completion for Estimating Missing Values in Visual Data},
author = {Liu, Ji and Musialski, Przemyslaw and Wonka, Peter and Ye, Jieping},
doi = {10.1109/TPAMI.2012.39},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu et al. - 2013 - Tensor completion for estimating missing values in visual data.pdf:pdf},
issn = {1939-3539},
journal = {IEEE transactions on pattern analysis and machine intelligence},
keywords = {Artifacts,Artificial Intelligence,Automated,Automated: methods,Computer-Assisted,Computer-Assisted: methods,Image Enhancement,Image Enhancement: methods,Image Interpretation,Pattern Recognition,Sample Size,Signal Processing,Tensor completion},
mendeley-tags = {Tensor completion},
month = {jan},
number = {1},
pages = {208--20},
pmid = {22271823},
shorttitle = {Pattern Analysis and Machine Intelligence, IEEE Tr},
title = {{Tensor completion for estimating missing values in visual data.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22271823},
volume = {35},
year = {2013}
}
@article{Liu2016,
author = {Liu, Qingshan and Wang, Jun and Zeng, Zhigang},
doi = {10.1016/j.neucom.2016.01.085},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu, Wang, Zeng - 2016 - Advances in Intelligent Control and Information Processing.pdf:pdf},
issn = {09252312},
journal = {Neurocomputing},
month = {feb},
title = {{Advances in Intelligent Control and Information Processing}},
url = {http://www.sciencedirect.com/science/article/pii/S092523121600254X},
year = {2016}
}
@inproceedings{Liutkus2014,
abstract = {In this study, we introduce a new framework called Kernel Additive Modelling for audio spectrograms that can be used for multichannel source separation. It assumes that the spectrogram of a source at any time-frequency bin is close to its value in a neighbourhood indicated by a source-specific proximity kernel. The rationale for this model is to easily account for features like periodicity, stability over time or frequency, self-similarity, etc. In many cases, such local dynamics are indeed much more natural to assess than any global model such as a tensor factorization. This framework permits one to use different proximity kernels for different sources and to estimate them blindly using their mixtures only. Estimation is performed using a variant of the kernel backfitting algorithm that allows for multichannel mixtures and permits parallelization. Experimental results on the separation of vocals from musical backgrounds demonstrate the efficiency of the approach.},
author = {Liutkus, Antoine and Rafii, Zafar and Pardo, Bryan and Fitzgerald, Derry and Daudet, Laurent},
booktitle = {2014 4th Joint Workshop on Hands-free Speech Communication and Microphone Arrays (HSCMA)},
doi = {10.1109/HSCMA.2014.6843240},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liutkus et al. - 2014 - Kernel spectrogram models for source separation.pdf:pdf},
isbn = {978-1-4799-3109-5},
keywords = {Conferences,Kernel,Kernel additive modelling,Kernel spectrogram models,Source separation,Spectrogram,Speech,Speech processing,Time-frequency analysis,audio signal processing,audio source separation,audio spectrograms,kernel,kernel backfitting algorithm,multichannel mixtures,multichannel source separation,musical backgrounds,source separation,spatial filtering,spectrogram models,tensor factorization,time-frequency,vocal separation},
mendeley-tags = {kernel},
month = {may},
pages = {6--10},
publisher = {IEEE},
shorttitle = {Hands-free Speech Communication and Microphone Arr},
title = {{Kernel spectrogram models for source separation}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6843240},
year = {2014}
}
@article{Lu2015,
author = {Lu, Shuxia and Wang, Xizhao and Zhang, Guiqiang and Zhou, Xu},
doi = {10.3233/IDA-150743},
issn = {1088467X},
journal = {Intelligent Data Analysis},
keywords = {neural networks},
mendeley-tags = {neural networks},
month = {jul},
number = {4},
pages = {743--760},
publisher = {IOS Press},
title = {{Effective algorithms of the Moore-Penrose inverse matrices for extreme learning machine}},
url = {http://content.iospress.com/articles/intelligent-data-analysis/ida743},
volume = {19},
year = {2015}
}
@article{Lu2016,
abstract = {Nonnegative Matrix Factorization (NMF), which aims at obtaining the nonnegative low-dimensional representation of data, has been received widely attentions. To obtain more effective nonnegative discriminant bases from the original NMF, a novel method called Nonnegative Discriminant Matrix Factorization (NDMF) is proposed for image classification in this paper. NDMF integrates the nonnegative constraint, orthogonality and discriminant information in the objective function. NDMF considers the incoherent information of both factors in standard NMF and is proposed to enhance the discriminant ability of the learned base matrix. NDMF projects the low-dimensional representation of the subspace of the base matrix to regularize the NMF for discriminant subspace learning. Based on the Euclidean distance metric and the generalized Kullback-Leibler (KL) divergence, two kinds of iterative algorithms are presented to solve the optimization problem. The between- and within-class scatter matrices are divided into positive and negative parts for the update rules and the proofs of the convergence are also presented. Extensive experimental results demonstrate the effectiveness of the proposed method in comparison to the state-of-the-art discriminant NMF algorithms.},
author = {Lu, Yuwu and Lai, Zhihui and Xu, Yong and Li, Xuelong and Zhang, David and Yuan, Chun},
doi = {10.1109/TCSVT.2016.2539779},
issn = {1051-8215},
journal = {IEEE Transactions on Circuits and Systems for Video Technology},
keywords = {Convergence,Euclidean distance,Image classification,Image reconstruction,Linear programming,Matrix decomposition,Matrix factorization,Nonnegative matrix factorization,Principal component analysis,discriminative ability,face recognition,maximum margin criterion},
mendeley-tags = {Matrix factorization},
number = {99},
pages = {1--1},
shorttitle = {IEEE Transactions on Circuits and Systems for Vide},
title = {{Nonnegative Discriminant Matrix Factorization}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7428887},
volume = {PP},
year = {2016}
}
@article{Luo2016,
abstract = {Precision medicine initiatives come amid the rapid growth in quantity and variety of biomedical data, which exceeds the capacity of matrix-oriented data representations and many current analysis algorithms. Tensor factorizations extend the matrix view to multiple modalities and support dimensionality reduction methods that identify latent groups of data for meaningful summarization of both features and instances. In this opinion article, we analyze the modest literature on applying tensor factorization to various biomedical fields including genotyping and phenotyping. Based on the cited work including work of our own, we suggest that tensor applications could serve as an effective tool to enable frequent updating of medical knowledge based on the continually growing scientific and clinical evidence. We encourage extensive experimental studies to tackle challenges including design choice of factorizations, integrating temporality and algorithm scalability.},
annote = {Survey in biomedical},
author = {Luo, Yuan and Wang, Fei and Szolovits, Peter},
doi = {10.1093/bib/bbw026},
issn = {1477-4054},
journal = {Briefings in bioinformatics},
month = {mar},
pages = {bbw026--},
pmid = {26994614},
title = {{Tensor factorization toward precision medicine.}},
url = {http://bib.oxfordjournals.org/content/early/2016/03/18/bib.bbw026.abstract},
year = {2016}
}
@article{Mahoney2008,
abstract = {Motivated by numerous applications in which the data may be modeled by a variable subscripted by three or more indices, we develop a tensor-based extension of the matrix CUR decomposition. The tensor-CUR decomposition is most relevant as a data analysis tool when the data consist of one mode that is qualitatively different from the others. In this case, the tensor-CUR decomposition approximately expresses the original data tensor in terms of a basis consisting of underlying subtensors that are actual data elements and thus that have a natural interpretation in terms of the processes generating the data. Assume the data may be modeled as a {\$}(2+1){\$}-tensor, i.e., an {\$}m \backslashtimes n \backslashtimes p{\$} tensor {\$}\backslashmathcal{\{}A{\}}{\$} in which the first two modes are similar and the third is qualitatively different. We refer to each of the p different {\$}m \backslashtimes n{\$} matrices as “slabs” and each of the {\$}mn{\$} different p-vectors as “fibers.” In this case, the tensor-CUR algorithm computes an approximation to the data tensor {\$}\backslashmathcal{\{}A{\}}{\$} t...},
author = {Mahoney, Michael W. and Maggioni, Mauro and Drineas, Petros},
doi = {10.1137/060665336},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mahoney, Maggioni, Drineas - 2008 - Tensor-CUR Decompositions for Tensor-Based Data.pdf:pdf},
issn = {0895-4798},
journal = {SIAM Journal on Matrix Analysis and Applications},
keywords = {15A23,CUR decomposition,hyperspectral imagery,recommendation system,tensor decomposition},
language = {en},
month = {jan},
number = {3},
pages = {957--987},
publisher = {Society for Industrial and Applied Mathematics},
title = {{Tensor-CUR Decompositions for Tensor-Based Data}},
url = {http://epubs.siam.org/doi/abs/10.1137/060665336},
volume = {30},
year = {2008}
}
@article{Martin2013,
abstract = {Operations with tensors, or multiway arrays, are increasingly prevalent in many applications involving multiway data analysis. This paper extends a third-order factorization strategy and tensor operations defined in a recent paper [M. E. Kilmer and C. D. Martin, Linear Algebra Appl., 435 (2011), pp. 641--658] to order-{\$}p{\$} tensors. The extension to order-{\$}p{\$} tensors is explained in a recursive way but for computational speed is implemented directly using the fast Fourier transform. A major motivation for considering factorization strategies for order-{\$}p{\$} tensors is to devise new types of algorithms for general order-{\$}p{\$} tensors which can be used in applications. We conclude with two applications in imaging. The first application is image deblurring, and the second application is video facial recognition. Both applications involve order-4 tensors.},
author = {Martin, Carla D. and Shafer, Richard and LaRue, Betsy},
doi = {10.1137/110841229},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Martin, Shafer, LaRue - 2013 - An Order-{\$}p{\$} Tensor Factorization with Applications in Imaging.pdf:pdf},
issn = {1064-8275},
journal = {SIAM Journal on Scientific Computing},
keywords = {15A69,65F30,multidimensional arrays,multilinear algebra,singular value decomposition,tensor decomposition},
language = {en},
month = {jan},
number = {1},
pages = {A474--A490},
publisher = {Society for Industrial and Applied Mathematics},
title = {{An Order-{\$}p{\$} Tensor Factorization with Applications in Imaging}},
url = {http://epubs.siam.org/doi/abs/10.1137/110841229},
volume = {35},
year = {2013}
}
@inproceedings{Maybank2005,
abstract = {This paper aims to take general tensors as inputs for supervised learning. A supervised tensor learning (STL) framework is established for convex optimization based learning techniques such as support vector machines (SVM) and minimax probability machines (MPM). Within the STL framework, many conventional learning machines can be generalized to take nth-order tensors as inputs. We also study the applications of tensors to learning machine design and feature extraction by linear discriminant analysis (LDA). Our method for tensor based feature extraction is named the tenor rank-one discriminant analysis (TR1DA). These generalized algorithms have several advantages: 1) reduce the curse of dimension problem in machine learning and data mining; 2) avoid the failure to converge; and 3) achieve better separation between the different categories of samples. As an example, we generalize MPM to its STL version, which is named the tensor MPM (TMPM). TMPM learns a series of tensor projections iteratively. It is then evaluated against the original MPM. Our experiments on a binary classification problem show that TMPM significantly outperforms the original MPM.},
author = {Maybank, S.},
booktitle = {Fifth IEEE International Conference on Data Mining (ICDM'05)},
doi = {10.1109/ICDM.2005.139},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Maybank - 2005 - Supervised Tensor Learning.pdf:pdf},
isbn = {0-7695-2278-5},
issn = {1550-4786},
keywords = {Computer science,Data mining,Feature extraction,Linear discriminant analysis,Machine learning,Minimax techniques,Supervised learning,Support vector machine classification,Support vector machines,Tensile stress,convex optimization,data mining,feature extraction,learning (artificial intelligence),learning machine design,linear discriminant analysis,machine learning,minimax probability machines,minimax techniques,statistical analysis,supervised,supervised learning,supervised tensor learning,support vector machines,tenor rank-one discriminant analysis,tensors},
mendeley-tags = {supervised},
pages = {450--457},
publisher = {IEEE},
shorttitle = {Data Mining, Fifth IEEE International Conference o},
title = {{Supervised Tensor Learning}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1565711},
year = {2005}
}
@article{Metzler2015,
abstract = {Tensor factorizations are computationally hard problems, and in particular, are often significantly harder than their matrix counterparts. In case of Boolean tensor factorizations -- where the input tensor and all the factors are required to be binary and we use Boolean algebra -- much of that hardness comes from the possibility of overlapping components. Yet, in many applications we are perfectly happy to partition at least one of the modes. In this paper we investigate what consequences does this partitioning have on the computational complexity of the Boolean tensor factorizations and present a new algorithm for the resulting clustering problem. This algorithm can alternatively be seen as a particularly regularized clustering algorithm that can handle extremely high-dimensional observations. We analyse our algorithms with the goal of maximizing the similarity and argue that this is more meaningful than minimizing the dissimilarity. As a by-product we obtain a PTAS and an efficient 0.828-approximation algorithm for rank-1 binary factorizations. Our algorithm for Boolean tensor clustering achieves high scalability, high similarity, and good generalization to unseen data with both synthetic and real-world data sets.},
archivePrefix = {arXiv},
arxivId = {1501.00696},
author = {Metzler, Saskia and Miettinen, Pauli},
eprint = {1501.00696},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Metzler, Miettinen - 2015 - Clustering Boolean Tensors.pdf:pdf},
month = {jan},
title = {{Clustering Boolean Tensors}},
url = {http://arxiv.org/abs/1501.00696},
year = {2015}
}
@inproceedings{Milosevic2013,
address = {New York, New York, USA},
author = {Milosevic, Bojan and Yang, Jinseok and Verma, Nakul and Tilak, Sameer S. and Zappi, Piero and Farella, Elisabetta and Benini, Luca and {Simunic Rosing}, Tajana},
booktitle = {Proceedings of the 16th ACM international conference on Modeling, analysis {\&} simulation of wireless and mobile systems - MSWiM '13},
doi = {10.1145/2507924.2507953},
isbn = {9781450323536},
keywords = {data recovery,energy management,latent variables,statistical modeling,tensor factorization,wireless sensor networks},
month = {nov},
pages = {247--254},
publisher = {ACM Press},
title = {{Efficient energy management and data recovery in sensor networks using latent variables based tensor factorization}},
url = {http://dl.acm.org/citation.cfm?id=2507924.2507953},
year = {2013}
}
@inproceedings{Moghaddam2012,
abstract = {Online reviews are valuable sources of information for a variety of decision-making processes such as purchasing products. As the number of online reviews is growing rapidly, it becomes increasingly difficult for users to identify those that are helpful. This has motivated research into the problem of identifying high quality and helpful reviews automatically. The current methods assume that the helpfulness of a review is independent from the readers of that review. However, we argue that the quality of a review may not be the same for different users. For example, a professional and an amateur photographer may rate the helpfulness of a review very differently. In this paper, we introduce the problem of predicting a personalized review quality for recommendation of helpful reviews. To address this problem, we propose a series of increasingly sophisticated probabilistic graphical models, based on Matrix Factorization and Tensor Factorization. We evaluate the proposed models using a database of 1.5 million reviews and more than 13 million quality ratings obtained from Epinions.com. The experiments demonstrate that the proposed latent factor models outperform the state-of-theart approaches using textual and social features. Finally, our experiments confirm that the helpfulness of a review is indeed not the same for all users and that there are some latent factors that affect a user's evaluation of the review quality. Copyright 2012 ACM.},
address = {New York, New York, USA},
annote = {Applications},
author = {Moghaddam, Samaneh and Jamali, Mohsen and Ester, Martin},
booktitle = {Proceedings of the fifth ACM international conference on Web search and data mining - WSDM '12},
doi = {10.1145/2124295.2124316},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Moghaddam, Jamali, Ester - 2012 - ETF Extended tensor factorization model for personalizing prediction of review helpfulness.pdf:pdf},
isbn = {9781450307475},
keywords = {matrix factorization,personalized review quality prediction,review recommendation,tensor factorization},
month = {feb},
pages = {163},
publisher = {ACM Press},
title = {{ETF: Extended tensor factorization model for personalizing prediction of review helpfulness}},
url = {http://dl.acm.org/citation.cfm?id=2124295.2124316},
year = {2012}
}
@article{Mørup2011,
annote = {Survey},
author = {M{\o}rup, Morten},
doi = {10.1002/widm.1},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/M{\o}rup - 2011 - Applications of tensor (multiway array) factorizations and decompositions in data mining.pdf:pdf},
issn = {19424787},
journal = {Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery},
month = {jan},
number = {1},
pages = {24--40},
title = {{Applications of tensor (multiway array) factorizations and decompositions in data mining}},
url = {http://doi.wiley.com/10.1002/widm.1},
volume = {1},
year = {2011}
}
@article{Mørup2008,
abstract = {There is a increasing interest in analysis of large-scale multiway data. The concept of multiway data refers to arrays of data with more than two dimensions, that is, taking the form of tensors. To analyze such data, decomposition techniques are widely used. The two most common decompositions for tensors are the Tucker model and the more restricted PARAFAC model. Both models can be viewed as generalizations of the regular factor analysis to data of more than two modalities. Nonnegative matrix factorization (NMF), in conjunction with sparse coding, has recently been given much attention due to its part-based and easy interpretable representation. While NMF has been extended to the PARAFAC model, no such attempt has been done to extend NMF to the Tucker model. However, if the tensor data analyzed are nonnegative, it may well be relevant to consider purely additive (i.e., nonnegative) Tucker decompositions). To reduce ambiguities of this type of decomposition, we develop updates that can impose sparseness in any combination of modalities, hence, proposed algorithms for sparse nonnegative Tucker decompositions (SN-TUCKER). We demonstrate how the proposed algorithms are superior to existing algorithms for Tucker decompositions when the data and interactions can be considered nonnegative. We further illustrate how sparse coding can help identify what model (PARAFAC or Tucker) is more appropriate for the data as well as to select the number of components by turning off excess components. The algorithms for SN-TUCKER can be downloaded from M{\o}rup (2007).},
annote = {NTD},
author = {M{\o}rup, Morten and Hansen, Lars Kai and Arnfred, Sidse M},
doi = {10.1162/neco.2008.11-06-407},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/M{\o}rup, Hansen, Arnfred - 2008 - Algorithms for sparse nonnegative Tucker decompositions.pdf:pdf},
issn = {0899-7667},
journal = {Neural computation},
keywords = {Algorithms,Artificial Intelligence,Brain,Brain: physiology,Computer Simulation,Computer-Assisted,Electroencephalography,Electroencephalography: methods,Humans,NTD,Signal Processing,Software,Statistics as Topic,Statistics as Topic: methods},
language = {en},
mendeley-tags = {NTD},
month = {aug},
number = {8},
pages = {2112--31},
pmid = {18386984},
publisher = {MIT Press 238 Main St., Suite 500, Cambridge, MA 02142-1046 USA journals-info@mit.edu},
title = {{Algorithms for sparse nonnegative Tucker decompositions.}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/neco.2008.11-06-407{\#}.VwZygt9ysbw},
volume = {20},
year = {2008}
}
@article{Motamarri2016,
author = {Motamarri, Phani and Gavini, Vikram and Blesgen, Thomas},
doi = {10.1103/PhysRevB.93.125104},
issn = {2469-9950},
journal = {Physical Review B},
month = {mar},
number = {12},
pages = {125104},
publisher = {American Physical Society},
title = {{Tucker-tensor algorithm for large-scale Kohn-Sham density functional theory calculations}},
url = {http://journals.aps.org/prb/abstract/10.1103/PhysRevB.93.125104},
volume = {93},
year = {2016}
}
@article{Murakami2016,
author = {Murakami, T and Watanabe, H},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Murakami, Watanabe - 2016 - Localization Attacks Using Matrix and Tensor Factorization.pdf:pdf},
title = {{Localization Attacks Using Matrix and Tensor Factorization}},
url = {https://staff.aist.go.jp/takao-murakami/pdf/Murakami{\_}TIFS16.pdf},
year = {2016}
}
@inproceedings{Murakami2014,
abstract = {Recent studies have proposed various attacks against location privacy using a Markov Chain transition matrix trained for each user. However, when a user has disclosed only a small amount of location information in the past, the training data can be extremely sparse. In this paper, we show how the attacker can solve this sparse data problem, and how the defender can defend against this type of attack. Our proposal is twofold: 1) We propose a training method that regards a set of transition matrices as a “tensor”, and adopt tensor factorization to robustly estimate transition matrices from a small amount of training data. 2) We then focus on a location prediction attack, which predicts a location of a target user from a past location that he/she disclosed, and propose a region merging method to minimize the region size as an optimal defense. The experimental results using the dataset of taxi traces show the effectiveness of our proposals. We also point out that our region merging method is effective especially when the defender has Big Data to train transition matrices.},
author = {Murakami, Takao and Watanabe, Hajime},
booktitle = {2014 IEEE International Conference on Big Data (Big Data)},
doi = {10.1109/BigData.2014.7004384},
isbn = {978-1-4799-5666-1},
keywords = {Big Data,Markov Chain,Markov chain transition matrix,Markov processes,Merging,Privacy,Sparse matrices,Tensile stress,Training,Training data,Vectors,data privacy,location information,location prediction,location prediction attacks,location privacy,matrix decomposition,merging,mobile computing,optimal defenses,region merging,region merging method,sparse data problem,taxi traces,tensor factorization,tensors,transition matrices estimation},
month = {oct},
pages = {13--21},
publisher = {IEEE},
shorttitle = {Big Data (Big Data), 2014 IEEE International Confe},
title = {{Location prediction attacks using tensor factorization and optimal defenses}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7004384},
year = {2014}
}
@inproceedings{Musialski2009,
abstract = {In this paper we propose an algorithm to estimate missing values in tensors of visual data. The values can be missing due to problems in the acquisition process, or because the user manually identified unwanted outliers. Our algorithm works even with a small amount of samples and it can propagate structure to fill larger missing regions. Our methodology is built on recent studies about matrix completion using the matrix trace norm. The contribution of our paper is to extend the matrix case to the tensor case by laying out the theoretical foundations and then by building a working algorithm. First, we propose a definition for the tensor trace norm, that generalizes the established definition of the matrix trace norm. Second, similar to matrix completion, the tensor completion is formulated as a convex optimization problem. Unfortunately, the straightforward problem extension is significantly harder to solve than the matrix case because of the dependency among multiple constraints. To tackle this problem, we employ a relaxation technique to separate the dependant relationships and use the block coordinate descent (BCD) method to achieve a globally optimal solution. Our experiments show potential applications of our algorithm and the quantitative evaluation indicates that our method is more accurate and robust than heuristic approaches.},
author = {Musialski, Przemyslaw and Wonka, Peter},
booktitle = {2009 IEEE 12th International Conference on Computer Vision},
doi = {10.1109/ICCV.2009.5459463},
isbn = {978-1-4244-4420-5},
issn = {1550-5499},
keywords = {Buildings,Computer graphics,Computer vision,Heuristic algorithms,Image reconstruction,Iterative algorithms,Iterative decoding,Robustness,State estimation,Tensile stress,tensor completion},
mendeley-tags = {tensor completion},
month = {sep},
pages = {2114--2121},
publisher = {IEEE},
shorttitle = {Computer Vision, 2009 IEEE 12th International Conf},
title = {{Tensor completion for estimating missing values in visual data}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5459463},
year = {2009}
}
@article{Nickel2013,
annote = {Book chapter},
author = {Nickel, M and Tresp, V},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nickel, Tresp - 2013 - An Analysis of Tensor Models for Learning on Structured Data.pdf:pdf;:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nickel, Tresp - 2013 - An Analysis of Tensor Models for Learning on Structured Data(2).pdf:pdf},
journal = {Machine Learning and Knowledge Discovery in {\ldots}},
title = {{An Analysis of Tensor Models for Learning on Structured Data}},
url = {http://link.springer.com/chapter/10.1007/978-3-642-40991-2{\_}18},
year = {2013}
}
@article{Nicolaou2011,
abstract = {Past research in analysis of human affect has focused on recognition of prototypic expressions of six basic emotions based on posed data acquired in laboratory settings. Recently, there has been a shift toward subtle, continuous, and context-specific interpretations of affective displays recorded in naturalistic and real-world settings, and toward multimodal analysis and recognition of human affect. Converging with this shift, this paper presents, to the best of our knowledge, the first approach in the literature that: 1) fuses facial expression, shoulder gesture, and audio cues for dimensional and continuous prediction of emotions in valence and arousal space, 2) compares the performance of two state-of-the-art machine learning techniques applied to the target problem, the bidirectional Long Short-Term Memory neural networks (BLSTM-NNs), and Support Vector Machines for Regression (SVR), and 3) proposes an output-associative fusion framework that incorporates correlations and covariances between the emotion dimensions. Evaluation of the proposed approach has been done using the spontaneous SAL data from four subjects and subject-dependent leave-one-sequence-out cross validation. The experimental results obtained show that: 1) on average, BLSTM-NNs outperform SVR due to their ability to learn past and future context, 2) the proposed output-associative fusion framework outperforms feature-level and model-level fusion by modeling and learning correlations and patterns between the valence and arousal dimensions, and 3) the proposed system is well able to reproduce the valence and arousal ground truth obtained from human coders. {\textcopyright} 2011 IEEE.},
author = {Nicolaou, M. A. and Gunes, H. and Pantic, M.},
doi = {10.1109/T-AFFC.2011.9},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nicolaou, Gunes, Pantic - 2011 - Continuous Prediction of Spontaneous Affect from Multiple Cues and Modalities in Valence-Arousal Space.pdf:pdf},
issn = {1949-3045},
journal = {IEEE Transactions on Affective Computing},
keywords = {Dimensional affect recognition,continuous affect prediction,emotional acoustic signals,facial expressions,multicue and multimodal fusion,output-associative fusion.,shoulder gestures,valence and arousal dimensions},
month = {apr},
number = {2},
pages = {92--105},
title = {{Continuous Prediction of Spontaneous Affect from Multiple Cues and Modalities in Valence-Arousal Space}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-80054842318{\&}partnerID=tZOtx3y1},
volume = {2},
year = {2011}
}
@article{Nielsen2014,
author = {Nielsen, SFV and Morup, M},
journal = {Machine Learning for Signal  {\ldots}},
keywords = {bioinformatics},
mendeley-tags = {bioinformatics},
title = {{Non-negative Tensor Factorization with missing data for the modeling of gene expressions in the Human Brain}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=6958919},
year = {2014}
}
@inproceedings{Ozerov2011,
abstract = {Separating multiple tracks from professionally produced music recordings (PPMRs) is still a challenging problem. We address this task with a user-guided approach in which the separation system is provided segmental information indicating the time activations of the particular instruments to separate. This information may typically be retrieved from manual annotation. We use a so-called multichannel nonnegative tensor factorization (NTF) model, in which the original sources are observed through a multichannel convolutive mixture and in which the source power spectrograms are jointly modeled by a 3-valence (time/frequency/source) tensor. Our user-guided separation method produced competitive results at the 2010 Signal Separation Evaluation Campaign, with sufficient quality for real-world music editing applications.},
author = {Ozerov, Alexey and Fevotte, Cedric and Blouet, Raphael and Durrieu, Jean-Louis},
booktitle = {2011 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
doi = {10.1109/ICASSP.2011.5946389},
isbn = {978-1-4577-0538-0},
issn = {1520-6149},
keywords = {3-valence tensor,Audio source separation,Lead,NTF,Noise,PPMR,Source separation,Spectrogram,Speech,Tensile stress,Time frequency analysis,audio signal processing,audio source separation,convolution,generalized expectation maximization,multichannel NTF model,multichannel convolutive mixture,multichannel nonnegative tensor factorization,multiple track separation,music,nonnegative tensor factorization,professionally produced music recording,real-world music editing application,segmental information,signal processing,source power spectrograms,source separation,structured constraints,tensors,user-guided,user-guided audio source separation,user-guided separation method},
mendeley-tags = {NTF,audio source separation,signal processing},
month = {may},
pages = {257--260},
publisher = {IEEE},
shorttitle = {Acoustics, Speech and Signal Processing (ICASSP), },
title = {{Multichannel nonnegative tensor factorization with structured constraints for user-guided audio source separation}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5946389},
year = {2011}
}
@inproceedings{Paez2014,
abstract = {This paper addresses the problem of searching for videos containing instances of specific human actions. The proposed strategy builds a multimodal latent space representation where both visual content and annotations are simultaneously mapped. The hypothesis behind the method is that such a latent space yields better results when built from multiple data modalities. The semantic embedding is learned using matrix factorization through stochastic gradient descent, which makes it suitable to deal with large-scale collections. The method is evaluated on a large-scale human action video dataset with three modalities corresponding to action labels, action attributes and visual features. The evaluation is based on a query-by-example strategy, where a sample video is used as input to the system. A retrieved video is considered relevant if it contains an instance of the same human action present in the query. Experimental results show that the learned multimodal latent semantic representation produces improved performance when compared with an exclusively visual representation.},
author = {Paez, Fabian and Vanegas, Jorge A. and Gonzalez, Fabio A.},
booktitle = {2014 12th International Workshop on Content-Based Multimedia Indexing (CBMI)},
doi = {10.1109/CBMI.2014.6849823},
isbn = {978-1-4799-3990-9},
keywords = {Histograms,Indexing,Matrix factorization,Semantics,Training,Trajectory,Visualization,action attributes,action labels,annotations,data modalities,gradient methods,human action video dataset,human action video indexing,human actions,image representation,indexing,information retrieval,latent space,learning (artificial intelligence),matrix decomposition,matrix factorization,multimodal data,multimodal latent semantic representation,multimodal latent space representation,online multimodal matrix factorization,query by example,query processing,query-by-example strategy,semantic embedding,stochastic gradient descent,video processing,video signal processing,visual content,visual features,visual representation},
month = {jun},
pages = {1--6},
publisher = {IEEE},
shorttitle = {Content-Based Multimedia Indexing (CBMI), 2014 12t},
title = {{Online multimodal matrix factorization for human action video indexing}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6849823},
year = {2014}
}
@inproceedings{Paez2013,
abstract = {Human action video retrieval is a useful tool for video surveillance and sports video analysis, among other applications. Previous work on image retrieval tasks has shown that latent semantic methods are an effective way to build a high-level representation of data to discover implicit relations between visual patterns, achieving a significant improvement on these tasks. The current paper evaluates the applicability of Non-Negative Matrix Factorization (NMF), a latent semantic method, on human action video retrieval. Experiments are carried out on common human action recognition datasets using state-of-the-art descriptors. We focus on evaluating the query by example approach i.e. only videos are used as queries. The performance of the method is compared against classic direct matching between video features.},
author = {Paez, Fabian and Vanegas, Jorge A. and Gonzalez, Fabio A.},
booktitle = {Symposium of Signals, Images and Artificial Vision - 2013: STSIVA - 2013},
doi = {10.1109/STSIVA.2013.6644926},
isbn = {978-1-4799-1121-9},
keywords = {Context,Feature extraction,Histograms,Indexing,NMF algorithm,Semantics,Visualization,descriptors,human action recognition datasets,human action video retrieval,latent semantic method,matrix decomposition,non-negative matrix factorization,nonnegative matrix factorization,query by example,query by example approach,sports video analysis,video query,video representation,video retrieval,video surveillance},
month = {sep},
pages = {1--4},
publisher = {IEEE},
shorttitle = {Image, Signal Processing, and Artificial Vision (S},
title = {{An evaluation of NMF algorithm on human action video retrieval}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6644926},
year = {2013}
}
@article{Park2007a,
abstract = {Facial images change appearance due to multiple factors such as different poses, lighting variations, and facial expressions. Tensors are higher order extensions of vectors and matrices, which make it possible to analyze different appearance factors of facial variation. Using higher order tensors, we can construct a multilinear structure and model the multiple factors of face variation. In particular, among the appearance factors, the factor of a person's identity modeled by a tensor structure can be used for face recognition. However, this tensor-based face recognition creates difficulty in factorizing the unknown parameters of a new test image and solving for the person-identity parameter. In this paper, to break this limitation of applying the tensor-based methods to face recognition, we propose a novel tensor approach based on an individual-modeling method and nonlinear mappings. The proposed method does not require the problematic tensor factorization and is more efficient than the traditional TensorFaces method with respect to computation and memory. We set up the problem of solving for the unknown factors as a least squares problem with a quadratic equality constraint and solve it using numerical optimization techniques. We show that an individual-multilinear approach reduces the order of the tensor so that it makes face-recognition tasks computationally efficient as well as analytically simpler. We also show that nonlinear kernel mappings can be applied to this optimization problem and provide more accuracy to face-recognition systems than linear mappings. In this paper, we show that the proposed method, individual kernel TensorFaces, produces the better discrimination power for classification. The novelty in our approach as compared to previous work is that the Individual Kernel TensorFaces method does not require estimating any factor of a new test image for face recognition. In addition, we do not need to have any a priori knowledge of or assumption abou- - t the factors of a test image when using the proposed method. We can apply individual kernel TensorFaces even if the factors of a test image are absent from the training set. Based on various experiments on the Carnegie Mellon University Pose, Illumination, and Expression database, we demonstrate that the proposed method produces reliable results for face recognition.},
author = {Park, Sung Won and Savvides, Marios},
doi = {10.1109/TSMCB.2007.904575},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Park, Savvides - 2007 - Individual Kernel Tensor-Subspaces for Robust Face Recognition A Computationally Efficient Tensor Framework With.pdf:pdf},
issn = {1083-4419},
journal = {IEEE Transactions on Systems, Man and Cybernetics, Part B (Cybernetics)},
keywords = {Algorithms,Artificial Intelligence,Automated,Biological,Biometry,Computer Simulation,Computer-Assisted,Constraint optimization,Face,Face recognition,Humans,Image Enhancement,Image Interpretation,Image recognition,Individual Kernel TensorFaces,Information Storage and Retrieval,Kernel,Least squares methods,Lighting,Models,Pattern Recognition,Principal Component Analysis,Principal component analysis,Reproducibility of Results,Robustness,Sensitivity and Specificity,Statistical,Subtraction Technique,Tensile stress,TensorFaces,Testing,face recognition,facial image,facial variation,higher order singular value decomposition,higher order singular value decomposition (HOSVD),individual principal component analysis (PCA),individual-modeling approach,individual-modeling method,individual-multilinear approach,kernel,kernel tensor-subspaces,least squares problem,multilinear analysis,multilinear structure,nonlinear kernel mappings,nonlinear mappings,numerical optimization,principal component analysis,robust face recognition,singular value decomposition,tensors},
mendeley-tags = {kernel},
month = {oct},
number = {5},
pages = {1156--1166},
shorttitle = {IEEE Transactions on Systems, Man, and Cybernetics},
title = {{Individual Kernel Tensor-Subspaces for Robust Face Recognition: A Computationally Efficient Tensor Framework Without Requiring Mode Factorization}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4305285},
volume = {37},
year = {2007}
}
@article{Park2007,
author = {Park, SW and Savvides, M},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Park, Savvides - 2007 - Individual Kernel Tensor-Subspaces for Robust Face Recognition A Computationally Efficient Tensor Framework With.pdf:pdf},
journal = {Systems, Man, and Cybernetics, Part B: {\ldots}},
keywords = {kernel},
mendeley-tags = {kernel},
title = {{Individual kernel tensor-subspaces for robust face recognition: A computationally efficient tensor framework without requiring mode factorization}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=4305285},
year = {2007}
}
@article{Poria2015,
abstract = {An increasingly large amount of multimodal content is posted on social media websites such as YouTube and Facebook everyday. In order to cope with the growth of such so much multimodal data, there is an urgent need to develop an intelligent multi-modal analysis framework that can effectively extract information from multiple modalities. In this paper, we propose a novel multimodal information extraction agent, which infers and aggregates the semantic and affective information associated with user-generated multimodal data in contexts such as e-learning, e-health, automatic video content tagging and human-computer interaction. In particular, the developed intelligent agent adopts an ensemble feature extraction approach by exploiting the joint use of tri-modal (text, audio and video) features to enhance the multimodal information extraction process. In preliminary experiments using the eNTERFACE dataset, our proposed multi-modal system is shown to achieve an accuracy of 87.95{\%}, outperforming the best state-of-the-art system by more than 10{\%}, or in relative terms, a 56{\%} reduction in error rate.},
author = {Poria, Soujanya and Cambria, Erik and Hussain, Amir and Huang, Guang-Bin},
doi = {10.1016/j.neunet.2014.10.005},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Poria et al. - 2015 - Towards an intelligent framework for multimodal affective data analysis.pdf:pdf},
issn = {1879-2782},
journal = {Neural networks : the official journal of the International Neural Network Society},
keywords = {Algorithms,Artificial Intelligence,Biometric Identification,Biometric Identification: methods,Humans,Information Storage and Retrieval,Information Storage and Retrieval: methods},
month = {mar},
pages = {104--16},
pmid = {25523041},
title = {{Towards an intelligent framework for multimodal affective data analysis.}},
url = {http://www.sciencedirect.com/science/article/pii/S0893608014002342},
volume = {63},
year = {2015}
}
@book{Przepiorkowski2014,
address = {Cham},
doi = {10.1007/978-3-319-10888-9},
editor = {Przepi{\'{o}}rkowski, Adam and Ogrodniczuk, Maciej},
isbn = {978-3-319-10887-2},
publisher = {Springer International Publishing},
series = {Lecture Notes in Computer Science},
title = {{Advances in Natural Language Processing}},
url = {http://link.springer.com/10.1007/978-3-319-10888-9},
volume = {8686},
year = {2014}
}
@article{Rabusseau2016,
abstract = {This paper proposes an efficient algorithm (HOLRR) to handle regression tasks where the outputs have a tensor structure. We formulate the regression problem as the minimization of a least square criterion under a multilinear rank constraint, a difficult non convex problem. HOLRR computes efficiently an approximate solution of this problem, with solid theoretical guarantees. A kernel extension is also presented. Experiments on synthetic and real data show that HOLRR outperforms multivariate and multilinear regression methods and is considerably faster than existing tensor methods.},
archivePrefix = {arXiv},
arxivId = {1602.06863},
author = {Rabusseau, Guillaume and Kadri, Hachem},
eprint = {1602.06863},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rabusseau, Kadri - 2016 - Higher-Order Low-Rank Regression.pdf:pdf},
month = {feb},
title = {{Higher-Order Low-Rank Regression}},
url = {http://arxiv.org/abs/1602.06863},
year = {2016}
}
@article{Raimondi2016,
abstract = {The problem of direction of arrival (DoA) estimation of seismic plane waves impinging on an array of sensors is considered from a new deterministic perspective using tensor decomposition techniques. In addition to temporal and spatial sampling, further information is taken into account, based on the different propagation speed of body waves (P and S) through solid media. Performances are evaluated through simulated data in terms of the Cram{\'{e}}r–Rao bounds and compared to other reference methods such as ESPRIT and MUSIC, in the presence of additive Gaussian circular noise. The proposed approach is then applied to real seismic data recorded at the Argenti{\'{e}}re glacier, occurring at the interface between the ice mass and the underlying bedrock. MUSIC and ESPRIT rely on the estimation of the covariance matrix of received data, thus requiring a large number of time samples. Moreover, information about propagation speed diversity is not taken into account by existing models in array processing. The discovered advantage in terms of the average error in estimating the direction of arrival of body waves is noteworthy, especially for a low number of sensors, and in separating closely located sources. Additionally, an improvement of precision in processing real seismic data is observed.},
author = {Raimondi, Francesca and Comon, Pierre and Michel, Olivier and Sahnoun, Souleymen and Helmstetter, Agnes},
doi = {10.1016/j.sigpro.2015.06.015},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Raimondi et al. - 2016 - Tensor decomposition exploiting diversity of propagation velocities Application to localization of icequake eve.pdf:pdf},
issn = {01651684},
journal = {Signal Processing},
keywords = {Antenna array processing,Diversity,DoA estimation,Elastic waves,Seismic,Tensor},
month = {jan},
pages = {75--88},
title = {{Tensor decomposition exploiting diversity of propagation velocities: Application to localization of icequake events}},
url = {http://www.sciencedirect.com/science/article/pii/S0165168415002145},
volume = {118},
year = {2016}
}
@inproceedings{Rendle2010,
address = {New York, New York, USA},
author = {Rendle, Steffen and Schmidt-Thieme, Lars},
booktitle = {Proceedings of the third ACM international conference on Web search and data mining - WSDM '10},
doi = {10.1145/1718487.1718498},
isbn = {9781605588896},
keywords = {personalization,recommender systems,tag recommendation,tensor factorization},
month = {feb},
pages = {81},
publisher = {ACM Press},
title = {{Pairwise interaction tensor factorization for personalized tag recommendation}},
url = {http://dl.acm.org/citation.cfm?id=1718487.1718498},
year = {2010}
}
@article{Ricci2014,
author = {Ricci, G and de Gemmis, M and Semeraro, G},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ricci, Gemmis, Semeraro - 2014 - Mathematical methods of tensor factorization applied to recommender systems.pdf:pdf},
journal = {New Trends in Databases and  {\ldots}},
title = {{Mathematical methods of tensor factorization applied to recommender systems}},
url = {http://link.springer.com/chapter/10.1007/978-3-319-01863-8{\_}40},
year = {2014}
}
@article{Ringeval2015,
abstract = {Automatic emotion recognition systems based on supervised machine learning require reliable annotation of affective behaviours to build useful models. Whereas the dimensional approach is getting more and more popular for rating affective behaviours in continuous time domains, e.g., arousal and valence, methodologies to take into account reaction lags of the human raters are still rare. We therefore investigate the relevance of using machine learning algorithms able to integrate contextual information in the modelling, like long short-term memory recurrent neural networks do, to automatically predict emotion from several (asynchronous) raters in continuous time domains, i.e., arousal and valence. Evaluations are performed on the recently proposed RECOLA multimodal database (27 subjects, 5 min of data and six raters for each), which includes audio, video, and physiological (ECG, EDA) data. In fact, studies uniting audiovisual and physiological information are still very rare. Features are extracted with various window sizes for each modality and performance for the automatic emotion prediction is compared for both different architectures of neural networks and fusion approaches (feature-level/decision-level). The results show that: (i) LSTM network can deal with (asynchronous) dependencies found between continuous ratings of emotion with video data, (ii) the prediction of the emotional valence requires longer analysis window than for arousal and (iii) a decision-level fusion leads to better performance than a feature-level fusion. The best performance (concordance correlation coefficient) for the multimodal emotion prediction is 0.804 for arousal and 0.528 for valence.},
author = {Ringeval, Fabien and Eyben, Florian and Kroupi, Eleni and Yuce, Anil and Thiran, Jean-Philippe and Ebrahimi, Touradj and Lalanne, Denis and Schuller, Bj{\"{o}}rn},
doi = {10.1016/j.patrec.2014.11.007},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ringeval et al. - 2015 - Prediction of asynchronous dimensional emotion ratings from audiovisual and physiological data.pdf:pdf},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {Audiovisual and physiological data,Context-learning long short-term memory recurrent,Continuous affect analysis,Multi-task learning,Multimodal fusion,Multitime resolution features extraction},
month = {nov},
pages = {22--30},
title = {{Prediction of asynchronous dimensional emotion ratings from audiovisual and physiological data}},
url = {http://www.sciencedirect.com/science/article/pii/S0167865514003572},
volume = {66},
year = {2015}
}
@article{Robeva2016,
abstract = {Orthogonal decomposition of tensors is a generalization of the singular value decomposition of matrices. In this paper, we study the spectral theory of orthogonally decomposable tensors. For such a tensor, we give a description of its singular vector tuples as a variety in a product of projective spaces.},
archivePrefix = {arXiv},
arxivId = {1603.09004},
author = {Robeva, Elina and Seigal, Anna},
eprint = {1603.09004},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Robeva, Seigal - 2016 - Singular Vectors of Orthogonally Decomposable Tensors.pdf:pdf},
month = {mar},
pages = {14},
title = {{Singular Vectors of Orthogonally Decomposable Tensors}},
url = {http://arxiv.org/abs/1603.09004},
year = {2016}
}
@book{Sakata2016,
address = {Tokyo},
author = {Sakata, Toshio and Sumi, Toshio and Miyazaki, Mitsuhiro},
doi = {10.1007/978-4-431-55459-2},
isbn = {978-4-431-55458-5},
publisher = {Springer Japan},
series = {SpringerBriefs in Statistics},
title = {{Algebraic and Computational Aspects of Real Tensor Ranks}},
url = {http://link.springer.com/10.1007/978-4-431-55459-2},
year = {2016}
}
@inproceedings{Savvides2006,
abstract = {Facial images change appearance due to multiple factors such as poses, lighting variations, facial expressions, etc. Tensor approach, an extension of conventional matrix, is appropriate to analyze facial factors since tensors make it possible to construct multilinear models using a multiple factor structure. We use higher-order tensors to model multiple factors of facial variations, but this provides some difficulty in use. First, it is difficult to decompose the multiple factors of a test image, especially when the factor parameters are unknown or are not in the training set. Second, for face recognition and face synthesis tasks, it is also difficult to construct reliable multilinear models which have more than two factors. In this paper, we propose a novel tensor factorization method to decompose mixing factors for unseen test images. We set up tensor factorization problem as a least squares problems with a quadratic equality constraint, and solve it using numerical optimization techniques. The novelty in our approach compared to previous work is that our tensor factorization method does not require any knowledge or assumption of test images; we can attain parameters of facial factors by our tensor factorization method. We have conducted several experiments to show the versatility of the method for both face recognition and synthesis tasks. Thus, we demonstrate the proposed method produces reliable results for trilinear models as well as bilinear models.},
author = {Savvides, M.},
booktitle = {2006 Conference on Computer Vision and Pattern Recognition Workshop (CVPRW'06)},
doi = {10.1109/CVPRW.2006.73},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Savvides - 2006 - Estimating Mixing Factors Simultaneously in Multilinear Tensor Decomposition for Robust Face Recognition and Synthesis.pdf:pdf},
isbn = {0-7695-2646-2},
keywords = {Constraint optimization,Face recognition,Image recognition,Least squares methods,Lighting,Matrix decomposition,Performance analysis,Robustness,Tensile stress,Testing},
pages = {49--49},
publisher = {IEEE},
shorttitle = {Computer Vision and Pattern Recognition Workshop,},
title = {{Estimating Mixing Factors Simultaneously in Multilinear Tensor Decomposition for Robust Face Recognition and Synthesis}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1640489},
year = {2006}
}
@article{Schifanella2014,
author = {Schifanella, Claudio and Candan, K. Sel{\c{c}}uk and Sapino, Maria Luisa},
doi = {10.1145/2532169},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Schifanella, Candan, Sapino - 2014 - Multiresolution Tensor Decompositions with Mode Hierarchies.pdf:pdf},
issn = {15564681},
journal = {ACM Transactions on Knowledge Discovery from Data},
keywords = {PARAFAC,Tensor decomposition,Tucker,multiresolution},
month = {jun},
number = {2},
pages = {1--38},
publisher = {ACM},
title = {{Multiresolution Tensor Decompositions with Mode Hierarchies}},
url = {http://dl.acm.org/citation.cfm?id=2630935.2532169},
volume = {8},
year = {2014}
}
@article{Sedghi2016,
abstract = {We consider the problem of training input-output recurrent neural networks (RNN) for sequence labeling tasks. We propose a novel spectral approach for learning the network parameters. It is based on decomposition of the cross-moment tensor between the output and a non-linear transformation of the input, based on score functions. We guarantee consistent learning with polynomial sample and computational complexity under transparent conditions such as non-degeneracy of model parameters, polynomial activations for the neurons, and a Markovian evolution of the input sequence. We also extend our results to Bidirectional RNN which uses both previous and future information to output the label at each time point, and is employed in many NLP tasks such as POS tagging.},
archivePrefix = {arXiv},
arxivId = {1603.00954},
author = {Sedghi, Hanie and Anandkumar, Anima},
eprint = {1603.00954},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sedghi, Anandkumar - 2016 - Training Input-Output Recurrent Neural Networks through Spectral Methods.pdf:pdf},
month = {mar},
title = {{Training Input-Output Recurrent Neural Networks through Spectral Methods}},
url = {http://arxiv.org/abs/1603.00954},
year = {2016}
}
@article{Sellami2016,
abstract = {Spectro-spatial dimensionality reduction in HyperSpectral Images (HSI) classification is a challenging task due to the problem of curse dimensionality, i.e. the high number of spectral bands and the heterogeneity of data. In this context, many dimensionality reduction methods have been developed to overcome the high correlation between bands and the redundancy of information in order to improve the classification accuracy. Most of these methods represent the original HSI as a set of vectors. Therefore, they only exploit spectral properties, neglecting the spatial information, i.e. the spatial rearrangement is lost. To jointly take advantage of spatial and spectral information, HSI has been recently represented as a tensor. In order to preserve the spatial and spectral information, we develop a hybrid method using both the Tensor Locality Preserving Projections method (TLPP) projecting the original data into a lower subspace and the Constrained Band Selection method (CBS) to select the relevant bands. These two methods will be jointly used to get high-level quality classification. Moreover, since the two obtained classifications are uncertain and imprecise, we propose to fuse them using the Dempster-Shafer's Theory (DST) to obtain an accurate classification preserving the spectro-spatial information. The proposed approach has been applied on real HSI showing its efficiency compared with conventional dimensionality reduction methods.},
author = {Sellami, Akrem and Farah, Imed Riadh},
doi = {10.1016/j.spasta.2016.02.003},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sellami, Farah - 2016 - High-level hyperspectral image classification based on spectro-spatial dimensionality reduction.pdf:pdf},
issn = {22116753},
journal = {Spatial Statistics},
keywords = {CBS,Dimensionality reduction,HSI classification,TLPP,Tensor model},
month = {feb},
title = {{High-level hyperspectral image classification based on spectro-spatial dimensionality reduction}},
url = {http://www.sciencedirect.com/science/article/pii/S221167531600018X},
year = {2016}
}
@article{Shao2015,
author = {Shao, W and He, L and Philip, SY},
journal = {Advances in Knowledge Discovery and Data  {\ldots}},
title = {{Clustering on Multi-source Incomplete Data via Tensor Modeling and Factorization}},
url = {http://link.springer.com/chapter/10.1007/978-3-319-18032-8{\_}38},
year = {2015}
}
@inproceedings{Shashua2005,
address = {New York, New York, USA},
author = {Shashua, Amnon and Hazan, Tamir},
booktitle = {Proceedings of the 22nd international conference on Machine learning - ICML '05},
doi = {10.1145/1102351.1102451},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shashua, Hazan - 2005 - Non-negative tensor factorization with applications to statistics and computer vision.pdf:pdf},
isbn = {1595931805},
month = {aug},
pages = {792--799},
publisher = {ACM Press},
title = {{Non-negative tensor factorization with applications to statistics and computer vision}},
url = {http://dl.acm.org/citation.cfm?id=1102351.1102451},
year = {2005}
}
@inproceedings{Shin2014,
abstract = {Given a high-dimensional and large-scale tensor, how can we decompose it into latent factors? Can we process it on commodity computers with limited memory? These questions are closely related to recommendation systems exploiting context information such as time and location. They require tensor factorization methods scalable with both the dimension and size of a tensor. In this paper, we propose two distributed tensor factorization methods, SALS and CDTF. Both methods are scalable with all aspects of data, and they show an interesting trade-off between convergence speed and memory requirements. SALS updates a subset of the columns of a factor matrix at a time, and CDTF, a special case of SALS, updates one column at a time. On our experiment, only our methods factorize a 5-dimensional tensor with 1B observable entries, 10M mode length, and 1K rank, while all other state-of-the-art methods fail. Moreover, our methods require several orders of magnitude less memory than the competitors. We implement our methods on MapReduce with two widely applicable optimization techniques: local disk caching and greedy row assignment.},
author = {Shin, Kijung and Kang, U.},
booktitle = {2014 IEEE International Conference on Data Mining},
doi = {10.1109/ICDM.2014.78},
isbn = {978-1-4799-4302-9},
issn = {1550-4786},
keywords = {CDTF,Distributed computing,Distributed databases,MapReduce,Matrix decomposition,Memory management,Optimization,Recommender system,SALS,Scalability,Tensile stress,Tensor factorization,Tin,coordinate descent for tensor factorization,data handling,distributed tensor factorization methods,factor matrix,greedy row assignment,high-dimensional tensor factorization,large-scale tensor factorization,least squares approximations,local disk caching,matrix decomposition,optimization techniques,parallel processing,subset alternating least square},
month = {dec},
pages = {989--994},
publisher = {IEEE},
shorttitle = {Data Mining (ICDM), 2014 IEEE International Confer},
title = {{Distributed Methods for High-Dimensional and Large-Scale Tensor Factorization}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7023435},
year = {2014}
}
@article{Simsekli2015,
abstract = {We provide an overview of matrix and tensor factorization methods from a Bayesian perspective, giving emphasis on both the inference methods and modeling techniques. Factorization based models and their many extensions such as tensor factorizations have proved useful in a broad range of applications, supporting a practical and computationally tractable framework for modeling. Especially in audio processing, tensor models help in a unified manner the use of prior knowledge about signals, the data generation processes as well as available data from different modalities. After a general review of tensor models, we describe the general statistical framework, give examples of several audio applications and describe modeling strategies for key problems such as deconvolution, source separation, and transcription.},
author = {Şimşekli, Umut and Virtanen, Tuomas and Cemgil, Ali Taylan},
doi = {10.1016/j.dsp.2015.03.011},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Şimşekli, Virtanen, Cemgil - 2015 - Non-negative tensor factorization models for Bayesian audio processing.pdf:pdf},
issn = {10512004},
journal = {Digital Signal Processing},
keywords = {Bayesian audio modeling,Bayesian inference,Coupled factorization,Nonnegative matrix and tensor factorization},
month = {mar},
title = {{Non-negative tensor factorization models for Bayesian audio processing}},
url = {http://www.sciencedirect.com/science/article/pii/S105120041500086X},
year = {2015}
}
@article{Singer2010,
abstract = {The problem of completing a low-rank matrix from a subset of its entries is often encountered in the analysis of incomplete data sets exhibiting an underlying factor model with applications in collaborative filtering, computer vision, and control. Most recent work has been focused on constructing efficient algorithms for exact or approximate recovery of the missing matrix entries and proving lower bounds for the number of known entries that guarantee a successful recovery with high probability. A related problem from both the mathematical and algorithmic points of view is the distance geometry problem of realizing points in a Euclidean space from a given subset of their pairwise distances. Rigidity theory answers basic questions regarding the uniqueness of the realization satisfying a given partial set of distances. We observe that basic ideas and tools of rigidity theory can be adapted to determine uniqueness of low-rank matrix completion, where inner products play the role that distances play in rigidit...},
author = {Singer, Amit and Cucuringu, Mihai},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Singer, Cucuringu - 2010 - Uniqueness of Low-Rank Matrix Completion by Rigidity Theory.pdf:pdf},
isbn = {10.1137/090750688},
journal = {SIAM Journal on Matrix Analysis and Applications},
keywords = {05C10,05C75,15A48,collaborative filtering,iterative methods,low-rank matrices,missing values,rigidity theory},
language = {en},
month = {feb},
publisher = {Society for Industrial and Applied Mathematics},
title = {{Uniqueness of Low-Rank Matrix Completion by Rigidity Theory}},
url = {http://epubs.siam.org/doi/abs/10.1137/090750688},
year = {2010}
}
@article{Smaragdis2004,
annote = {Single source audio separation by NMF or NTF},
author = {Smaragdis, P},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Smaragdis - 2004 - Non-negative matrix factor deconvolution extraction of multiple sound sources from monophonic inputs.pdf:pdf},
journal = {Independent Component Analysis and Blind Signal  {\ldots}},
keywords = {audio},
mendeley-tags = {audio},
title = {{Non-negative matrix factor deconvolution; extraction of multiple sound sources from monophonic inputs}},
url = {http://link.springer.com/chapter/10.1007/978-3-540-30110-3{\_}63},
year = {2004}
}
@article{Sordoni2014,
author = {Sordoni, A and Bengio, Y and Nie, JY},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sordoni, Bengio, Nie - 2014 - Learning Concept Embeddings for Query Expansion by Quantum Entropy Minimization.pdf:pdf},
journal = {Twenty-Eighth AAAI  {\ldots}},
keywords = {quantum},
mendeley-tags = {quantum},
title = {{Learning Concept Embeddings for Query Expansion by Quantum Entropy Minimization}},
url = {http://www-etud.iro.umontreal.ca/{~}sordonia/pdf/aaai2014{\_}sordoni.pdf},
year = {2014}
}
@article{Sordoni2013,
author = {Sordoni, A and Nie, JY and Bengio, Y},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sordoni, Nie, Bengio - 2013 - Modeling term dependencies with quantum language models for IR.pdf:pdf},
journal = {Proceedings of the 36th international ACM {\ldots}},
keywords = {quantum},
mendeley-tags = {quantum},
title = {{Modeling term dependencies with quantum language models for IR}},
url = {http://dl.acm.org/citation.cfm?id=2484098},
year = {2013}
}
@inproceedings{Srivastava2012,
author = {Srivastava, Nitish and Salakhutdinov, Ruslan R.},
booktitle = {Advances in Neural Information Processing Systems},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Srivastava, Salakhutdinov - 2012 - Multimodal Learning with Deep Boltzmann Machines.pdf:pdf},
pages = {2222--2230},
title = {{Multimodal Learning with Deep Boltzmann Machines}},
url = {http://papers.nips.cc/paper/4683-multimodal-learning-with-deep-boltzmann-machines},
year = {2012}
}
@article{Sun2015,
abstract = {Tensor clustering is an important tool that exploits intrinsically rich structures in real-world multiarray or Tensor datasets. Often in dealing with those datasets, standard practice is to use subspace clustering that is based on vectorizing multiarray data. However, vectorization of tensorial data does not exploit complete structure information. In this paper, we propose a subspace clustering algorithm without adopting any vectorization process. Our approach is based on a novel heterogeneous Tucker decomposition model taking into account cluster membership information. We propose a new clustering algorithm that alternates between different modes of the proposed heterogeneous tensor model. All but the last mode have closed-form updates. Updating the last mode reduces to optimizing over the multinomial manifold for which we investigate second order Riemannian geometry and propose a trust-region algorithm. Numerical experiments show that our proposed algorithm compete effectively with state-of-the-art clustering algorithms that are based on tensor factorization.},
author = {Sun, Yanfeng and Gao, Junbin and Hong, Xia and Mishra, Bamdev and Yin, Baocai},
doi = {10.1109/TPAMI.2015.2465901},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sun et al. - 2015 - Heterogeneous Tensor Decomposition for Clustering via Manifold Optimization.pdf:pdf},
issn = {0162-8828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Clustering algorithms,Fisher metric,Manifolds,Matrix decomposition,Measurement,Numerical models,Optimization,Riemannian optimization,Tensile stress,Tensor clustering,clustering,multinomial manifold,trust-region},
mendeley-tags = {clustering},
number = {3},
pages = {1--1},
shorttitle = {Pattern Analysis and Machine Intelligence, IEEE Tr},
title = {{Heterogeneous Tensor Decomposition for Clustering via Manifold Optimization}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7182334},
volume = {38},
year = {2015}
}
@article{Tichavsky2016,
abstract = {In this paper, a numerical method is proposed for canonical polyadic (CP) decomposition of small size tensors. The focus is primarily on decomposition of tensors that correspond to small matrix multiplications. Here, rank of the tensors is equal to the smallest number of scalar multiplications that are necessary to accomplish the matrix multiplication. The proposed method is based on a constrained Levenberg-Marquardt optimization. Numerical results indicate the rank and border ranks of tensors that correspond to multiplication of matrices of the size 2x3 and 3x2, 3x3 and 3x2, 3x3 and 3x3, and 3x4 and 4x3. The ranks are 11, 15, 23 and 29, respectively. In particular, a novel algorithm for multiplying the matrices of the sizes 3x3 and 3x2 with 15 multiplications is presented.},
archivePrefix = {arXiv},
arxivId = {1603.01372},
author = {Tichavsky, Petr and Phan, Anh Huy and Cichocki, Andrzej},
eprint = {1603.01372},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tichavsky, Phan, Cichocki - 2016 - Numerical CP Decomposition of Some Difficult Tensors.pdf:pdf},
month = {mar},
title = {{Numerical CP Decomposition of Some Difficult Tensors}},
url = {http://arxiv.org/abs/1603.01372},
year = {2016}
}
@article{Tucker1966,
annote = {seminal paper; important author},
author = {Tucker, Ledyard R},
doi = {10.1007/BF02289464},
issn = {0033-3123},
journal = {Psychometrika},
keywords = {tensor},
mendeley-tags = {tensor},
month = {sep},
number = {3},
pages = {279--311},
title = {{Some mathematical notes on three-mode factor analysis}},
url = {http://link.springer.com/10.1007/BF02289464},
volume = {31},
year = {1966}
}
@article{Tucker1963,
annote = {Seminal paper, important author},
author = {Tucker, LR},
journal = {Problems in measuring change},
keywords = {tensor},
mendeley-tags = {tensor},
title = {{Implications of factor analysis of three-way matrices for measurement of change}},
url = {https://scholar.google.com.co/scholar?hl=en{\&}q=tucker+implications+of+factor+analysis+of+three-way{\&}btnG={\&}as{\_}sdt=1{\%}2C5{\&}as{\_}sdtp={\#}0},
year = {1963}
}
@article{Tucker1964,
annote = {Seminal paper, important author},
author = {Tucker, LR},
journal = {Contributions to mathematical psicology},
keywords = {tensor},
mendeley-tags = {tensor},
title = {{The extension of factor analysis to three-dimensional matrices}},
url = {https://scholar.google.com.co/scholar?q=tucker+the+extension+of+factor+analysis+for+three-dimensional+matrices{\&}btnG={\&}hl=en{\&}as{\_}sdt=0{\%}2C5{\#}0},
year = {1964}
}
@article{Turzi2016,
abstract = {The orientational order of nematic liquid crystals is traditionally studied by means of the second-rank ordering tensor {\$}\backslashmathbb{\{}S{\}}{\$}. When this is calculated through experiments or simulations, the symmetry group of the phase is not known $\backslash$emph{\{}a-priori{\}}, but need to be deduced from the numerical realisation of {\$}\backslashmathbb{\{}S{\}}{\$}, which is affected by numerical errors. There is no generally accepted procedure to perform this analysis. Here, we provide a new algorithm suited to identifying the symmetry group of the phase. As a by product, we prove that there are only five phase-symmetry classes of the second-rank ordering tensor and give a canonical representation of {\$}\backslashmathbb{\{}S{\}}{\$} for each class. The nearest tensor of the assigned symmetry is determined by group-projection. In order to test our procedure, we generate uniaxial and biaxial phases in a system of interacting particles, endowed with {\$}D{\_}{\{}\backslashinfty h{\}}{\$} or {\$}D{\_}{\{}2h{\}}{\$}, which mimic the outcome of Monte-Carlo simulations. The actual symmetry of the phases is correctly identified, along with the optimal choice of laboratory frame.},
archivePrefix = {arXiv},
arxivId = {1602.06413},
author = {Turzi, Stefano S. and Bisi, Fulvio},
eprint = {1602.06413},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Turzi, Bisi - 2016 - Determination of the symmetry classes of orientational ordering tensors.pdf:pdf},
month = {feb},
title = {{Determination of the symmetry classes of orientational ordering tensors}},
url = {http://arxiv.org/abs/1602.06413},
year = {2016}
}
@article{Usset2016,
abstract = {A functional regression model with a scalar response and multiple functional predictors is proposed that accommodates two-way interactions in addition to their main effects. The proposed estimation procedure models the main effects using penalized regression splines, and the interaction effect by a tensor product basis. Extensions to generalized linear models and data observed on sparse grids or with measurement error are presented. A hypothesis testing procedure for the functional interaction effect is described. The proposed method can be easily implemented through existing software. Numerical studies show that fitting an additive model in the presence of interaction leads to both poor estimation performance and lost prediction power, while fitting an interaction model where there is in fact no interaction leads to negligible losses. The methodology is illustrated on the AneuRisk65 study data.},
author = {Usset, Joseph and Staicu, Ana-Maria and Maity, Arnab},
doi = {10.1016/j.csda.2015.08.020},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Usset, Staicu, Maity - 2016 - Interaction models for functional regression.pdf:pdf},
issn = {01679473},
journal = {Computational Statistics {\&} Data Analysis},
keywords = {Functional regression,Hypothesis testing,Interaction,Spline smoothing,tensor product},
mendeley-tags = {tensor product},
month = {feb},
pages = {317--330},
title = {{Interaction models for functional regression}},
url = {http://www.sciencedirect.com/science/article/pii/S016794731500208X},
volume = {94},
year = {2016}
}
@article{Virtanen2007,
abstract = {An unsupervised learning algorithm for the separation of sound sources in one-channel music signals is presented. The algorithm is based on factorizing the magnitude spectrogram of an input signal into a sum of components, each of which has a fixed magnitude spectrum and a time-varying gain. Each sound source, in turn, is modeled as a sum of one or more components. The parameters of the components are estimated by minimizing the reconstruction error between the input spectrogram and the model, while restricting the component spectrograms to be nonnegative and favoring components whose gains are slowly varying and sparse. Temporal continuity is favored by using a cost term which is the sum of squared differences between the gains in adjacent frames, and sparseness is favored by penalizing nonzero gains. The proposed iterative estimation algorithm is initialized with random values, and the gains and the spectra are then alternatively updated using multiplicative update rules until the values converge. Simulation experiments were carried out using generated mixtures of pitched musical instrument samples and drum sounds. The performance of the proposed method was compared with independent subspace analysis and basic nonnegative matrix factorization, which are based on the same linear model. According to these simulations, the proposed method enables a better separation quality than the previous algorithms. Especially, the temporal continuity criterion improved the detection of pitched musical sounds. The sparseness criterion did not produce significant improvements},
annote = {Single source audio separation by NMF or NTF},
author = {Virtanen, Tuomas},
doi = {10.1109/TASL.2006.885253},
issn = {1558-7916},
journal = {IEEE Transactions on Audio, Speech and Language Processing},
keywords = {Acoustic signal analysis,Costs,Humans,Independent component analysis,Machine learning algorithms,Multiple signal classification,Music,Source separation,Sparse matrices,Spectrogram,Unsupervised learning,acoustic signal processing,audio source separation,blind source separation,drum sounds,independent subspace analysis,iterative estimation algorithm,iterative methods,magnitude spectrogram factorization,matrix decomposition,monaural sound source separation,multiplicative update rules,music,nonnegative matrix factorization,one-channel music signals,pitched musical instrument samples,reconstruction error,signal reconstruction,source separation,sparse coding,sparseness criteria,temporal continuity criterion,time-varying gain,unsupervised learning,unsupervised learning algorithm},
month = {mar},
number = {3},
pages = {1066--1074},
shorttitle = {Audio, Speech, and Language Processing, IEEE Trans},
title = {{Monaural Sound Source Separation by Nonnegative Matrix Factorization With Temporal Continuity and Sparseness Criteria}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4100700},
volume = {15},
year = {2007}
}
@article{Vo2015,
abstract = {In the field of visual data mining, Histogram of Oriented Gradients (HOG) and its variants have been widely used. The speed and ability to extract image features that are robust against many types of distortions such as scaling, orientation, affine and illumination that HOG offers have made it a popular choice for the task of detecting images in scenes for classification. However, the high dimensionality nature of HOG descriptors (features), usually in the order of multiple thousands of them per image, would require careful consideration in place to achieve accurate and timely categorization of objects within images. This work explores the possibility of processing HOG features as tensors, or multi-dimensional arrays. A direct result of that is tensor decomposition techniques such as canonical polyadic (CP) decomposition performed on the high-order HOG tensors as the mean for dimensionality reduction by filtering. This work focuses on the impact of this approach on both accuracy and efficiency, comparing it against the standard practice of processing HOG features. Validating with the Caltech-101 dataset, the results achieved with artificial neural network (ANN) classification indicate that the proposed method not only improves the overall system performance, it also achieves the edge in accuracy by a notable margin.},
author = {Vo, Tan and Tran, Dat and Ma, Wanli},
doi = {10.1016/j.neucom.2014.06.093},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vo, Tran, Ma - 2015 - Tensor decomposition and application in image classification with histogram of oriented gradients.pdf:pdf},
issn = {09252312},
journal = {Neurocomputing},
keywords = {ANN,CP decomposition,HOG,Image classification,Tensor},
month = {oct},
pages = {38--45},
title = {{Tensor decomposition and application in image classification with histogram of oriented gradients}},
url = {http://www.sciencedirect.com/science/article/pii/S0925231215004294},
volume = {165},
year = {2015}
}
@article{WAng2016,
author = {WAng, H and Qinglin, LI and KAng, Q},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/WAng, Qinglin, KAng - 2016 - RESEARCH ON BISPECTRUM ANALYSIS OF SECONDARY FEATURE FOR VEHICLE EXTERIOR NOISE BASED ON NONNEGATIVE TUCKER.pdf:pdf},
journal = {EKSPLOATACJA I NIEZAWODNOSC},
title = {{RESEARCH ON BISPECTRUM ANALYSIS OF SECONDARY FEATURE FOR VEHICLE EXTERIOR NOISE BASED ON NONNEGATIVE TUCKER3}},
url = {http://www.ein.org.pl/sites/default/files/2016-02-18.pdf},
year = {2016}
}
@article{Wang2014,
author = {Wang, Liqi and Chu, Moody T. and Bo, Yu},
doi = {10.1007/s11075-014-9885-1},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang, Chu, Bo - 2014 - A computational framework of gradient flows for general linear matrix equations.pdf:pdf},
issn = {1017-1398},
journal = {Numerical Algorithms},
month = {jul},
number = {1},
pages = {121--141},
title = {{A computational framework of gradient flows for general linear matrix equations}},
url = {http://link.springer.com/10.1007/s11075-014-9885-1},
volume = {68},
year = {2014}
}
@article{Wang2013,
abstract = {Nonnegative Matrix Factorization (NMF), a relatively novel paradigm for dimensionality reduction, has been in the ascendant since its inception. It incorporates the nonnegativity constraint and thus obtains the parts-based representation as well as enhancing the interpretability of the issue correspondingly. This survey paper mainly focuses on the theoretical research into NMF over the last 5 years, where the principles, basic models, properties, and algorithms of NMF along with its various modifications, extensions, and generalizations are summarized systematically. The existing NMF algorithms are divided into four categories: Basic NMF (BNMF), Constrained NMF (CNMF), Structured NMF (SNMF), and Generalized NMF (GNMF), upon which the design principles, characteristics, problems, relationships, and evolution of these algorithms are presented and analyzed comprehensively. Some related work not on NMF that NMF should learn from or has connections with is involved too. Moreover, some open issues remained to be solved are discussed. Several relevant application areas of NMF are also briefly described. This survey aims to construct an integrated, state-of-the-art framework for NMF concept, from which the follow-up research may benefit.},
author = {Wang, Yu-Xiong and Zhang, Yu-Jin},
doi = {10.1109/TKDE.2012.51},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang, Zhang - 2013 - Nonnegative Matrix Factorization A Comprehensive Review.pdf:pdf},
issn = {1041-4347},
journal = {IEEE Transactions on Knowledge and Data Engineering},
keywords = {Algorithm design and analysis,BNMF,CNMF,Data analysis,Data mining,GNMF,Matrix decomposition,NTF,Optimization,SNMF,Semantics,Signal processing algorithms,Vectors,basic NMF,constrained NMF,dimensionality reduction,generalized NMF,kernel NMF,matrix decomposition,multivariate data analysis,nonnegative matrix factorization,nonnegative matrix factorization (NMF),nonnegativity constraint,parts-based representation,structured NMF},
mendeley-tags = {NTF,kernel NMF},
month = {jun},
number = {6},
pages = {1336--1353},
shorttitle = {IEEE Transactions on Knowledge and Data Engineerin},
title = {{Nonnegative Matrix Factorization: A Comprehensive Review}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6165290},
volume = {25},
year = {2013}
}
@article{Wimalawarne2016,
abstract = {We theoretically and experimentally investigate tensor-based regression and classification. Our focus is regularization with various tensor norms, including the overlapped trace norm, the latent trace norm, and the scaled latent trace norm. We first give dual optimization methods using the alternating direction method of multipliers, which is computationally efficient when the number of training samples is moderate. We then theoretically derive an excess risk bound for each tensor norm and clarify their behavior. Finally, we perform extensive experiments using simulated and real data and demonstrate the superiority of tensor-based learning methods over vector- and matrix-based learning methods.},
author = {Wimalawarne, Kishan and Tomioka, Ryota and Sugiyama, Masashi},
doi = {10.1162/NECO_a_00815},
issn = {1530-888X},
journal = {Neural computation},
language = {English},
month = {apr},
number = {4},
pages = {686--715},
pmid = {26890354},
publisher = {MIT Press},
title = {{Theoretical and Experimental Analyses of Tensor-Based Regression and Classification.}},
url = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=7439919},
volume = {28},
year = {2016}
}
@article{Wu2016,
abstract = {Spectral clustering and co-clustering are well-known techniques in data analysis, and recent work has extended spectral clustering to square, symmetric tensors and hypermatrices derived from a network. We develop a new tensor spectral co-clustering method that applies to any non-negative tensor of data. The result of applying our method is a simultaneous clustering of the rows, columns, and slices of a three-mode tensor, and the idea generalizes to any number of modes. The algorithm we design works by recursively bisecting the tensor into two pieces. We also design a new measure to understand the role of each cluster in the tensor. Our new algorithm and pipeline are demonstrated in both synthetic and real-world problems. On synthetic problems with a planted higher-order cluster structure, our method is the only one that can reliably identify the planted structure in all cases. On tensors based on n-gram text data, we identify stop-words and semantically independent sets; on tensors from an airline-airport multimodal network, we find worldwide and regional co-clusters of airlines and airports; and on tensors from an email network, we identify daily-spam and focused-topic sets.},
archivePrefix = {arXiv},
arxivId = {1603.00395},
author = {Wu, Tao and Benson, Austin R. and Gleich, David F.},
eprint = {1603.00395},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wu, Benson, Gleich - 2016 - General Tensor Spectral Co-clustering for Higher-Order Data.pdf:pdf},
month = {mar},
title = {{General Tensor Spectral Co-clustering for Higher-Order Data}},
url = {http://arxiv.org/abs/1603.00395},
year = {2016}
}
@article{Wu2016a,
author = {Wu, Zhaojun and Wang, Qiang and Wu, Zhenghua and Shen, Yi},
doi = {10.1117/1.JEI.25.1.013037},
issn = {1017-9909},
journal = {Journal of Electronic Imaging},
month = {feb},
number = {1},
pages = {013037},
publisher = {International Society for Optics and Photonics},
title = {{Total variation-regularized weighted nuclear norm minimization for hyperspectral image mixed denoising}},
url = {http://electronicimaging.spiedigitallibrary.org/article.aspx?articleid=2498934},
volume = {25},
year = {2016}
}
@article{Xu2014,
abstract = {Higher-order singular value decomposition (HOSVD) is an efficient way for data reduction and also eliciting intrinsic structure of multi-dimensional array data. It has been used in many applications, and some of them involve incomplete data. To obtain HOSVD of the data with missing values, one can first impute the missing entries through a certain tensor completion method and then perform HOSVD to the reconstructed data. However, the two-step procedure can be inefficient and does not make reliable decomposition.   In this paper, we formulate an incomplete HOSVD problem and combine the two steps into solving a single optimization problem, which simultaneously achieves imputation of missing values and also tensor decomposition. We also present two algorithms for solving the problem based on block coordinate update. Global convergence of both algorithms is shown under mild assumptions. The convergence of the second algorithm implies that of the popular higher-order orthogonality iteration (HOOI) method, and thus we, for the first time, give global convergence of HOOI.   In addition, we compare the proposed methods to state-of-the-art ones for solving incomplete HOSVD and also low-rank tensor completion problems and demonstrate the superior performance of our methods over other compared ones. Furthermore, we apply them to face recognition and MRI image reconstruction to show their practical performance.},
archivePrefix = {arXiv},
arxivId = {1411.4324},
author = {Xu, Yangyang},
eprint = {1411.4324},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xu - 2014 - On Higher-order Singular Value Decomposition from Incomplete Data.pdf:pdf},
month = {nov},
title = {{On Higher-order Singular Value Decomposition from Incomplete Data}},
url = {http://arxiv.org/abs/1411.4324},
year = {2014}
}
@article{Xu2015,
abstract = {Higher-order low-rank tensors naturally arise in many applications including hyperspectral data recovery, video inpainting, seismic data reconstruction, and so on. We propose a new model to recover a low-rank tensor by simultaneously performing low-rank matrix factorizations to the all-mode matricizations of the underlying tensor. An alternating minimization algorithm is applied to solve the model, along with two adaptive rank-adjusting strategies when the exact rank is not known. Phase transition plots reveal that our algorithm can recover a variety of synthetic low-rank tensors from significantly fewer samples than the compared methods, which include a matrix completion method applied to tensor recovery and two state-of-the-art tensor completion methods. Further tests on real- world data show similar advantages. Although our model is non-convex, our algorithm performs consistently throughout the tests and gives better results than the compared methods, some of which are based on convex models. In addition, subsequence convergence of our algorithm can be established in the sense that any limit point of the iterates satisfies the KKT condtions.},
author = {Xu, Yangyang and Hao, Ruru and Yin, Wotao and Su, Zhixun},
doi = {10.3934/ipi.2015.9.601},
issn = {1930-8337},
journal = {Inverse Problems and Imaging},
keywords = {Alternating least squares,Higher-order tensor,Low-rank matrix completion,Low-rank tensor completion,Non-convex optimization},
month = {mar},
number = {2},
pages = {601--624},
publisher = {American Institute of Mathematical Sciences},
title = {{Parallel matrix factorization for low-rank tensor completion}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84924953250{\&}partnerID=tZOtx3y1},
volume = {9},
year = {2015}
}
@article{Xu2013,
abstract = {This paper considers regularized block multiconvex optimization, where the feasible set and objective function are generally nonconvex but convex in each block of variables. It also accepts nonconvex blocks and requires these blocks to be updated by proximal minimization. We review some interesting applications and propose a generalized block coordinate descent method. Under certain conditions, we show that any limit point satisfies the Nash equilibrium conditions. Furthermore, we establish global convergence and estimate the asymptotic convergence rate of the method by assuming a property based on the Kurdyka--{\L}ojasiewicz inequality. The proposed algorithms are tested on nonnegative matrix and tensor factorization, as well as matrix and tensor recovery from incomplete observations. The tests include synthetic data and hyperspectral data, as well as image sets from the CBCL and ORL databases. Compared to the existing state-of-the-art algorithms, the proposed algorithms demonstrate superior performance in ...},
author = {Xu, Yangyang and Yin, Wotao},
doi = {10.1137/120887795},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xu, Yin - 2013 - A Block Coordinate Descent Method for Regularized Multiconvex Optimization with Applications to Nonnegative Tensor Fact.pdf:pdf},
issn = {1936-4954},
journal = {SIAM Journal on Imaging Sciences},
keywords = {49M20,65B05,90C26,90C30,90C52,Kurdyka--{\L}ojasiewicz inequality,NTF,Nash equilibrium,block coordinate descent,block multiconvex,matrix completion,nonnegative matrix and tensor factorization,proximal gradient method,tensor completion},
language = {en},
mendeley-tags = {NTF},
month = {sep},
number = {3},
pages = {1758--1789},
publisher = {Society for Industrial and Applied Mathematics},
title = {{A Block Coordinate Descent Method for Regularized Multiconvex Optimization with Applications to Nonnegative Tensor Factorization and Completion}},
url = {http://epubs.siam.org/doi/abs/10.1137/120887795},
volume = {6},
year = {2013}
}
@article{Xu2015a,
abstract = {Tensor decomposition is a powerful computational tool for multiway data analysis. Many popular tensor decomposition approaches-such as the Tucker decomposition and CANDECOMP/PARAFAC (CP)-amount to multi-linear factorization. They are insufficient to model (i) complex interactions between data entities, (ii) various data types (e.g., missing data and binary data), and (iii) noisy observations and outliers. To address these issues, we propose tensor-variate latent nonparametric Bayesian models for multiway data analysis. We name these models InfTucker. These new models essentially conduct Tucker decomposition in an infinite feature space. Unlike classical tensor decomposition models, our new approaches handle both continuous and binary data in a probabilistic framework. Unlike previous Bayesian models on matrices and tensors, our models are based on latent Gaussian or t processes with nonlinear covariance functions. Moreover, on network data, our models reduce to nonparametric stochastic blockmodels and can be used to discover latent groups and predict missing interactions. To learn the models efficiently from data, we develop a variational inference technique and explore properties of the Kronecker product for computational efficiency. Compared with a classical variational implementation, this technique reduces both time and space complexities by several orders of magnitude. On real multiway and network data, our new models achieved significantly higher prediction accuracy than state-of-art tensor decomposition methods and blockmodels.},
author = {Xu, Zenglin and Yan, Feng and Qi, Yuan},
doi = {10.1109/TPAMI.2013.201},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xu, Yan, Qi - 2015 - Bayesian Nonparametric Models for Multiway Data Analysis.pdf:pdf},
issn = {1939-3539},
journal = {IEEE transactions on pattern analysis and machine intelligence},
keywords = {Algorithms for data and knowledge management,Bayes methods,Computational modeling,Data models,Gaussian process,Gaussian processes,Machine learning,Matrix decomposition,Multiway analysis,Noise,Tensile stress,network modeling,nonparametric Bayes,random graphs and exchangeable arrays,stochastic blockmodel,tensor/matrix factorization},
month = {feb},
number = {2},
pages = {475--87},
pmid = {26353255},
shorttitle = {Pattern Analysis and Machine Intelligence, IEEE Tr},
title = {{Bayesian Nonparametric Models for Multiway Data Analysis.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/26353255},
volume = {37},
year = {2015}
}
@article{Yan2015,
author = {Yan, H and Paynabar, K and Shi, J},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yan, Paynabar, Shi - 2015 - Image-Based Process Monitoring Using Low-Rank Tensor Decomposition.pdf:pdf},
journal = {Automation Science and  {\ldots}},
title = {{Image-Based Process Monitoring Using Low-Rank Tensor Decomposition}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=6855374},
year = {2015}
}
@article{Yang2015,
abstract = {In this letter, we propose a rank-one tensor updating algorithm for solving tensor completion problems. Unlike the existing methods which penalize the tensor by using the sum of nuclear norms of unfolding matrices, our optimization model directly employs the tensor nuclear norm which is studied recently. Under the framework of the conditional gradient method, we show that at each iteration, solving the proposed model amounts to computing the tensor spectral norm and the related rank-one tensor. Because the problem of finding the related rank-one tensor is NP-hard, we propose a subroutine to solve it approximately, which is of low computational complexity. Experimental results on real datasets show that our algorithm is efficient and effective.},
author = {Yang, Yuning and Feng, Yunlong and Suykens, Johan A. K.},
doi = {10.1109/LSP.2015.2420592},
issn = {1070-9908},
journal = {IEEE Signal Processing Letters},
keywords = {Approximation algorithms,Computational modeling,Frank–Wolfe (conditional gradient) method,Gradient methods,NP-hard problem,Signal processing algorithms,Tensile stress,computational complexity,conditional gradient method,gradient methods,iteration method,matrix algebra,optimisation,optimization model,rank-one tensor,rank-one tensor updating algorithm,tensor completion,tensor completion problem,tensor nuclear norm,tensor nuclear/spectral norm,tensor spectral norm,tensors,unfolding matrix algebra},
month = {oct},
number = {10},
pages = {1633--1637},
shorttitle = {IEEE Signal Processing Letters},
title = {{A Rank-One Tensor Updating Algorithm for Tensor Completion}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7080836},
volume = {22},
year = {2015}
}
@inproceedings{Ye2008,
address = {New York, New York, USA},
author = {Ye, Jieping and Alexander, Gene and Reiman, Eric and Chen, Kewei and Wu, Teresa and Li, Jing and Zhao, Zheng and Patel, Rinkal and Bae, Min and Janardan, Ravi and Liu, Huan},
booktitle = {Proceeding of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining - KDD 08},
doi = {10.1145/1401890.1402012},
isbn = {9781605581934},
keywords = {biomarker detection,heterogeneous data source fusion,kernel,multiple kernel learning,neuroimaging,tensor factorization},
mendeley-tags = {kernel},
month = {aug},
pages = {1025},
publisher = {ACM Press},
title = {{Heterogeneous data fusion for alzheimer's disease study}},
url = {http://dl.acm.org/citation.cfm?id=1401890.1402012},
year = {2008}
}
@article{Yin2016,
abstract = {OBJECTIVE
We provide a survey of recent advances in biomedical image analysis and classification from emergent imaging modalities such as terahertz (THz) pulse imaging (TPI) and dynamic contrast-enhanced magnetic resonance images (DCE-MRIs) and identification of their underlining commonalities. 

METHODS
Both time and frequency domain signal pre-processing techniques are considered: noise removal, spectral analysis, principal component analysis (PCA) and wavelet transforms. Feature extraction and classification methods based on feature vectors using the above processing techniques are also discussed. These include Mahalanobis distance, support vector machine (SVM) and extreme learning machine (ELM) classifiers. 

VALIDATION
Examples where the proposed methodologies have been successful in classifying TPIs and DCE-MRIs are discussed. 

RESULTS
Identifying commonalities in the structure of such heterogeneous datasets potentially leads to a unified multi-channel signal processing framework for biomedical image analysis. 

CONCLUSION
The proposed complex valued classification methodology enables fusion of entire datasets from a sequence of spatial images taken at different time stamps; this is of interest from the viewpoint of inferring disease proliferation. The approach is also of interest for other emergent multi-channel biomedical imaging modalities and of relevance across the biomedical signal processing community.},
author = {Yin, Xiao-Xia and Hadjiloucas, Sillas and Zhang, Yanchun and Su, Min-Ying and Miao, Yuan and Abbott, Derek},
doi = {10.1016/j.artmed.2016.01.005},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yin et al. - 2016 - Pattern identification of biomedical images with time series Contrasting THz pulse imaging with DCE-MRIs.pdf:pdf},
issn = {09333657},
journal = {Artificial Intelligence in Medicine},
keywords = {Basal cell carcinomas,Complex extreme learning machine,Computer-aided diagnosis,Dynamic contrast-enhanced magnetic resonance image,Extreme learning machine,Mahalanobisdistance,Multi-channel signal processing,Poly(dA-dT)-Poly(dT-dA) DNA,Quaternary classification,Support vector machine,Tensor algebra,Terahertz pulse imaging,Time domain spectroscopy,Tumour microvasculature,principal component analysis},
month = {feb},
title = {{Pattern identification of biomedical images with time series: Contrasting THz pulse imaging with DCE-MRIs}},
url = {http://www.sciencedirect.com/science/article/pii/S0933365716300112},
year = {2016}
}
@article{Yuan2014,
abstract = {Many problems can be formulated as recovering a low-rank tensor. Although an increasingly common task, tensor recovery remains a challenging problem because of the delicacy associated with the decomposition of higher order tensors. To overcome these difficulties, existing approaches often proceed by unfolding tensors into matrices and then apply techniques for matrix completion. We show here that such matricization fails to exploit the tensor structure and may lead to suboptimal procedure. More specifically, we investigate a convex optimization approach to tensor completion by directly minimizing a tensor nuclear norm and prove that this leads to an improved sample size requirement. To establish our results, we develop a series of algebraic and probabilistic techniques such as characterization of subdifferetial for tensor nuclear norm and concentration inequalities for tensor martingales, which may be of independent interests and could be useful in other tensor related problems.},
archivePrefix = {arXiv},
arxivId = {1405.1773},
author = {Yuan, Ming and Zhang, Cun-Hui},
eprint = {1405.1773},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yuan, Zhang - 2014 - On Tensor Completion via Nuclear Norm Minimization.pdf:pdf},
month = {may},
title = {{On Tensor Completion via Nuclear Norm Minimization}},
url = {http://arxiv.org/abs/1405.1773},
year = {2014}
}
@article{Zafeiriou2009,
abstract = {Nonnegative matrix factorization (NMF) has proven to be very successful for image analysis, especially for object representation and recognition. NMF requires the object tensor (with valence more than one) to be vectorized. This procedure may result in information loss since the local object structure is lost due to vectorization. Recently, in order to remedy this disadvantage of NMF methods, nonnegative tensor factorizations (NTF) algorithms that can be applied directly to the tensor representation of object collections have been introduced. In this paper, we propose a series of unsupervised and supervised NTF methods. That is, we extend several NMF methods using arbitrary valence tensors. Moreover, by incorporating discriminant constraints inside the NTF decompositions, we present a series of discriminant NTF methods. The proposed approaches are tested for face verification and facial expression recognition, where it is shown that they outperform other popular subspace approaches.},
author = {Zafeiriou, Stefanos},
doi = {10.1109/TNN.2008.2005293},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zafeiriou - 2009 - Discriminant nonnegative tensor factorization algorithms.pdf:pdf},
issn = {1941-0093},
journal = {IEEE transactions on neural networks / a publication of the IEEE Neural Networks Council},
keywords = {Face verification,NTF,arbitrary valence tensors,discriminant nonnegative tensor factorization,face recognition,face verification,facial expression recognition,image analysis,image representation,information loss,linear discriminant analysis,local object structure,matrix decomposition,nonnegative matrix factorization,nonnegative matrix factorization (NMF),nonnegative tensor factorization (NTF),object collections,object recognition,object representation,object tensor,subspace techniques,supervised NTF methods,tensor representation,tensors},
mendeley-tags = {NTF},
month = {feb},
number = {2},
pages = {217--35},
pmid = {19150796},
shorttitle = {IEEE Transactions on Neural Networks},
title = {{Discriminant nonnegative tensor factorization algorithms.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19150796},
volume = {20},
year = {2009}
}
@article{Zhang2012,
abstract = {Many machine learning and pattern classification methods have been applied to the diagnosis of Alzheimer's disease (AD) and its prodromal stage, i.e., mild cognitive impairment (MCI). Recently, rather than predicting categorical variables as in classification, several pattern regression methods have also been used to estimate continuous clinical variables from brain images. However, most existing regression methods focus on estimating multiple clinical variables separately and thus cannot utilize the intrinsic useful correlation information among different clinical variables. On the other hand, in those regression methods, only a single modality of data (usually only the structural MRI) is often used, without considering the complementary information that can be provided by different modalities. In this paper, we propose a general methodology, namely multi-modal multi-task (M3T) learning, to jointly predict multiple variables from multi-modal data. Here, the variables include not only the clinical variables used for regression but also the categorical variable used for classification, with different tasks corresponding to prediction of different variables. Specifically, our method contains two key components, i.e., (1) a multi-task feature selection which selects the common subset of relevant features for multiple variables from each modality, and (2) a multi-modal support vector machine which fuses the above-selected features from all modalities to predict multiple (regression and classification) variables. To validate our method, we perform two sets of experiments on ADNI baseline MRI, FDG-PET, and cerebrospinal fluid (CSF) data from 45 AD patients, 91 MCI patients, and 50 healthy controls (HC). In the first set of experiments, we estimate two clinical variables such as Mini Mental State Examination (MMSE) and Alzheimer's Disease Assessment Scale-Cognitive Subscale (ADAS-Cog), as well as one categorical variable (with value of ‘AD', ‘MCI' or ‘HC'), from the baseline MRI, FDG-PET, and CSF data. In the second set of experiments, we predict the 2-year changes of MMSE and ADAS-Cog scores and also the conversion of MCI to AD from the baseline MRI, FDG-PET, and CSF data. The results on both sets of experiments demonstrate that our proposed M3T learning scheme can achieve better performance on both regression and classification tasks than the conventional learning methods.},
author = {Zhang, Daoqiang and Shen, Dinggang},
doi = {10.1016/j.neuroimage.2011.09.069},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang, Shen - 2012 - Multi-modal multi-task learning for joint prediction of multiple regression and classification variables in Alzheim.pdf:pdf},
issn = {10538119},
journal = {NeuroImage},
keywords = {ADAS-Cog,Alzheimer's disease (AD),MCI conversion,MMSE,Multi-modal multi-task (M3T) learning,Multi-modality,Multi-task feature selection},
month = {jan},
number = {2},
pages = {895--907},
title = {{Multi-modal multi-task learning for joint prediction of multiple regression and classification variables in Alzheimer's disease}},
url = {http://www.sciencedirect.com/science/article/pii/S105381191101144X},
volume = {59},
year = {2012}
}
@article{Zhang2014,
author = {Zhang, Jianguang and Han, Yahong and Jiang, Jianmin},
doi = {10.1007/s00530-014-0416-7},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang, Han, Jiang - 2014 - Semi-supervised tensor learning for image classification.pdf:pdf},
issn = {0942-4962},
journal = {Multimedia Systems},
month = {sep},
title = {{Semi-supervised tensor learning for image classification}},
url = {http://link.springer.com/10.1007/s00530-014-0416-7},
year = {2014}
}
@article{Zhang2016,
abstract = {Nonnegative tensor factorization (NTF) has been widely applied in high-dimensional nonnegative tensor data analysis. However, most of the existing algorithms suffer from slow convergence caused by the nonnegativity constraint and hence their practical applications are severely limited. In this study, we propose a new algorithm called FastNTF{\_}APG to speed up NTF by combining accelerated proximal gradient and low-rank approximation. Experimental results demonstrate that FastNTF{\_}APG achieves significantly higher computational efficiency than state-of-the-art NTF algorithms.},
author = {Zhang, Yu and Zhou, Guoxu and Zhao, Qibin and Cichocki, Andrzej and Wang, Xingyu},
doi = {10.1016/j.neucom.2015.08.122},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang et al. - 2016 - Fast nonnegative tensor factorization based on accelerated proximal gradient and low-rank approximation.pdf:pdf},
issn = {09252312},
journal = {Neurocomputing},
keywords = {Accelerated proximal gradient,CP (PARAFAC) decompositions,Low-rank approximation.,Nonnegative tensor factorization},
month = {mar},
title = {{Fast nonnegative tensor factorization based on accelerated proximal gradient and low-rank approximation}},
url = {http://www.sciencedirect.com/science/article/pii/S0925231216003222},
year = {2016}
}
@article{Zhang2013,
author = {Zhang, ZY and Li, T and Ding, C},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang, Li, Ding - 2013 - Non-negative tri-factor tensor decomposition with applications.pdf:pdf},
journal = {Knowledge and information systems},
title = {{Non-negative tri-factor tensor decomposition with applications}},
url = {http://link.springer.com/article/10.1007/s10115-011-0460-y},
year = {2013}
}
@article{Zhao2014,
abstract = {Face recognition using different imaging modalities has become an area of growing interest. A large number of multispectral face recognition algorithms/systems have been proposed in last decade. How to fuse features of different spectrum has still been a crucial problem for face recognition. To address this problem, we propose a sparse tensor embedding (STE) algorithm which represents a multispectral image as a third-order tensor. STE constructs sparse neighborhoods and the corresponding weights of the tensor. One advantage of the proposed technique is that the difficulty in selecting the size of the local neighborhood can be avoided in the manifold learning based tensor feature extraction algorithms. STE iteratively obtains one spectral space transformation matrix through preserving the sparse neighborhoods. Due to sparse representation, STE can not only keep the underlying spatial structure of multispectral images but also enhance robustness. The experiments on multispectral face databases, Equinox and PolyU-HSFD face databases, show that the performance of the proposed method outperform that of the state-of-the-art algorithms. {\textcopyright} 2014 Elsevier B.V.},
author = {Zhao, Haitao and Sun, Shaoyuan},
journal = {Neurocomputing},
keywords = {Multibiometrics,Multispectral face recognition,Sparse tensor embedding},
pages = {427--436},
publisher = {Elsevier},
title = {{Sparse tensor embedding based multispectral face recognition}},
volume = {133},
year = {2014}
}
@article{Zhao2015,
abstract = {We propose a generative model for robust tensor factorization in the presence of both missing data and outliers. The objective is to explicitly infer the underlying low-CANDECOMP/PARAFAC (CP)-rank tensor capturing the global information and a sparse tensor capturing the local information (also considered as outliers), thus providing the robust predictive distribution over missing entries. The low-CP-rank tensor is modeled by multilinear interactions between multiple latent factors on which the column sparsity is enforced by a hierarchical prior, while the sparse tensor is modeled by a hierarchical view of Student-t distribution that associates an individual hyperparameter with each element independently. For model learning, we develop an efficient variational inference under a fully Bayesian treatment, which can effectively prevent the overfitting problem and scales linearly with data size. In contrast to existing related works, our method can perform model selection automatically and implicitly without the need of tuning parameters. More specifically, it can discover the groundtruth of CP rank and automatically adapt the sparsity inducing priors to various types of outliers. In addition, the tradeoff between the low-rank approximation and the sparse representation can be optimized in the sense of maximum model evidence. The extensive experiments and comparisons with many state-of-the-art algorithms on both synthetic and real-world data sets demonstrate the superiorities of our method from several perspectives.},
author = {Zhao, Qibin and Zhou, Guoxu and Zhang, Liqing and Cichocki, Andrzej and Amari, Shun-Ichi},
doi = {10.1109/TNNLS.2015.2423694},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhao et al. - 2015 - Bayesian Robust Tensor Factorization for Incomplete Multiway Data.pdf:pdf},
issn = {2162-2388},
journal = {IEEE transactions on neural networks and learning systems},
keywords = {Approximation methods,Bayes methods,Data models,Probabilistic logic,Rank determination,Robustness,Tensile stress,Tuning,robust factorization,tensor completion,tensor factorization,variational Bayesian (VB) inference,video background modeling.},
month = {jun},
number = {99},
pages = {1},
pmid = {26068876},
shorttitle = {Neural Networks and Learning Systems, IEEE Transac},
title = {{Bayesian Robust Tensor Factorization for Incomplete Multiway Data.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/26068876},
volume = {PP},
year = {2015}
}
@article{Zhou2016a,
abstract = {With the increasing availability of various sensor technologies, we now have access to large amounts of multiblock (also called multiset, multirelational, or multiview) data that need to be jointly analyzed to explore their latent connections. Various component analysis methods have played an increasingly important role for the analysis of such coupled data. In this article, we first provide a brief review of existing matrix-based (two-way) component analysis methods for the joint analysis of such data with a focus on biomedical applications. Then, we discuss their important extensions and generalization to multiblock multiway (tensor) data. We show how constrained multiblock tensor decomposition methods are able to extract similar or statistically dependent common features that are shared by all blocks, by incorporating the multiway nature of data. Special emphasis is given to the flexible common and individual feature analysis of multiblock data with the aim to simultaneously extract common and individual latent components with desired properties and types of diversity. Illustrative examples are given to demonstrate their effectiveness for biomedical data analysis.},
author = {Zhou, Guoxu and Zhao, Qibin and Zhang, Yu and Adali, Tulay and Xie, Shengli and Cichocki, Andrzej},
doi = {10.1109/JPROC.2015.2474704},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhou et al. - 2016 - Linked Component Analysis From Matrices to High-Order Tensors Applications to Biomedical Data.pdf:pdf},
issn = {0018-9219},
journal = {Proceedings of the IEEE},
keywords = {(multilinear) independent component analysis,(multiway) blind source separation (BSS),Analysis of multirelational data,Bioinformatics,Biomedical signal processing,Blind source separation,CP (CANDECOMP/PARAFAC) decompositions,Data mining,Feature extraction,Matrix decomposition,Principal component analysis,Tensile stress,biomedical applications,biomedical data,biomedical data analysis,constrained Tucker decompositions for multiblock d,constrained multiblock tensor decomposition method,data analysis,data fusion,electroencephalography,feature extraction,group and joint independent component analysis,high-order tensors,independent component analysis,independent vector analysis (IVA),individual feature analysis,individual latent components,joint analysis,latent connections,linked component analysis,matrix-based two-way component analysis methods,medical signal processing,multiblock multiway tensor data,multirelational data,multiset data,multiview data,nonnegative/sparse matrix/tensor factorizations,sensor technologies,statistically dependent common features,tensors},
month = {feb},
number = {2},
pages = {310--331},
shorttitle = {Proceedings of the IEEE},
title = {{Linked Component Analysis From Matrices to High-Order Tensors: Applications to Biomedical Data}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7373530},
volume = {104},
year = {2016}
}
@article{Zhou2016,
abstract = {We consider the problem of uplink channel estimation for millimeter wave (mmWave) systems, where the base station (BS) and mobile stations (MSs) are equipped with large antenna arrays to provide sufficient beamforming gain for outdoor wireless communications. Hybrid analog and digital beamforming structures are employed by both the BS and the MS due to hardware constraints. We propose a layered pilot transmission scheme and a CANDECOMP/PARAFAC (CP) decomposition-based method for joint estimation of the channels from multiple users (i.e. MSs) to the BS. The proposed method exploits the sparse scattering nature of the mmWave channel and the intrinsic multi-dimensional structure of the multiway data collected from multiple modes. The uniqueness of the CP decomposition is studied and sufficient conditions for essential uniqueness are obtained. The conditions shed light on the design of the beamforming matrix, the combining matrix and the pilot sequences, and meanwhile provide general guidelines for choosing system parameters. Our analysis reveals that our proposed method can achieve a substantial training overhead reduction by employing the layered pilot transmission scheme. Simulation results show that the proposed method presents a clear advantage over a compressed sensing-based method in terms of both estimation accuracy and computational complexity.},
archivePrefix = {arXiv},
arxivId = {1602.07955},
author = {Zhou, Zhou and Fang, Jun and Yang, Linxiao and Li, Hongbin and Chen, Zhi and Li, Shaoqian},
eprint = {1602.07955},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhou et al. - 2016 - Channel Estimation for Millimeter Wave Multiuser MIMO Systems via PARAFAC Decomposition.pdf:pdf},
month = {feb},
title = {{Channel Estimation for Millimeter Wave Multiuser MIMO Systems via PARAFAC Decomposition}},
url = {http://arxiv.org/abs/1602.07955},
year = {2016}
}
@article{Bhadra2016,
abstract = {In this paper, we introduce the first method that (1) can complete kernel matrices with completely missing rows and columns as opposed to individual missing kernel values, (2) does not require any of the kernels to be complete a priori, and (3) can tackle non-linear kernels. These aspects are necessary in practical applications such as integrating legacy data sets, learning under sensor failures and learning when measurements are costly for some of the views. The proposed approach predicts missing rows by modelling both within-view and between-view relationships among kernel values. We show, both on simulated data and real world data, that the proposed method outperforms existing techniques in the restricted settings where they are available, and extends applicability to new settings.},
archivePrefix = {arXiv},
arxivId = {1602.02518},
author = {Bhadra, Sahely and Kaski, Samuel and Rousu, Juho},
eprint = {1602.02518},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bhadra, Kaski, Rousu - 2016 - Multi-view Kernel Completion.pdf:pdf},
keywords = {multimodal,tensor completion},
mendeley-tags = {multimodal,tensor completion},
month = {feb},
title = {{Multi-view Kernel Completion}},
url = {http://arxiv.org/abs/1602.02518},
year = {2016}
}
@article{Cabral2011,
author = {Cabral, RS and la Torre, F De and Costeira, JP and Bernardino, A},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cabral et al. - 2011 - Matrix Completion for Multi-label Image Classification.pdf:pdf},
journal = {NIPS},
title = {{Matrix Completion for Multi-label Image Classification.}},
url = {http://papers.nips.cc/paper/4419-matrix-completionfor-multi-label-image-classification.pdf},
year = {2011}
}
@incollection{Daoqiang2006,
abstract = {In this paper, we extend the original non-negative matrix factorization (NMF) to kernel NMF (KNMF). The advantages of KNMF over NMF are: 1) it could extract more useful features hidden in the original data through some kernel-induced nonlinear mappings; 2) it can deal with data where only relationships (similarities or dissimilarities) between objects are known; 3) it can process data with negative values by using some specific kernel functions (e.g. Gaussian). Thus, KNMF is more general than NMF. To further improve the performance of KNMF, we also propose the SpKNMF, which performs KNMF on sub-patterns of the original data. The effectiveness of the proposed algorithms is validated by extensive experiments on UCI datasets and the FERET face database.},
address = {Berlin, Heidelberg},
author = {Daoqiang, Zhang and Zhi-Hua, Zhou and Songcan, Chen},
booktitle = {PRICAI 2006: Trends in Artificial Intelligence},
doi = {10.1007/978-3-540-36668-3},
editor = {Yang, Qiang and Webb, Geoff},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Daoqiang, Zhi-Hua, Songcan - 2006 - Non-negative Matrix Factorization on Kernels.pdf:pdf},
isbn = {978-3-540-36667-6},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Non-negative Matrix Factorization on Kernels}},
url = {http://www.springerlink.com/index/10.1007/978-3-540-36668-3},
volume = {4099},
year = {2006}
}
@article{Ding,
abstract = {Current nonnegative matrix factorization (NMF) deals with X = FGT type. We provide a systematic analysis and extensions of NMF to the symmetric W = HHT, and the weighted W = HSHT. We show that (1) W = HHT is equivalent to Kernel if-means clustering and the Laplacian-based spectral clustering. (2) X = FGT is equivalent to simultaneous clustering of rows and columns of a bipartite graph. Algorithms are given for computing these symmetric NMFs. Read More: http://epubs.siam.org/doi/abs/10.1137/1.9781611972757.70},
author = {Ding, Chris and He, Xiaofeng and {D. Simon}, Horst},
journal = {Proceedings of the 2005 SIAM International Conference on Data Mining},
language = {en},
title = {{On the Equivalence of Nonnegative Matrix Factorization and Spectral Clustering}},
url = {http://epubs.siam.org/doi/abs/10.1137/1.9781611972757.70}
}
@article{Drineas2005,
author = {Drineas, Petros and Mahoney, Michael W.},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Drineas, Mahoney - 2005 - On the Nystr{\"{o}}m Method for Approximating a Gram Matrix for Improved Kernel-Based Learning.pdf:pdf},
issn = {1532-4435},
journal = {The Journal of Machine Learning Research},
month = {dec},
pages = {2153--2175},
publisher = {JMLR.org},
title = {{On the Nystr{\"{o}}m Method for Approximating a Gram Matrix for Improved Kernel-Based Learning}},
url = {http://dl.acm.org/citation.cfm?id=1046920.1194916},
volume = {6},
year = {2005}
}
@inproceedings{Graepel2002,
address = {Berlin, Heidelberg},
author = {Graepel, Thore},
booktitle = {Artificial Neural Networks — ICANN 2002},
doi = {10.1007/3-540-46084-5},
editor = {Dorronsoro, Jos{\'{e}} R.},
isbn = {978-3-540-44074-1},
month = {aug},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Kernel Matrix Completion by Semidefinite Programming}},
url = {http://link.springer.com/10.1007/3-540-46084-5},
volume = {2415},
year = {2002}
}
@article{Kwok2004,
abstract = {In this paper, we address the problem of finding the pre-image of a feature vector in the feature space induced by a kernel. This is of central importance in some kernel applications, such as on using kernel principal component analysis (PCA) for image denoising. Unlike the traditional method which relies on nonlinear optimization, our proposed method directly finds the location of the pre-image based on distance constraints in the feature space. It is noniterative, involves only linear algebra and does not suffer from numerical instability or local minimum problems. Evaluations on performing kernel PCA and kernel clustering on the USPS data set show much improved performance.},
author = {Kwok, James Tin-yau and Tsang, Ivor Wai-hung},
doi = {10.1109/TNN.2004.837781},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kwok, Tsang - 2004 - The pre-image problem in kernel methods.pdf:pdf;:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kwok, Tsang - 2004 - The pre-image problem in kernel methods(2).pdf:pdf},
issn = {1045-9227},
journal = {IEEE transactions on neural networks / a publication of the IEEE Neural Networks Council},
keywords = {Algorithms,Artificial Intelligence,Automated,Automated: methods,Cluster Analysis,Computer Simulation,Computer-Assisted,Computer-Assisted: methods,Decision Support Techniques,Feedback,Image Interpretation,Information Storage and Retrieval,Information Storage and Retrieval: methods,Neural Networks (Computer),Pattern Recognition,Principal Component Analysis},
month = {nov},
number = {6},
pages = {1517--25},
pmid = {15565778},
shorttitle = {IEEE Transactions on Neural Networks},
title = {{The pre-image problem in kernel methods.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15565778},
volume = {15},
year = {2004}
}
@article{Lanckriet2004,
author = {Lanckriet, Gert R. G. and Cristianini, Nello and Bartlett, Peter and Ghaoui, Laurent El and Jordan, Michael I.},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lanckriet et al. - 2004 - Learning the Kernel Matrix with Semidefinite Programming.ps:ps},
issn = {1532-4435},
journal = {The Journal of Machine Learning Research},
keywords = {kernel},
mendeley-tags = {kernel},
month = {dec},
pages = {27--72},
publisher = {JMLR.org},
title = {{Learning the Kernel Matrix with Semidefinite Programming}},
url = {http://dl.acm.org/citation.cfm?id=1005332.1005334},
volume = {5},
year = {2004}
}
@inproceedings{Li2012,
abstract = {Non-negative factorization (NMF) has been a popular machine learning method for analyzing microarray data. Kernel approaches can capture more non-linear discriminative features than linear ones. In this paper, we propose a novel kernel NMF (KNMF) approach for feature extraction and classification of microarray data. Our approach is also generalized to kernel high-order NMF (HONMF). Extensive experiments on eight microarray datasets show that our approach generally outperforms the traditional NMF and existing KNMFs. Preliminary experiment on a high-order microarray data shows that our KHONMF is a promising approach given a suitable kernel function.},
author = {Li, Yifeng and Ngom, Alioune},
booktitle = {2012 IEEE Symposium on Computational Intelligence in Bioinformatics and Computational Biology (CIBCB)},
doi = {10.1109/CIBCB.2012.6217254},
isbn = {978-1-4673-1191-5},
keywords = {Classification,Clustering algorithms,Equations,Feature Extraction,Feature extraction,Kernel,Kernel Non-Negative Matrix Factorization,Matrix decomposition,Microarray Data,Optimization,Tensile stress,bioinformatics,classification,data classification,feature extraction,genetic algorithms,genetics,kernel nonnegative matrix factorization,learning (artificial intelligence),machine learning method,matrix decomposition,microarray data analysis,nonlinear discriminative features,operating system kernels},
month = {may},
pages = {371--378},
publisher = {IEEE},
shorttitle = {Computational Intelligence in Bioinformatics and C},
title = {{A new Kernel non-negative matrix factorization and its application in microarray data analysis}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6217254},
year = {2012}
}
@article{Liang2010,
abstract = {Nonnegative matrix factorization (NMF) is a technique for analyzing the data structure when nonnegative constraints are imposed. However, NMF aims at minimizing the objective function from the viewpoint of data reconstruction and thus it may produce undesirable performances in classification tasks. In this paper, we develop a novel NMF algorithm (called KDNMF) by optimizing the objective function in a feature space under nonnegative constraints and discriminant constraints. The KDNMF method exploits the geometrical structure of data points and seeks the tradeoff between data reconstruction errors and the geometrical structure of data. The projected gradient method is used to solve KDNMF since directly using the multiplicative update algorithm to update nonnegative matrices is impractical for Gaussian kernels. Experiments on facial expression images and face images are conducted to show the effectiveness of the proposed method.},
author = {Liang, Zhizheng and Li, Youfu and Zhao, Tuo},
doi = {10.1016/j.sigpro.2010.01.019},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liang, Li, Zhao - 2010 - Projected gradient method for kernel discriminant nonnegative matrix factorization and the applications.pdf:pdf},
issn = {01651684},
journal = {Signal Processing},
keywords = {Discriminant analysis,Feature extraction,Image classification,Kernel function,Nonnegative matrix factorization},
month = {jul},
number = {7},
pages = {2150--2163},
title = {{Projected gradient method for kernel discriminant nonnegative matrix factorization and the applications}},
url = {http://www.sciencedirect.com/science/article/pii/S0165168410000344},
volume = {90},
year = {2010}
}
@inproceedings{PaezTorres2015,
abstract = {Matrix factorization (MF) has shown to be a competitive machine learning strategy for many problems such as dimensionality reduction, latent topic modeling, clustering, dictionary learning and manifold learning, among others. In general, MF is a linear modeling method, so different strategies, most of them based on kernel methods, have been proposed to extend it to non-linearmodeling. However, as with many other kernel methods, memory requirements and computing time limit the application of kernel-based MF methods in large-scale prob- lems. In this paper, we present a new kernel MF (KMF). This method uses a budget, a set of representative points of size p ? n,where n is the size of the training data set, to tackle the memory problem, and uses stochastic gradient descent to tackle the computation time and memory problems. The experimental results show a performance, in particular tasks, comparable to other kernel matrix factorization and clustering methods, and a competitive computing time in large-scale problems. Keywords:},
address = {Cham},
author = {{Paez Torres}, Andres Esteban and Gonzalez, Fabio A.},
booktitle = {Progress in Pattern Recognition, Image Analysis, Computer Vision, and Applications},
doi = {10.1007/978-3-319-25751-8},
editor = {Pardo, Alvaro and Kittler, Josef},
file = {:home/ajaque/Documents/PhD/multi modal/chp{\%}3A10.1007{\%}2F978-3-319-25751-8{\_}78.pdf:pdf},
isbn = {978-3-319-25750-1},
keywords = {Feature space factorization,Kernel matrix factorization,Large-scale learning,kernel NMF},
mendeley-tags = {kernel NMF},
publisher = {Springer International Publishing},
series = {Lecture Notes in Computer Science},
title = {{Online Kernel Matrix Factorization}},
url = {http://link.springer.com/10.1007/978-3-319-25751-8},
volume = {9423},
year = {2015}
}
@article{Paisley2010,
author = {Paisley, JW and Carin, L},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Paisley, Carin - 2010 - A nonparametric Bayesian model for kernel matrix completion.1146v1:1146v1},
journal = {ICASSP},
title = {{A nonparametric Bayesian model for kernel matrix completion.}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.675.2434{\&}rep=rep1{\&}type=pdf},
year = {2010}
}
@article{Taishin2011,
author = {Taishin, Kin and Tsuyoshi, Kato and Koji, Tsuda and Kiyoshi, Asai},
doi = {10.11234/gi1990.14.516},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Taishin et al. - 2011 - Protein Classification via Kernel Matrix Completion.pdf:pdf},
journal = {Genome Informatics},
keywords = {matrix completion},
mendeley-tags = {matrix completion},
month = {jul},
pages = {516},
title = {{Protein Classification via Kernel Matrix Completion}},
url = {https://www.jstage.jst.go.jp/article/gi1990/14/0/14{\_}0{\_}516/{\_}article},
year = {2011}
}
@article{Talwalkar2010,
abstract = {The Nystrom method is an efficient technique to speed up large-scale learning applications by generating low-rank approximations. Crucial to the performance of this technique is the assumption that a matrix can be well approximated by working exclusively with a subset of its columns. In this work we relate this assumption to the concept of matrix coherence and connect matrix coherence to the performance of the Nystrom method. Making use of related work in the compressed sensing and the matrix completion literature, we derive novel coherence-based bounds for the Nystrom method in the low-rank setting. We then present empirical results that corroborate these theoretical bounds. Finally, we present more general empirical results for the full-rank setting that convincingly demonstrate the ability of matrix coherence to measure the degree to which information can be extracted from a subset of columns.},
archivePrefix = {arXiv},
arxivId = {1004.2008},
author = {Talwalkar, Ameet and Rostamizadeh, Afshin},
eprint = {1004.2008},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Talwalkar, Rostamizadeh - 2010 - Matrix Coherence and the Nystrom Method.pdf:pdf},
month = {apr},
title = {{Matrix Coherence and the Nystrom Method}},
url = {http://arxiv.org/abs/1004.2008},
year = {2010}
}
@article{Tsuda2003,
author = {Tsuda, Koji and Akaho, Shotaro and Asai, Kiyoshi},
doi = {10.1162/153244304322765649},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tsuda, Akaho, Asai - 2003 - The em algorithm for kernel matrix completion with auxiliary data.pdf:pdf},
issn = {0003-6951},
journal = {The Journal of Machine Learning Research},
month = {dec},
pages = {67--81},
publisher = {JMLR.org},
title = {{The em algorithm for kernel matrix completion with auxiliary data}},
url = {http://dl.acm.org/citation.cfm?id=945365.945369},
volume = {4},
year = {2003}
}
@article{Williams2005,
author = {Williams, D and Carin, L},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Williams, Carin - 2005 - Analytical kernel matrix completion with incomplete multi-view data.pdf:pdf},
journal = {Proceedings of the ICML Workshop on  {\ldots}},
title = {{Analytical kernel matrix completion with incomplete multi-view data}},
url = {http://www.stefan-rueping.de/publications/rueping-scheffer-2005-a.pdf{\#}page=80},
year = {2005}
}
@article{Zhu2014,
abstract = {The nonnegative matrix factorization (NMF) is widely used in signal and image processing, including bio-informatics, blind source separation and hyperspectral image analysis in remote sensing. A great challenge arises when dealing with a nonlinear formulation of the NMF. Within the framework of kernel machines, the models suggested in the literature do not allow the representation of the factorization matrices, which is a fallout of the curse of the pre-image. In this paper, we propose a novel kernel-based model for the NMF that does not suffer from the pre-image problem, by investigating the estimation of the factorization matrices directly in the input space. For different kernel functions, we describe two schemes for iterative algorithms: an additive update rule based on a gradient descent scheme and a multiplicative update rule in the same spirit as in the Lee and Seung algorithm. Within the proposed framework, we develop several extensions to incorporate constraints, including sparseness, smoothness, and spatial regularization with a total-variation-like penalty. The effectiveness of the proposed method is demonstrated with the problem of unmixing hyperspectral images, using well-known real images and results with state-of-the-art techniques.},
archivePrefix = {arXiv},
arxivId = {1407.4420{\#}},
author = {Zhu, Fei and Honeine, Paul and Kallas, Maya},
eprint = {1407.4420{\#}},
file = {:home/ajaque/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhu, Honeine, Kallas - 2014 - Kernel Nonnegative Matrix Factorization Without the Curse of the Pre-image - Application to Unmixing Hyper.pdf:pdf},
month = {jul},
pages = {13},
title = {{Kernel Nonnegative Matrix Factorization Without the Curse of the Pre-image - Application to Unmixing Hyperspectral Images}},
url = {http://arxiv.org/abs/1407.4420{\#}},
year = {2014}
}
